\ifdissertation
In this chapter, we address the problem of symmetry without regard for
alignment or performance issues. We will begin from asymmetric, state-based
lenses and build a theory of symmetric, state-based lenses from them, and
show how to recover the rich asymmetric syntax in symmetric form. In
particular, we will show how to implement lens composition---the process of
running two bidirectional transformations, one after the other---long
thought to be an operation fundamentally in conflict with symmetric
bidirectional presentations. In order to support this operation with the
usual algebraic properties like associativity, we will need to develop a
theory of behavioral equivalence. Unlike asymmetric theories, where ordinary
equality suffices, our symmetric lenses have hidden state whose importance
should be discounted when checking whether two lenses compute the same
transformation. We will also discuss a collection of bidirectional
operations which correspond to common transformations of container-based
data types as well as inductive data types built up from products, sums, and
type-level recursion. Finally, we will give an account of the connection
between asymmetric and symmetric lenses: asymmetric lenses can be lifted to
symmetric lenses, and symmetric lenses can be represented as a span of
asymmetric lenses.
\fi%dissertation

\section{Fundamental Definitions} \label{symm}

\ifcomplement
\SMALLSECTIONHEADER{Asymmetric Lenses}
%
To set the stage, let's review the standard definition of
asymmetric lenses.  
%
(Other definitions can be given, featuring weaker or stronger laws, but this
version is widely accepted.  We discuss variants in
\S\ref{sec:relwork}.)
%
Suppose $X$ is some set of source structures (say, the possible states of a
database) and $Y$ a set of target structures (views of the database).
%
An asymmetric lens from $X$ to $Y$ has two components:
\[ 
\begin{array}{r@{\ \;}c@{\ \;}l}
\GET &\in& X \arrow Y\\
\PUT &\in& Y \times X \arrow X
\end{array}
\]
The \GET{} component is the forward transformation, a total function from
$X$ to $Y$.  The \PUT{} component takes an old $X$ and a modified $Y$ and
yields a correspondingly modified $X$.  These components
must obey two ``round-tripping'' laws for every $x \in X$ and $y
\in Y$:
%
\infax[GetPut]{
  \PUT(\GET \; x, x) = x 
}
\infax[PutGet]{
  \GET\; (\PUT(y,x)) = y  
}
%
It is also useful to be able to create an element of $x$ given just an
element of $y$, with no ``original $x$'' to put it into; in order to handle
this in a 
uniform way, each lens is also equipped with a
function $\CREATE\in Y\arrow X$, and we assume one more axiom:
\infax[CreateGet]{
    \GET\; (\CREATE \; y) = y
}
\fi%complement

\SMALLSECTIONHEADER{Complements}
%
The key  step toward symmetric lenses is the notion
of {\em complements}.  The idea dates back to a famous paper in the
database literature on the view update
problem~\cite{DBLP:journals/tods/BancilhonS81} and was adapted to
lenses in~\cite{Matching10} (and, for a slightly different
definition,~\cite{matsuda2007btb}), and it is quite simple.  If we think of
the    
\GET{} component of a lens as a sort of projection function, then we can find
another projection from $X$ into some set $C$ that
keeps all the information discarded by \GET{}.  Equivalently, we can think
of \GET{} as returning two results---an element of $Y$ and an element of
$C$---that together contain all the information needed to reconstitute the
original element of $X$.  Now the \PUT{} function doesn't need a whole $x\in
X$ to recombine with some updated $y\in Y$; it can
just take the complement $c\in C$ generated from $x$ by the \GET, since this
will 
contain all the information that is missing from $y$.  Moreover, instead of
a separate
$\CREATE$ function, we can simply pick a distinguished element
$\missing\in C$ and define $\CREATE(y)$ as $\PUT(y,\missing)$.
\ifcomplement
In many realistic cases, this modified form of \GET will not be surjective:
there will be pairs of complements and views which do not match up. One may
worry that this makes the implementation of \PUT functions more difficult,
as they may need to merge a view and a complement which are not in the image
of \GET; however, as we discuss below, it turns out that this is no more
difficult than the task that asymmetric lenses already handle of merging a
view and source which do not match.
\fi

Formally, an {\em asymmetric lens with complement}
mapping between $X$ and $Y$ consists of a set $C$, a
distinguished element $\missing \in C$, and two functions
\[
\begin{array}{r@{\ \;}c@{\ \;}l}
\GET &\in& X \arrow Y \times C\\
\PUT &\in& Y \times C \arrow X
\end{array}
\]
obeying the following laws for every $x \in X$, $y \in Y$, and $c \in C$:%
\footnote{We can convert back and
forth between the two presentations; in particular, if $(\GET, \PUT,
\CREATE)$ are the components of a traditional lens, then we define a
canonical complement by $C=\{f\in Y{\rightarrow}X\mid \forall
y.\;\GET(f(y))=y\}$. We then define the components $\missing'$, $\GET'$, and
$\PUT'$ 
of an asymmetric lens with complement as $\missing'=\CREATE$ and
$\GET'(x)=(\GET(x),\lambda y.\PUT(y,x))$ and $\PUT'(y,f)=f(y)$.
\iffull
Going the other way, if $(\aget, \aput, \missing)$ are the components of an
asymmetric lens with complement, we can define a traditional lens by
$\aget'(x) = \mlfst(\aget(x))$ and $\aput'(y,x) = \aput(y,\mlsnd(\aget(x)))$
and $\acreate(y) = \aput(y,\missing)$.
\fi
}
%
\infrule[GetPut]{
  \GET\; x = (y,c)
}{
  \PUT\; (y,c) = x 
}
\infrule[PutGet]{
  \GET\; (\PUT \; (y,c)) = (b',c')
}{
  b' = y
}
Note that the type is just ``lens from $X$ to $Y$'': the set
$C$ is an internal component, not part of the externally visible type.
In symbols, $ \mathit{Lens}(X,Y) =
\exists C.\; \{ \mathord{\missing}:\, C,\; \GET:\,X \arrow Y
\times C,\; \PUT:\,Y \times C \arrow X \}$.

\SMALLSECTIONHEADER{Symmetric Lenses}
%
Now we can symmetrize.  
First, instead of having only \GET{} return a complement, we make \PUT{}
return a complement too, and we take this complement as a second argument
to $\GET$.
%
\iffull
\[
\begin{array}{r@{\ \;}c@{\ \;}l}
\GET &\in& X \times C_Y \arrow Y \times C_X\\
\PUT &\in& Y \times C_X \arrow X \times C_Y
\end{array}
\]
\else
So we have $\GET \in X \times C_Y \arrow Y \times C_X$ and 
$\PUT \in Y \times C_X \arrow X \times C_Y$.
\fi
%
Intuitively, $C_X$ is the ``information from $X$ that is discarded by
\GET\commaquote and $C_Y$ is the ``information from $Y$ that is discarded by
\PUT\dotquote Next we observe that we can, without loss of generality, use the
same set $C$ as the complement in both directions.  \iffull (This ``tweak''
is actually critical: it is what allows us to define composition of symmetric
lenses.)\fi
\iffull
\[
\begin{array}{r@{\ \;}c@{\ \;}l}
\GET &\in& X \times C \arrow Y \times C\\
\PUT &\in& Y \times C \arrow X \times C
\end{array}
\]
\else
So now we have 
$\GET \in X \times C \arrow Y \times C$ and
$\PUT \in Y \times C \arrow X \times C$.
\fi
%
We can think of the combined complement $C$ as $C_X \times
C_Y$---that is, each complement contains some ``private information from
$X$'' and some ``private information from $Y$''; by convention, the \GET{}
function reads the $C_Y$ part and writes the $C_X$ part, while the \PUT{}
reads the $C_X$ part and writes the $C_Y$ part.  
%
Lastly, now that everything is symmetric, the \GET{} / \PUT{} distinction is not
helpful, so we rename the functions to \PUTR{} and \PUTL.  This brings us to
our core definition.

\iffull
\begin{figure*}[t!] \centering
\vspace*{-4ex}
\hspace*{-1em}
\begin{tabular}{@{}cc}
  \ifpdf\tikz\pdf{symmetric-minus};\vspace*{-1ex}
  \else \tikz\pdf{symmetric-minus}node[below=8.2ex]{};
  \fi
 &
  \tikz\pdf{symmetric};
  \ifpdf\vspace*{-2ex}\fi
 \\
(a) Initial \replicas & (b) Initial complement 
\vspace*{4ex} \\
  \ifpdf\tikz\pdf{symmetric-edit};\vspace*{-.7ex}
  \else \tikz\pdf{symmetric-edit}node[below=10ex]{};
  \fi
&
  \tikz\pdf{symmetric-propagatex};
\\
(c) One \replica edited & (d) Propagating the edit 
\vspace*{3ex}
\\
  \ifpdf\vspace*{3ex}\tikz\pdf{symmetric-edit2};\vspace*{-8ex}
  \else \tikz\pdf{symmetric-edit2}node[below=12.9ex]{};
  \fi
&
  \ifpdf\tikz\pdf{symmetric-propagate2};\vspace*{-1ex}
  \else \tikz\pdf{symmetric-propagate2}node[below=12.9ex]{};
  \fi
\\
(e) Second \replica is edited & (f) This change is propagated
\vspace*{1.5ex}
\\
\end{tabular}
\caption{Behavior of a symmetric lens}\vspace*{2ex}
\label{fig:symm}
\end{figure*}
\else
\begin{figure*}[t!] \centering
\vspace*{-4ex}
\hspace*{-1em}
\begin{tabular}{@{}ccc}
  \ifpdf\tikz\pdf{symmetric-minus};\vspace*{-1ex}
  \else \tikz\pdf{symmetric-minus}node[below=8.2ex]{};
  \fi
 &
  \tikz\pdf{symmetric};
  \ifpdf\vspace*{-1ex}\fi
&
  \ifpdf\tikz\pdf{symmetric-edit};\vspace*{-3ex}
  \else \tikz\pdf{symmetric-edit}node[below=10ex]{};
  \fi
 \\
(a) Initial \replicas & (b) Initial complement & (c) One \replica edited 
\vspace*{2ex} \\
  \tikz\pdf{symmetric-propagatex};
&
  \ifpdf\vspace*{3ex}\tikz\pdf{symmetric-edit2};\vspace*{-4ex}
  \else \tikz\pdf{symmetric-edit2}node[below=12.9ex]{};
  \fi
&
  \ifpdf\tikz\pdf{symmetric-propagate2};\vspace*{-1ex}
  \else \tikz\pdf{symmetric-propagate2}node[below=12.9ex]{};
  \fi
\\
(d) Propagating the edit & (e) Second \replica is edited & (f) This change is propagated
\vspace*{1ex}
\\
\end{tabular}
\caption{Behavior of a symmetric lens}
\label{fig:symm}
\end{figure*}
\fi

\begin{defn}[Symmetric lens]
A lens $\ell$ from $X$ to 
$Y$ (written $\ell \in X \lens Y$) has three parts:
a set of complements $C$, a distinguished element $\missing \in
C$, and two functions
\begin{eqnarray*}
    \putr &\in& X \times C \to Y \times C\\
    \putl &\in& Y \times C \to X \times C
\end{eqnarray*}
satisfying the following round-tripping laws:
\infrule[PutRL]{\putr(x,c) = (y,c')}{\putl(y,c') = (x,c')}
\infrule[PutLR]{\putl(y,c) = (x,c')}{\putr(x,c') = (y,c')}
When several lenses are under discussion, we use record notation to identify
their parts, writing $\ell.C$ for the complement set of $\ell$, etc. 
\end{defn}

\iftext The force of the \rn{PutRL} and \rn{PutLR} laws is to establish some
``consistent'' or ``steady-state'' triples $(x,y,c)$, for which \PUT{}s of $x$
from the left or $y$ from the right will have no effect---that is, will not
change the complement. The conclusion of each rule has the same variable
$c'$ on both sides of the equation to reflect this.  We will use the
equation $\putr(x,c) = (y,c)$ to characterize the steady states\footnote{The
alternate equation $\putl(y,c)=(x,c)$ has the same solutions.}.  In
general, a \PUT{} of a new $x'$ from the left entails finding a $y'$ and a
$c'$ that restore consistency.  Additionally, we often wish this
process to involve the
complement $c$ from the previous steady state; as a result, it can be
delicate to choose a good value of $\missing$. This value can often be
chosen compositionally; each of our primitive lenses and lens combinators
specify one good choice for $\missing$.

\iflater\finish{There's a good technical discussion of the options for
  dealing with creation in symmetric.v --- might be worth including it
  here.}\fi \fi

\iffull\else One can imagine other laws.  In particular, the long version of
the paper considers symmetric forms of the asymmetric ``\rn{PutPut}'' laws,
which specify that two \PUT{} operations in a row should have the same
effect as the second one alone.  As with asymmetric lenses, these
laws appear too strong to be desirable in practice.  \fi

%% %
%% We say that lenses $l$ and $l'$ are {\em equivalent} if there exists a
%% relation $\mathord{\equivl} \subseteq C \times \C{l'}$ such that:
%% \infax[MissingC]{l.\missing \equivl l'.\missing}
%% \infrule[PutrC]{
%%   c \equivl c' 
%%   \andalso
%%   l.\PUTR (a, c) = (b,c_1)
%%   \andalso
%%   l'.\PUTR (a, c') = (b,c_1')
%% }{
%%   b = b' \ \wedge\   c_1 \equivl c_1'
%% }
%% \infrule[PutlC]{
%%   c \equivl c' 
%%   \andalso
%%   l.\PUTL (b, c) = (a,c_1)
%%   \andalso
%%   l'.\PUTL (b, c') = (a,c_1')
%% }{
%%   a = a' \ \wedge\   c_1 \equivl c_1'
%% }

%% With these definitions in place, we can develop some basic
%% structure.  For every set $A$, we can define is an identity lens $\mathit{id}$
%% (with a trivial complement) from $A$ to itself.  If we have a lens $l$
%% from $A$ to $B$ and a lens $l'$ from $B$ to $X$, we can compose them to form
%% a lens $(l;l')$ from $A$ to $X$, using $l.C \times l'.C$ as the complement.
%% %
%% We can also show that, up to equivalence, composition is associative and
%% \emph{id} is its unit---i.e., symmetric lenses form a category.  

%% \iffull \else \iftext \finish{Briefly mention the PutPut laws and the fact
%%   that, as usual, they are too strong.} \fi \fi
%% \iffull

\paragraph*{Examples} Figure~\ref{fig:symm} illustrates the use of a
symmetric lens.  
%
The structures in this example are lists of textual records describing
composers. The partially synchronized records (a) have a name and two dates
on the left and a name and a country on the right.
%
The complement (b) contains all the information that is discarded by both
$\PUT$s---all the dates from the left-hand structure and all the countries
from the right-hand structure.  (It can be viewed as a pair of lists of
strings, or equivalently as a list of pairs of strings; the way we build
list lenses later actually corresponds to the latter.)  If we add a
new record to the left hand structure (c) and use the $\PUTR$ operation to
propagate it through the lens (d), we copy the shared information (the new
name) directly from left to right, store the private information (the new
dates) in the complement, and use a default string to fill in both the
private information on the right and the corresponding right-hand part of
the complement.  If we now update the right-hand structure to fill in the
missing information and correct a typo in one of the other names
(e), then a $\PUTL$ operation will propagate the edited country to the
complement, propagate the edited name to the other structure, and use the
complement to restore the dates for all three composers.

Viewed more abstractly, the
connection between the information about a single composer in the two tables
is a lens from $X \times Y$ to $Y \times Z$, with complement $X
\times Z$---let's call this lens $e$.  Its \PUTR{} component is given $(x,y)$ as
input and has $(x',z)$ in its complement; it constructs a new complement by
replacing $x'$ by $x$ to form $(x,z)$, and it constructs its output by
pairing the $y$ from its input and the $z$ from its complement to form
$(y,z)$. The \PUTL{} component does the opposite, replacing the $z$ part of
the complement and retrieving the $x$ part.  Then the
top-level lens in Figure~\ref{fig:symm}---let's call it
$e\LIST$---abstractly has type $(X \times Y)\LIST \lens (Y \times Z)\LIST$
and can be thought of as the ``lifting'' of $e$ from elements
to lists.  

There are several plausible implementations of
$e\LIST$, with slightly different behaviors when list elements are
added and removed---i.e., when the input and complement arguments to \PUTR{}
or \PUTL{} are lists
of different lengths.  One possibility is to take $e\LIST.C = (e.C)\LIST$
and maintain the invariant that the complement list in the output is the same length as
the input list. When the lists in the input have different lengths, we can
restore the 
invariant by either truncating the complement list or padding it with
$e.\missing$.
% \iffull
For example, taking $X = \{a,b,c,\ldots\}$, $Y = \{1,2,3,\ldots\}$, $Z =
\{A,B,C,\ldots\}$, and $e.\missing = (m,M)$, and writing
$\left<a,b,c\right>$ for the sequence with the three elements $a$, $b$, and
$c$, we could have:
\[
\begin{array}{ll}
& \PUTR (\left<(a,1)\right>,\;
         \left<(p,P),(q,Q)\right>)
\\
= &\PUTR (\left<(a,1)\right>,\;
         \left<(p,P)\right>)\mbox{\hspace{7.7em}(truncating)}
\\
= & ( \left<(1,P)\right>,\; \left<(a,P)\right>)
\\ [1.5ex]
& \PUTR (\left<(a,1),(b,2)\right>,\;
         \left<(a,P)\right>)
\\
= &\PUTR (\left<(a,1),(b,2)\right>,\;
         \left<(a,P),(m,M)\right>)\mbox{\qquad(padding)}
\\
= & (\left<(1,P),(2,M)\right>,\;
         \left<(a,P),(b,M)\right>)
\end{array}
\]
% \fi
Notice that, after the first \PUTR{}, the information in the second
element of the complement list $(q,Q)$ is lost.
The second \PUTR{} creates a brand new second element for the list, so the value $Q$ is
gone forever; what's left is the default value $M$.

Another possibility---arguably better behaved---is to keep
  an {\em 
  infinite} list of complements.  Whenever we do a \PUT{}, we use (and
update) a prefix of the complement list of the same length as the current
value being \PUT, but we keep the infinite tail so that, later, we have
  values to use when the list being \PUT{} is longer.
%% \finish{Probably we should ``iffull'' the following display once it's been
%%   checked, to save space.}
% \iffull
\[
\begin{array}{ll}
& \PUTR (\left<(a,1)\right>,\;
         \left<(p,P),(q,Q),(m,M),(m,M),\ldots\right>) 
\\
= & ( \left<(1,P)\right>,\; \left<(a,P),(q,Q),(m,M),(m,M),\ldots\right>)
\\ [1.5ex]
& \PUTR (\left<(a,1),(b,2)\right>,\;
         \left<(a,P),(q,Q),(m,M),(m,M),\ldots\right>)
\\
= & (\left<(1,P),(2,Q)\right>,\;
         \left<(a,P),(b,Q),(m,M),\ldots\right>)
\end{array}
\]
% \fi

We call the first form the {\em forgetful} list mapping lens and the second
the {\em retentive} list mapping lens.  We will see, later, that the
difference between these two precisely boils down to a difference in the
behavior of the lens-summing operator $\oplus$ in the specification
$e\LIST \simeq \id_\Unit \oplus (e \otimes e\LIST)$ of the list mapping lens.

\begin{figure*}[t!] \centering
\vspace*{-4ex}
\begin{tabular}{@{}ccc}
  \tikz\pdf{sums1};
  &
  \tikz\pdf{sums2};
  \ifpdf\else\vspace*{2ex}\fi
  \\
  (a) Initial \replicas & (b) Alphabetizing the right
  \vspace*{2ex} \\
  \tikz\pdf{sums3};
  &
  \tikz\pdf{sums4};
  \ifpdf\else\vspace*{2ex}\fi
  \\
  (c) Inserting Chopin on the left & (d) Deleting Beethoven from the left
\end{tabular}
\caption{Synchronizing lists of sums}
\label{fig:sums}
\end{figure*}
Figure~\ref{fig:sums} illustrates another use of symmetric lenses. The
structures in this example are lists of categorized data; each name on the
left is either a composer (tagged {\tt inl}) or an author (tagged
{\tt inr}), and each name 
on the right is either a composer or an actor.  The
lens under consideration will synchronize just the composers between the two
lists, leaving the authors untouched on the left and the actors untouched on
the right. The synchronized state (a) shows a complement with two lists,
each with holes for the composers.  If we re-order the
right-hand structure (b), the change in order will be
reflected on the left by swapping the two composers. Adding another composer
on the left
(c) involves adding a new hole to each complement; on the left, the location
of the hole is determined by the new list, and on the right it simply shows
up at the end. Similarly, if we remove a composer (d), the
final hole on the other side disappears.

Abstractly, to achieve this behavior we need to define a lens $\comp$
between $(X+Y)\LIST$ and 
$(X+Z)\LIST$.  To do this, it is convenient to first define a lens that
connects $(X+Y)\LIST$ and $X\LIST \times Y\LIST$; call this lens $\partition$.
The complement of the $\partition$ is a list of booleans telling whether the
corresponding element of the left list is an $X$ or a $Y$. The $\putr$
function is fairly simple: we separate the $(X+Y)$ list into $X$ and $Y$
lists by checking the tag of each element, and set the complement to exactly
match the tags. For example:
\begin{align*}
\putr(\left<\mlinl a,\mlinl b,\mlinr 1\right>,c) &=
    ((\left<a,b\right>,\left<1\right>),\left<\false,\false,\true\right>) \\
\putr(\left<\mlinl a,\mlinr 1,\mlinl b\right>,c) &=
    ((\left<a,b\right>,\left<1\right>),\left<\false,\true,\false\right>)
\end{align*}
These examples demonstrate that $\putr$ ignores the complement entirely,
fabricating a completely new one from its input. The $\putl$ function, on
the other hand, relies entirely on the complement for its ordering
information. When there are extra entries (not accounted for by the
complement), it adds them at the 
end. Consider taking the output of the second $\putr$ above and
adding $c$ to the $X$ list and $2$ to the $Y$ list:
\\[1.5ex]
\noindent\begin{tabular}{l}
$\putl((\left<a,b,c\right>,\left<1,2\right>),\left<\false,\true,\false\right>) =$ \\
\qquad$(\left<\mlinl a,\mlinr 1,\mlinl b,\mlinl c,\mlinr 2\right>,$ \\
\qquad$\left<\false,\true,\false,\false,\true\right>)$
\end{tabular}
\\[1.5ex]
\noindent The $\putl$ fills in as much of the beginning of the list as it
can, using the complement to indicate whether to draw elements from $X\LIST$
or from $Y\LIST$.  (How the remaining $X$ and $Y$ elements are interleaved
is a free choice, not specified by the lens laws, since this case only
arises when we are {\em not} in a round-tripping situation. The strategy
shown here, where all new $X$ entries precede all new $Y$ entries, is just
one possibility.)

Given $\partition$, we can obtain $\comp$ by composing three lenses in
sequence: from $(X+Y)\LIST$ we get to $X\LIST \times Y\LIST$ using
$\partition$, then to $X\LIST \times Z\LIST$ using a variant of the lens $e$ 
discussed above, and finally to $(X+Z)\LIST$ using a ``backwards''
$\partition$. 

\iffull
\paragraph*{Put-Put Laws}

Studies of asymmetric lenses sometimes consider a fourth behavioral law not
discussed above:

\infax[PutPut]{\aput(v', \aput(v, s)) = \aput(v', s)}

This law is somewhat controversial: some reasonable $\aget$
operations---such as the mapping operation that applies a transformation to
each element of a list---cannot be paired with a $\aput$ that satisfies this
law, but relying on this law allows one to optimize chains of successive
puts and strongly constrains the operation of $\aput$, preventing some
clearly unsatisfactory $\aput$ implementations. We will explore some of the
ways one might generalize of this law to the realm of symmetric lenses
below.

\begin{lemma} The following ``put the same thing twice'' laws follow from
the ones we have:
\infrule[PutR2]{\putr(x,c) = (y,c')}{\putr(x,c') = (y,c')}
\infrule[PutL2]{\putl(y,c) = (x,c')}{\putl(y,c') = (x,c')}
\end{lemma}

We could consider generalizing these to say that putting an arbitrary pair
of values, one after the other, is the same as doing just the second $\PUT$
into the first complement:
{
\typicallabel{XXXXXXX}
\infrule[Strong-PutPutR$^\ast$] {\putr(x,c)=(\_\,,c')} {\putr(x',c')=\putr(x',c)}
\infrule[Strong-PutPutL$^\ast$] {\putl(y,c)=(\_\,,c')} {\putl(y',c')=\putl(y',c)}
}
%
But these laws are very strong---probably too strong to be useful (the
$^\ast$ annotations in their names are a reminder that we do {\em not} adopt
them).  The reason is that they demand that the effect of every update is
completely undoable---not only the effect on the other \replica, but also the
effect of the first update on the complement must be completely forgotten if
we make a second update.  In particular, neither of the list-mapping lenses
in \S\ref{lists}, i.e.\ Defs.~ \ref{delala} \& \ref{dedaja}, satisfy these laws.
\fi

%% But this means we
%% cannot write some very important lenses.  For example, consider the lens
%% \[
%% \mathit{map}\, \pi_{1y} \;\in\; (X\times Y)\LIST \lens X\LIST
%% \]
%% that, from left to right, projects away all the $Y$ parts of a list of
%% $(X\times Y)$s.  This lens must be able to deal with $\putl$s that shorten
%% or lengthen the list.  For ones that lengthen the list, the lens must supply
%% a suitable $Y$.  But now the \rn{putput} laws make inconsistent demands:
%% \begin{itemize}
%% \item If one update shortens the list by one element and the next restores
%% it to its original length, the \rn{putputl} law says that the $Y$ that is
%% supplied must be the one that was there originally.  So this deleted $Y$
%% {\em must} be retained in the complement after the $\putl$ that shortens the
%% list, in case it is needed again.
%% \item On the other hand, if the first update lengthens the list by one
%% element and then shortens it again, the \rn{putputl} law says that the
%% resulting complement must the same as if we've just done the second $\putl$ ---
%% i.e., the second $\putl$ is {\em not allowed} to keep the deleted $Y$ in the
%% complement.  \PENDING{This is wrong: should be $\putr$.}
%% \end{itemize}
%% Thus, there seems to be no reasonable implementation of a list mapping lens
%% that satisfies the \rn{putputr$^\ast$} and \rn{putputl$^\ast$} laws.

\iffull
A weaker version of these laws, constraining the output but not the effect
on the complement, may be more interesting:
%
{
\typicallabel{XXXXX}
\infrule[Weak-PutPutR*] 
  {\putr(x,c)=(\_\,,c') \\ \putr(x',c)=(y,\_) \\ \putr(x',c')=(y',\_)}
  {y = y'}
\infrule[Weak-PutPutL*] 
  {\putl(y,c)=(\_\,,c') \\ \putl(y',c)=(x,\_) \\ \putl(y',c')=(x',\_)}
  {x = x'}
}
%
  We do not choose to adopt these laws here because they are not satisfied
  by the ``forgetful'' variants of our summing and list mapping lenses.
  However, the forgetful variants are mainly interesting because of
  their close connection to analogous asymmetric lenses; in practice, the
  ``retentive'' variants seem more useful, and these do satisfy the weak
  \rn{PutPut} laws.  
\fi % \iffull

\paragraph*{Alignment}\label{firstalign}

\ifdissertation
The present chapter does \emph{not} deal with the important goal of
alignment; we
\else
One important {\em non}-goal of the present paper is dealing with
the (important) issue of {\em alignment}~\cite{Boomerang07,Matching10}. We
\fi
consider only the simple case of lenses
that work ``positionally\dotquote For example, the lens $e\LIST$ in the example
will always use $e$ to propagate
changes between the first element of $x$ and the first element of $y$,
between the second element of $x$ and the second of $y$, and so on.  This
amounts to assuming that the lists are edited either by editing individual
elements in place or by adding or deleting elements at the end of the list;
if an actual edit inserts an element at the head of one of the lists,
positional alignment will produce surprising (and probably distressing)
results.
\ifdissertation
We will incorporate a richer notion of alignment in
Chapter~\ref{chap:delta}.
\else
We see two avenues for incorporating richer notions of alignment:
either we can generalize the mechanisms of {\em matching
  lenses}~\cite{Matching10} to the setting of symmetric lenses, or we can
refine the whole framework of symmetric lenses with a notion of {\em delta
propagation}; see \S\ref{sec:future}.
\fi%dissertation

\section{Equivalence}\label{equiv}

\iftext 
%% Separate complements, already in the asymmetric case, give
%% rise to a nontrivial equivalence on lenses, and we'll need to work up
%% to this equivalence in everything we do from now on.  
Since each lens carries its own complement---and since this need
not be the same as the 
complement of another lens with the same domain and codomain---we now need to
define what it means for two lenses to be indistinguishable, in the sense
that no user could ever tell the difference between them by observing just the
$X$ and $Y$ parts of their outputs.  We will use this relation pervasively
in what follows: indeed, most of the laws we would like our constructions to
validate---even things as basic as associativity of composition---will not
hold ``on the nose\commaquote but only up to equivalence. 
\fi

\iffull
\begin{defn}[$R$-similarity]
\else
\begin{defn}
\fi
Given \iffull sets \fi $X,Y,C_f,C_g$ and a relation $R \subseteq C_f \times C_g$,
we say that functions 
$f \in X \times C_f \to Y \times C_f$ and $g \in X \times C_g \to Y \times C_g$
are {\em $R$-similar}, written $f \sim_R g$, if they take equal inputs with $R$-related
complements to equal outputs with $R$-related complements:
\infrule{
    (c_f,c_g) \in R \\
    f(x,c_f) = (y_f,c_f') \\
    g(x,c_g) = (y_g,c_g')
}{
    y_f = y_g \land (c_f',c_g') \in R
}
\end{defn}

\begin{defn}[Lens equivalence]
Two lenses $k$ and $\ell$ are {\em equivalent} (written $k \equiv \ell$) if
there is a relation $R \subseteq k.C \times \ell.C$ \iffull on their complement
sets \fi with
\begin{enumerate}
    \item $(k.\missing, \ell.\missing) \in R$
    \item $k.\putr \sim_R \ell.\putr$
    \item $k.\putl \sim_R \ell.\putl$.
\end{enumerate}
We write $X \Lens Y$ for the set of equivalence classes of lenses from $X$
to $Y$.  When $\ell$ is a lens, we write $\EQCLASS{\ell}$ for the
equivalence class of $\ell$ (that is, $\ell \in X\lens Y$ iff
$\EQCLASS{\ell} \in X\Lens Y$).  Where no confusion results, we 
abuse notation and drop these brackets, using $\ell$ for both a lens and
its equivalence class.
\end{defn}

\iffull
\begin{lemma}
Lens equivalence is an equivalence relation.
\end{lemma}
\begin{proof}
Reflexivity and symmetry are obvious. We briefly sketch transitivity.
% (reflexivity) Choose an arbitrary lens $\ell \in X \lens Y$; we then must
% show $\ell\equiv\ell$. Take $R$ to be equality. It's clear that
% $(\ell.\missing,\ell.\missing) \in R$. To show that $\ell.\putr \sim_R
% \ell.\putr$, we may assume that $(c_0,c_0') \in R$, that
% $\ell.\putr(x,c_0)=(y,c_1)$, and that $\ell.\putr(x,c_0')=(y',c_1')$. We can
% then construct this chain of reasoning:
% \begin{align*}
%     (c_0,c_0') &\in R\\
%     c_0 &= c_0'\\
%     \ell.\putr(x,c_0) &= \ell.\putr(x,c_0')\\
%     (y,c_1) &= (y',c_1')\\
%     y=y' &\land c_1=c_1'\\
%     y=y' &\land (c_1,c_1') \in R
% \end{align*}
% This last line is just what we needed, so $\ell.\putr \sim_R \ell.\putr$.
% The proof that $\ell.\putl \sim_R \ell.\putl$ is similar.

% (symmetry) Suppose $k \equiv \ell$, as witnessed by $R$. Then the converse
% relation
% \[R\op=\{(c_\ell,c_k) \mid (c_k,c_\ell)\in R\}\]
% witnesses $\ell \equiv k$. Since $(k.\missing,\ell.\missing) \in R$, we
% consequently know $(\ell.\missing,k.\missing) \in R\op$. Moreover, simply
% expanding the definitions of $k.\putr \sim_R \ell.\putr$ (which we know by
% assumption) and $\ell.\putr \sim_{R\op} k.\putr$ (which we wish to show)
% makes them evidently equivalent conditions, and similarly for the pair of
% $k.\putl \sim_R \ell.\putl$ and $\ell.\putl \sim_{R\op} k.\putl$. Hence
% $\ell \equiv k$.

Suppose $k \equiv \ell$ (as witnessed by $R_{k\ell}$) and
$\ell \equiv m$ (as witnessed by $R_{\ell m}$). We show that the
relation
\[R_{km} = R_{k\ell}\circ R_{\ell m} = \{(c_k,c_m) \mid \exists c_\ell.\ c_k \relRx{k\ell} c_\ell
\land c_\ell \relRx{\ell m} c_m\}\]
witnesses the equivalence $k \equiv m$. It is clear that
\[(k.\missing,m.\missing) \in R_{km},\]
since we can choose $c_\ell = \ell.\missing$. Next, we show that $k.\putr
\sim_{R_{km}} m.\putr$. We may assume three things:
\begin{align*}
    (c_k,c_m) &\in R_{km} \\
    k.\putr(x,c_k) &= (y_k, c_k') \\
    m.\putr(x,c_m) &= (y_m, c_m')
\end{align*}
Since $(c_k,c_m) \in R_{km}$, we can choose $c_\ell$ such that $(c_k,c_\ell)
\in R_{k\ell}$ and $(c_\ell,c_m) \in R_{\ell m}$. Choosing
$(y_\ell,c_\ell')=\ell.\putr(x,c_\ell)$, we then conclude that $y_k=y_\ell$
and $(c_k',c_\ell') \in R_{k\ell}$, since $k.\putr \sim_{R_{k\ell}}
\ell.\putr$. Similarly, we can conclude that $y_\ell=y_m$ and
$(c_\ell',c_m') \in R_{\ell m}$ because $\ell.\putr \sim_{R_{\ell m}}
m.\putr$. Thus $y_k=y_m$ and because of the
existence of $c_\ell'$, we know $(c_k',c_m') \in R_{km}$. But these are
exactly the two facts we need to conclude that $k.\putr \sim_{R_{km}}
m.\putr$. A similar argument shows that $k.\putl \sim_{R_{km}} m.\putl$, and
hence that $k \equiv m$.
\end{proof}
\fi

\iffull\else We show in the long version that this definition of lens
equivalence coincides with a more ``observational'' definition where two
lenses are equivalent iff they always give the same sequence of outputs when
presented with the same sequence of inputs, starting with a $\missing$
complement.  

\fi

\iffull
\begin{defn}[Put object]
Given a lens $\ell \in X \lens Y$, define a \emph{put object} for $\ell$ to
be a member of $X + Y$. Define a function $\apply$ taking a lens, an element
of that lens' complement set, and a list of put objects as follows\iftext{}
(using ML-like syntax)\fi:
\begin{eqnarray*}
\apply(\ell,c,(\mlinl x) \CONS \mathit{puts}) &=& \mllet (y,c') = \ell.\putr(x,c) \mline \\
&& (\mlinr y) \CONS \apply(\ell,c',\mathit{puts}) \\
\apply(\ell,c,(\mlinr y) \CONS \mathit{puts}) &=& \mllet (x,c') = \ell.\putl(y,c) \mline \\
&& (\mlinl x) \CONS \apply(\ell,c',\mathit{puts}) \\
\apply(\ell,c,\NIL) &=&  \NIL
\end{eqnarray*}
\end{defn}
A put object describes one interaction with the lens. A put object of the form $\mlinl x$ is supposed to be sent through the lens using $\putr$; a put object of the form $\mlinr y$ is supposed to be sent using $\putl$. Given a sequence of such put objects the function $\apply$ sends them throught the lens one after the other updating the complements as it goes. It returns the sequence of corresponding outputs in the form of complementary put objects. 
\begin{defn}[Observational equivalence]
Lenses $k,\ell \in X \lens Y$ are \emph{observationally equivalent} (written
$k \approx \ell$) if, for every sequence of put objects $P \in (X + Y)\LIST$
we have
\[\apply(k,k.\missing,P) = \apply(\ell,\ell.\missing,P).\]
\end{defn}

\iffull
\begin{theorem}
\else
\begin{theorem}
\fi
    $k \approx \ell$ iff $k \equiv \ell$.
\end{theorem}

\begin{proof}
$(\Longleftarrow)$ Suppose that $k\equiv \ell$ via relation $R$. For all
sequences of put objects $P$, and for
elements $c \in k.C$ and $d\in \ell.C$ such that $(c,d) \in R$, we have
$\apply(k,c,P)=\apply(\ell,d,P)$. This follows by induction on the length of $P$
from the definition of $\apply$.
Thus, $k\approx \ell$ follows by specialization to $c=k.\missing$ and
$d=\ell.\missing$. 

$(\Longrightarrow)$ Now suppose $k\approx \ell$. To show $k\equiv \ell$, define $R
\subseteq k.C \times \ell.C$ by
\dissdis
R = \{(c,d) \;|\; \apply(k,c,P)=\apply(\ell,d,P) \mbox{ for all $P$}\}.
\dissdis By assumption, we have $(k.\missing, \ell.\missing) \in R$.

Now suppose that $(c,d) \in R$ and that $k.\putr(x,c)=(y,c')$ and
$\ell.\putr(x,d)=(y',d')$.  Applying the assumption $(c,d) \in R$ to the
length-one sequence $P = \CONCRETELIST{\mlinl(x)}$ shows $y=y'$. To show
$(c',d') \in R$ let $P$ be an arbitrary sequence of put objects and define
$P' = \mlinl(x) \CONS P$. The assumption $(c,d) \in R$ gives $\apply(k,c,P') =
\apply(\ell,d,P')$, hence in particular $\apply(k,c',P)=\apply(\ell,d',P)$, thus
$(c',d') \in R$. We have thus shown that $k.\putr \sim_R \ell.\putr$.
Analogously, we show that $k.\putl \sim_R \ell.\putl$, and it follows that
$k\equiv \ell$ via relation $R$.
\end{proof}
\fi

\section{Basic Constructions}\label{basic}

With the basic definitions in hand, we can start defining lenses.  We
begin in this section with several relatively simple constructions.  

% % \paragraph*{Identity and Composition}

\ifdissertation\breakifnearbottom\fi

\begin{defn}[Identity lens] Let $\Unit$ be a distinguished singleton set and
$\unit$ its only element.  
\lensdef{id}
{\id_X \in X \lens X}
{
    C &=& \Unit \\
    \missing &=& \unit \\
    \putr(x, \unit) &=& (x, \unit) \\
    \putl(x, \unit) &=& (x, \unit)
}
\end{defn}

To check that this definition is well formed, we must show that the
components defined in the lower box satisfy the round-trip laws implied by the
upper box.
\iffull
The proof is a straightforward calculation.
\else
This proof and analogous ones for later lens definitions are given in full
in the long version.
\fi

\begin{defn}[Lens composition]\
\lensdef{composition}
{\infruleplain{k \in X \lens Y \qquad \ell \in Y \lens Z}{k;\ell \in X \lens Z}}
{
    C &=& k.C \times \ell.C \\
    \missing &=& (k.\missing, \ell.\missing) \\
    \putr(x, (c_k, c_\ell))
    &=& \mllet (y, c_k') = k.\putr(x, c_k) \mline \\
    & & \mllet (z, c_\ell') = \ell.\putr(y, c_\ell) \mline \\
    & & (z, (c_k', c_\ell')) \\
    \putl(z, (c_k, c_\ell))
    &=& \mllet (y, c_\ell') = \ell.\putl(z, c_\ell) \mline \\
    & & \mllet (x, c_k') = k.\putl(y, c_k) \mline \\
    & & (x, (c_k', c_\ell'))
}
\end{defn}

\iffull
\begin{goodlens}
We show that the lens satisfies \rn{PutRL}; the proof that it satisfies
\rn{PutLR} is entirely symmetric. Assume that $k$ and $\ell$ each satisfy
\rn{PutRL}, and that $(k;\ell).\putr(x,(c_k,c_\ell))=(z,(c_k',c_\ell'))$.
From the definition of $(k;\ell).\putr$, we can conclude that there is a $y$
such that $k.\putr(x,c_k)=(y,c_k')$ and $\ell.\putr(y,c_\ell)=(z,c_\ell')$.
\ifcomplement
\begin{itemize}
    \item[]
        $(k;\ell).\putl(z,(c_k',c_\ell'))$
    \item[$=$] \{definition of $(k;\ell).\putl$\}
    \item[]
        $\mllet (y', c_\ell'') = \ell.\putl(z, c_\ell') \mlinm
         \mllet (x', c_k'') = k.\putl(y', c_k') \mlinm
         (x', (c_k'', c_\ell''))$
    \item[$=$] \{\rn{PutRL} applied to $\ell$\}
    \item[]
        $\mllet (x', c_k'') = k.\putl(y, c_k') \mlinm
         (x', (c_k'', c_\ell'))$
    \item[$=$] \{\rn{PutRL} applied to $k$\}
    \item[] $(x, (c_k', c_\ell'))$
\end{itemize}
Since this final equation is exactly what is demanded from applying
\rn{PutRL} to $k;\ell$, we are done.
\else%complement
\begin{align}
    (k;\ell).\putl(z,(c_k',c_\ell')) ={}
    & \mllet (y', c_\ell'') = \ell.\putl(z, c_\ell') \mline \label{cg:def}\\
    & \mllet (x', c_k'') = k.\putl(y', c_k') \mline \nonumber\\
    & (x', (c_k'', c_\ell'')) \nonumber\\
    ={}
    & \mllet (x', c_k'') = k.\putl(y, c_k') \mline \label{cg:computel}\\
    & (x', (c_k'', c_\ell')) \nonumber\\
    ={}
    & (x, (c_k', c_\ell')) \label{cg:computek}
\end{align}
Equation~\ref{cg:def} comes from expanding the definition of
$(k;\ell).\putl$; equation~\ref{cg:computel} from applying \rn{PutRL} to
$\ell$ and substituting let-bound variables; and equation~\ref{cg:computek}
from applying \rn{PutRL} to $k$ and again substituting let-bound variables.
Moreover, this last equation is exactly what is demanded from applying
\rn{PutRL} to $k;\ell$, so we are done.
\fi%complement
\end{goodlens}
\fi

This definition specifies what it means to compose two  lenses.
To show that this definition lifts to equivalence classes of lenses, we
need to check the following congruence property. \iffull\else We 
include the proof to give a taste of the technique; 
proofs of similar lemmas for the other operators on lenses 
defined below are deferred to the long version.\fi

\begin{lemma}[Composition preserves equivalence]\label{CPE}
If $k \equiv k'$ and $\ell \equiv \ell'$, then $k;\ell \equiv k';\ell'$.
\end{lemma}

\begin{definition}
The following function on relations is convenient here:
\[R_1 \swizzle R_2 = \{((c_1,c_2),(c_1',c_2'))\;|\;(c_1,c_1') \in R_1 \land
(c_2,c_2') \in R_2\}\]
\end{definition}

\begin{pfof}{\ref{CPE}}
  If the simulation $R_k$ witnesses $k\equiv k'$ and $R_\ell$ witnesses
  $\ell\equiv \ell'$ then it is straightforward to verify that $R = R_k
  \swizzle R_\ell$ witnesses $k;\ell \equiv k';\ell'$. There are three
  things to show.

  \begin{longenum}
      \ifboolexpr{bool{complement} and bool{full}}{
      \item Since $R_k$ and $R_\ell$ are simulation relations, we know:\\
          \phantom{$\iff$}$k.\missing \relRk k'.\missing\land\ell.\missing\relRl\ell'.\missing$\\
          $\iff$ \{definition of $R$\}\\
          \phantom{$\iff$}$(k.\missing, \ell.\missing)\relR(k'.\missing,\ell'.\missing)$\\
          $\iff$ \{definition of $k;\ell$\}\\
          \phantom{$\iff$}$(k; \ell).\missing\relR(k'; \ell').\missing$\\
          This is what we wished to show.
      }{
      \item We wish to show the first line:
          \begin{align*}
                  &(k; \ell).\missing\relR(k'; \ell').\missing \\
              \iff&(k.\missing, \ell.\missing)\relR(k'.\missing,\ell'.\missing) \\
              \iff&k.\missing \relRk k'.\missing\land\ell.\missing\relRl\ell'.\missing
          \end{align*}
          But the final line is certainly true, since $R_k$ and $R_\ell$ are
          simulation relations.
      }

      \item We must show that $(k;\ell).\putr\sim_R(k';\ell').\putr$. So
          take $c_k,c_\ell,c_{k'},c_{\ell'}$ such that
          $(c_k,c_\ell)\relR(c_{k'},c_{\ell'})$ and choose an input $x$.
          Define the following:
          \begin{align*}
              (y,c_k') &= k.\putr(x,c_k) \\
              (z,c_\ell') &= \ell.\putr(y,c_\ell) \\
              (y',c_{k'}') &= k'.\putr(x,c_{k'}) \\
              (z',c_{\ell'}') &= \ell'.\putr(y',c_{\ell'})
          \end{align*}
          We can then compute:
          \begin{align*}
              (k;\ell).\putr(x,(c_k,c_\ell)) &= (z,(c_k',c_\ell')) \\
              (k';\ell').\putr(x,(c_{k'},c_{\ell'})) &= (z',(c_{k'}',c_{\ell'}'))
          \end{align*}
          We need to show that $z = z'$ and that
          $(c_k',c_\ell')\relR(c_{k'}',c_{\ell'}')$.  Since
          $c_k \relRk c_{k'}$, we can conclude that $y = y'$ and
          $c_k' \relRk c_{k'}'$; similarly, since
          $c_\ell \relRl c_{\ell'}$ and $y = y'$, we know that $z =
          z'$ (discharging one of our two proof burdens) and
          $c_\ell' \relRl c_{\ell'}'$. Combining the above facts, we
          find that $(c_k',c_\ell')\relR(c_{k'}',c_{\ell'}')$ by definition
          of $R$ (discharging the other proof burden).

      \item The proof that $(k;\ell).\putl\sim_R(k';\ell').\putl$ is
          similar to the $\putr$ case.\endofpf
  \end{longenum}
\end{pfof}

\begin{lemma}[Associativity of composition]
\displayifspace{
j;(k;\ell) \equiv (j;k);\ell \iffull\else.\fi}
%
(The equivalence is crucial here: $j;(k;\ell)$ and $(j;k);\ell$ are not
the same lens because their complements are structured differently.)
\end{lemma}


\iffull
\begin{proof}
We define a witnessing simulation relation $R$ by
\[
\relR = \{((c_1,(c_2,c_3)), ((c_1,c_2),c_3))\mid  c_1\in j.C, c_2\in k.C, c_3\in \ell.C\}.
\]
The verification is then straightforward.
% \begin{align*}
%     (j;(k;\ell)).\missing &= (j.\missing,(k.\missing,\ell.\missing)) \\
%     &\relR ((j.\missing,k.\missing),\ell.\missing) \\
%     &= ((j;k);\ell).\missing
% \end{align*}
% To complete the proof, we must show that $(j;(k;\ell)).\putr \sim_R
% ((j;k);\ell).\putr$ and that $(j;(k;\ell)).\putl \sim_R ((j;k);\ell).\putl$.
% The proofs of these are similar enough that we will show only the former.
%
% Choose arbitrary $x,c_j,c_k,c_\ell$ and define:
% \begin{align*}
%     (y,c_j') &= j.\putr(x,c_j) \\
%     (z,c_k') &= k.\putr(y,c_k) \\
%     (w,c_\ell') &= \ell.\putr(z,c_\ell)
% \end{align*}
% Then we can compute
% \begin{align*}
%     ((j;k);\ell).\putr(x,((c_j,c_k),c_\ell)) &= (w,((c_j',c_k'),c_\ell')) \\
%     (j;(k;\ell)).\putr(x,(c_j,(c_k,c_\ell))) &= (w,(c_j',(c_k',c_\ell')))
% \end{align*}
% by simply tracing through the definition of lens composition and plugging in
% the defined values for $j.\putr$, $k.\putr$, and $\ell.\putr$ above. But
% these two equations show exactly what we need, since $w=w$ and:
% \[((c_j',c_k'),c_\ell') \relR (c_j',(c_k',c_\ell'))\]
\end{proof}
\fi

\begin{lemma}[Identity arrows]
\iftext The identity lens is a left and right identity for composition: \fi
\displayifspace{\id_X;\ell \equiv \ell;\id_Y \equiv \ell\iffull\else.\fi}
%% \iftext
%% (Again, note that this is not true at the level of lenses, only equivalence
%% classes\iffull{} of lenses\fi.)
%% \fi
\end{lemma}

\iffull
\begin{proof}
For left identity we use the simulation relation $R$ given by $(\unit,c)
\relR c$ whenever $c\in \ell.C$. The verification is direct. 
% It's clear that
% \[(\id;\ell).\missing=(\unit,\ell.\missing)\relR\ell.\missing.\]
% To show that $(\id;\ell).\putr \sim_R \ell.\putr$, consider:
% \begin{align*}
%     (\id;\ell).\putr(x,(\unit,c)) ={}
%     & \mllet (x', c') = \id.\putr(x,\unit) \mline \\
%     & \mllet (y, c'') = \ell.\putr(x',c) \mline \\
%     & (y,(c',c'')) \\
%     ={}
%     & \mllet (y, c'') = \ell.\putr(x,c) \mline \\
%     & (y,(\unit,c''))
% \end{align*}
% But this shows that the output of $(\id;\ell).\putr$ matches the output of
% $\ell.\putr$, and that if the input states were related, then the output
% states will be related, too. So $(\id;\ell).\putr \sim_R \ell.\putr$.
% Similarly, to show that $(\id;\ell).\putl \sim_R \ell.\putl$, consider:
% \begin{align*}
%     (\id;\ell).\putl(y,(\unit,c)) ={}
%     & \mllet (x, c') = \ell.\putl(y, c) \mline \\
%     & \mllet (x', c'') = \id.\putl(x, \unit) \mline \\
%     & (x', (c'', c')) \\
%     ={}
%     & \mllet (x, c') = \ell.\putl(y, c) \mline \\
%     & (x, (\unit, c'))
% \end{align*}
% Thus, the output of $(\id;\ell).\putl$ matches the output of $\ell.\putl$,
% and the output states will be related whenever the input ones were. So
% $\id;\ell \equiv \ell$.

The proof of the right-identity law $\ell;\id \equiv \ell$ is analogous.
\end{proof}
\fi

Thus symmetric lenses form a category, \LENS, with sets as objects and
equivalence classes of lenses as arrows.  The identity arrow for a set
$X$ is 
$\EQCLASS{\id_X}$. Composition is $\EQCLASS{k};\EQCLASS{\ell} =
\EQCLASS{k;\ell}$.  

% \paragraph*{Bijections}
\begin{prop}[Bijective lenses]
\iffull Every bijective function gives rise to a lens: \else \ \fi
\lensdef{bijection}
{\infruleplain{f \in X \to Y \andalso \mbox{$f$ bijective}}{\bij_f \in X
    \lens Y}} 
{
    C &=& \Unit \\
    \missing &=& \unit \\
    \putr(x, \unit) &=& (f(x), \unit) \\
    \putl(y, \unit) &=& (f^{-1}(y), \unit)
}
\end{prop}
\ifdissertation
(If we were implementing a bidirectional language, we might not want to
expose $\bij$ in its syntax, since we would then need to offer
\else
(If we were designing {\em syntax} for a bidirectional language, we
might not want to include $\bij$, since we would then need to offer
\fi
programmers some notation for writing down bijections in such a way that we
can verify that they {\em are} bijections and derive their inverses.
However, even if it doesn't appear in the surface syntax, we will see
several places where $\bij$ is useful in talking about the algebraic theory
of symmetric lenses.)

\iffull
\begin{goodlens}
    We verify that the \rn{PutRL} law holds for bijection lenses; the proof
    that \rn{PutLR} holds is symmetric. Observe that
    $\bij_f.\putr(x,\unit)=(f(x),\unit)$. We can therefore compute that
    $\bij_f.\putl(f(x),\unit)=(f^{-1}(f(x)),\unit)=(x,\unit)$. Thus, after a
    round-trip, we return to the same $x$ we started from---and the same
    complement, $\unit$, validating the law.
\end{goodlens}

In fact, any stateless lens, i.e., a lens with trivial complement, is
an instance of a bijection lens:
\begin{lemma}
If $\ell \in X \lens Y$ and $h \in \ell.C \to \Unit$ is a bijection, then
there exists a bijection $f \in X \to Y$ such that $\ell \equiv \bij_f$.
\label{trivial_complement_bijection}
\end{lemma}

\begin{proof}
We define:
\[f(x) = \mlfst(\ell.\putr(x,h^{-1}(\unit)))\]
We must show that $f$ is bijective and that $\bij_f \equiv \ell$. For the
former, we exhibit its inverse in $g$:
\[g(y) = \mlfst(\ell.\putl(y,h^{-1}(\unit)))\]
The round-trip law \rn{PutRL} guarantees that $g(f(x))=x$, and the
round-trip law \rn{PutLR} guarantees that $f(g(y))=y$.

To show the latter, we argue that $h$ witnesses the equivalence. Clearly
\dissdis
h(\bij_f.\missing) = \ell.\missing
\dissdis
because all elements of $\ell.C$ are
equal (and hence $(\bij_f.\missing,\ell.\missing) \in h$). The definition of
$f$ makes it clear that $\bij_f.\putr \sim_h \ell.\putr$; similarly, the
definition of $f$'s inverse $g$ makes it clear that $\bij_f.\putl \sim_h
\ell.\putl$.
\end{proof}

\begin{corollary}
If $\ell.C$ is a singleton set $\{c\}$ and $\mlfst(\ell.\putr(x,c))=x$ for all
$x$, then $\ell \equiv \id$.
\label{singleton_id}
\end{corollary}
\fi

This transformation (like several others we will see) respects much of the
structure 
available in our category. Formally, $\mathit{bij}$ is a functor.  Recall
that
a {\em covariant} (respectively, {\em contravariant}) {\em functor} between
categories \catC 
and \catD is a pair of maps---one from objects of \catC to objects of \catD
and the other from arrows of \catC to arrows of \catD---that preserve
typing, identities, and composition:
\begin{itemize}
    \item The image of any arrow $f : X \to Y$ in \catC has the
        type $F(f) : F(X) \to F(Y)$ (respectively, $F(f) : F(Y) \to F(X)$)
        in \catD.
    \item For every object $X$ in \catC, we have $F(\id_X) = \id_{F(X)}$ in \catD.
    \item If $f;g = h$ in \catC, then $F(f);F(g) = F(h)$
        (respectively, $F(g);F(f) = F(h)$) in \catD.
\end{itemize}
Covariant functors are simply called functors. When it can be inferred
from the arrow mapping, the object mapping is often elided.

\iffull
\begin{lemma}[Embedding bijections]
\else
\begin{lemma}
\fi
The $\mathit{bij}$ operator forms a functor from the category {\sc iso},
whose objects 
are sets and whose arrows are isomorphic functions, to \LENS{}---that is,
$\bij_{\id_X} = \id_X$ and $\bij_f;\bij_g = \bij_{f; g}$. 

\iffull
\begin{proof}
Showing that $\bij_{\id_X}=\id_X$ is a straightforward application of
Corollary~\ref{singleton_id}. Now consider $\bij_f;\bij_g$.  Since its
complement is a singleton set, Lemma~\ref{trivial_complement_bijection}
tells us that $\bij_f;\bij_g \equiv \bij_h$, where
\[h(x) = \mlfst((\bij_f;\bij_g).\putr(x,(\unit,\unit))),\]
which can be reduced to:
\[h(x) = g(f(x))\]
Thus $\bij_f;\bij_g \equiv \bij_{f;g}$ as desired.
\end{proof}
\fi
\end{lemma}

\iffull Since functors preserve isomorphisms it follows that bijective
lenses are isomorphisms in the category of lenses. However, not every
isomorphism in \LENS{} is of that form. This is because a bijective
lens displays no dependency on the complement at all, whereas an
isomorphism in the category of lenses still allows for some limited
interaction with the complement as in the following counterexample.

Define the set $\Trit=\{-1,0,1\}$ and the function $f \in
\Trit \times \Trit \to \Trit$ which returns its arguments if they are equal
and the third possible value if they are not:
\begin{center}\begin{tabular}{rrr}
    $c$ & $x$ & $f(c,x)$ \\
    \hline
    $-1$ & $-1$ & $-1$ \\
    $-1$ & $ 0$ & $ 1$ \\
    $-1$ & $ 1$ & $ 0$ \\
    $ 0$ & $-1$ & $ 1$ \\
    $ 0$ & $ 0$ & $ 0$ \\
    $ 0$ & $ 1$ & $-1$ \\
    $ 1$ & $-1$ & $ 0$ \\
    $ 1$ & $ 0$ & $-1$ \\
    $ 1$ & $ 1$ & $ 1$
\end{tabular}\end{center}
For any particular $c$, the partial application $f(c)$ is a bijection and an
involution. Thus, we can define the following lens, which is its own
inverse but is not equivalent to any bijective lens:
\lensdef{strange_iso}
{\mathit{strange} \in \Trit \lens \Trit}
{
C &=& \Unit + \Trit \\
\missing &=& \mlinl\unit \\
\putr(x,\mlinl\unit) &=& (x,\mlinr x) \\
\putr(x,\mlinr c) &=& (f(c,x),\mlinr c) \\
\putl(x,\mlinl\unit) &=& (x,\mlinr x) \\
\putl(x,\mlinr c) &=& (f(c,x),\mlinr c)
}

We can show, however, that the $\putr$ and $\putl$ functions of any
invertible lens induce a bijection between the two \replicas for any pair of
reachable complements.  More precisely:

\begin{lemma}
Suppose we have lenses $k \in X \lens Y$ and $\ell \in Y \lens X$ such that
$k;\ell \equiv \id_X$ and $\ell;k \equiv \id_Y$. Then there is a relation
$R \subseteq k.C \times \ell.C$ satisfying the following conditions:
\infax[1]{(k;\ell).\missing \in R}
\infrule[2]
    {(k;\ell).\putr(x,c) = (x',c') \andalso c \in R}
    {x' = x \land c' \in R}
\infrule[3]
    {(k;\ell).\putl(x,c) = (x',c') \andalso c \in R}
    {x' = x \land c' \in R}
\infrule[4]
    {(\ell;k).\putr(y,c) = (y',c') \andalso \gamma^\times(c) \in R}
    {y' = y \land \gamma^\times(c') \in R}
\infrule[5]
    {(\ell;k).\putl(y,c) = (y',c') \andalso \gamma^\times(c) \in R}
    {y' = y \land \gamma^\times(c') \in R}
Here, the function $\gamma^\times$ is the symmetry in \SET{}, namely
$\gamma^\times((x,y))=(y,x)$.

\begin{proof}
We get an $R_1$ that satisfies \rn1-\rn3 from the fact that
$k;\ell\equiv\id_X$, and we get an $R_2$ that satisfies \rn1, \rn4, and \rn5
from the fact that $\ell;k\equiv\id_Y$. Then we can define $R=R_1 \cap R_2$.
There are four conditions to check, but we will consider only one of them
here, as the others are very similar:
\infrule
    {(k;\ell).\putr(x,c)=(x',c') \andalso c \in R}
    {c' \in R_2}

Now $c \in R$ means $c=(c_k,c_\ell)$ where
$c_k\relRx 1c_\ell$ and $c_k\relRx 2c_\ell$. We can define
\begin{eqnarray*}
    (y,c_k') &=& k.\putr(x,c_k) \\
    (x',c_\ell') &=& \ell.\putr(y,c_\ell).
\end{eqnarray*}
Since $R_1$ satisfies \rn2, we know $x'=x$, that is, we know
\begin{eqnarray*}
    \ell.\putr(y,c_\ell) &=& (x,c_\ell') \\
    k.\putr(x,c_k) &=& (y,c_k').
\end{eqnarray*}
Now the fact that $R_2$ satisfies \rn4 above tells us that
$c_k'\relRx 2c_\ell'$, that is, $c' \in R_2$.
\end{proof}
\end{lemma}

\begin{corollary}[\ifdissertation\spaceskip 5.5pt\fi Isomorphisms are indexed bijections]
Consider the functions $f$ and $g$ which give the value-only part of a lens'
puts:
\begin{eqnarray*}
    f_{\ell,c_\ell}(x) &=& \mlfst(\ell.\putr(x,c_\ell)) \\
    g_{\ell,c_\ell}(x) &=& \mlfst(\ell.\putl(x,c_\ell))
\end{eqnarray*}
If $c_k \relR c_\ell$ (using the $R$ given by the previous lemma), then
$f_{k,c_k}$, $f_{\ell,c_\ell}$, $g_{k,c_k}$, and $g_{\ell,c_\ell}$ are all
bijections.

\begin{proof}
For any $x \in X$, we know $f_{\ell,c_\ell}(f_{k,c_k}(x))=x$ by \rn2, and
for any $y \in Y$, we know $f_{k,c_k}(f_{\ell,c_\ell}(y))=y$ by \rn4. Thus,
not only is $f_{k,c_k}$ a bijection, we actually have its inverse:
$f_{k,c_k}^{-1}=f_{\ell,c_\ell}$! Similarly,
$g_{k,c_k}^{-1}=g_{\ell,c_\ell}$.
\end{proof}
\end{corollary}
\fi

% \paragraph*{Duals}

\begin{defn}[Dual of a lens]\ 
\lensdef{dual}
{\infruleplain{\ell \in X \lens Y}{\ell\op \in Y \lens X}}
{
    C &=& \ell.C \\
    \missing &=& \ell.\missing \\
    \putr(y, c) &=& \ell.\putl(y, c) \\
    \putl(x, c) &=& \ell.\putr(x, c)
}
\end{defn}

\iffull
\begin{goodlens}
We observe that saying $\ell\op$ satisfies \rn{PutRL} is an identical
condition to saying $\ell$ satisfies \rn{PutLR}, and likewise having
$\ell\op$ satisfy \rn{PutLR} is identical to having $\ell$ satisfy
\rn{PutRL}.
\end{goodlens}
\fi

It is easy to see that $(-)\op$ is involutive---that is, that $(\ell\op)\op
= \ell$ for every $\ell$---and that $\bij_{f^{-1}} = \bij_f\op$ for any
bijective $f$. Recalling that an endofunctor is a functor whose source and
target categories are identical, we can easily show the following lemma.

\begin{lemma}
The $(-)\op$ operation can be lifted to a contravariant endofunctor on the
category \LENS{}, mapping each arrow
$\EQCLASS{\ell}$ to $\EQCLASS{\ell\op}$. 
\end{lemma}

\ifdissertation\breakifnearbottom\fi

\begin{proof}
We must show three things:
\begin{enumerate}
    \item The mapping $\EQCLASS\ell \mapsto \EQCLASS{\ell\op}$ is
        well-defined, that is, that if $k \equiv \ell$, then $k\op \equiv
        \ell\op$.
    \item The mapping respects identities, that is, that $\id\op \equiv
        \id$.
    \item The mapping respects composition, that is, $(k;\ell)\op \equiv
        \ell\op;k\op$.
\end{enumerate}
We sketch the proofs in that order. 
\begin{enumerate}
    \item If $k \equiv \ell$ is witnessed by $R$ then $k\op \equiv
        \ell\op$ is also witnessed by $R$; 
% , since we have the following three
%         facts:
%         \[k\op.\missing = k.\missing \relR \ell.\missing =
%         \ell\op.\missing\]
%         \[k\op.\putr = k.\putl \sim_R \ell.\putl = \ell\op.\putr\]
%         \[k\op.\putl = k.\putr \sim_R \ell.\putr = \ell\op.\putl\]
    \item In fact, $\id\op = \id$; \ifdissertation and \fi
    \item The relation $(c_k,c_\ell) \relR (c_\ell,c_k)$ whenever $c_k \in
        k.C$ and $c_\ell \in \ell.C$ witnesses the equivalence.
        \ifdissertation\endofpf\fi


% We observe
%         that:
%         \begin{align*}
%             (k;\ell)\op.\missing
%             &= (k.\missing,\ell.\missing) \\
%             &\relR (\ell.\missing,k.\missing) \\
%             &= (\ell\op;k\op).\missing
%         \end{align*}

%         To show that $(k;\ell)\op.\putr \sim_R (\ell\op;k\op).\putr$,
%         consider arbitrary $c_k,c_\ell,z$ and set
%         $(y,c_\ell')=\ell.\putl(x,c_\ell)$ and $(x,c_k')=k.\putl(y,c_k)$.
%         Then we can compute
%         \begin{align*}
%             (k;\ell)\op.\putr(z,(c_k,c_\ell)) &= (x, (c_k', c_\ell')) \\
%             (\ell\op;k\op).\putr(z,(c_\ell,c_k)) &= (x, (c_\ell', c_k')),
%         \end{align*}
%         which shows the desired relationship. Showing that
%         $(k;\ell)\op.\putl \sim_R (\ell\op;k\op).\putl$ is similar.
\end{enumerate}
\end{proof}

\ifdissertation
The existence of $(-)\op$ is one of the two canonical constructions that
motivate the name ``symmetric lenses'' (the other being $\disconnect$, which
we discuss below). Before we formalize this intuition, we review two
standard constructions from category theory.
\begin{definition}
    The \emph{opposite} of a category $\catC$, denoted $\catC\op$, has
    backwards composition compared to $\catC$. That is, whenever $f;g=h$ in
    $\catC$, we have $g;f=h$ in $\catC\op$. This induces the remaining
    components of $\catC\op$:
    \begin{description}
        \item[Objects] The objects of $\catC\op$ are exactly the objects of
            $\catC$.
        \item[Arrows] The arrows $f : X \to Y$ of $\catC\op$ are the arrows
            $f : Y \to X$ of $\catC$.
        \item[Identities] The identities of $\catC\op$ are exactly the
            identities of $\catC$.
    \end{description}
\end{definition}
That is, forming the opposite of a category means formally reversing the
``direction'' of each arrow. In general, a category and its opposite can
have very different structure. What we want to show is that the
directionality of arrows in \LENS is not important; we can formalize this by
saying that \LENS and \LENSop have the same structure, provided we can
formalize what it means for two categories have the same structure. There
are many ways to define equivalence between categories; a particularly
strong one is to apply the standard categorical notion of isomorphism to
\CAT, the category whose objects are categories and whose arrows are
functors. That is:
\begin{definition}
    Categories \catC and \catD are \emph{isomorphic} if there are functors
    $F : \catC \to \catD$ and $G : \catD \to \catC$ for which $F;G$ is the
    identity on \catC and $G;F$ is the identity on \catD.
\end{definition}
\fi%dissertation

\begin{corollary}\label{self_duality}
The category \LENS is self dual, i.e., \ifdissertation isomorphic to
\LENSop. \else equivalent to its own opposite. \fi (Note that this does not
mean that each arrow is its own inverse!)
\end{corollary}
\begin{pf}
The arrow part of $(-)\op$ is bijective.
\end{pf}
\iflater\finish(Is there  some relation with CPS calculi, symmetric
lambda-calculus, sequent calculus, etc.?)  \fi

The lenses we have discussed so far maintain all the information
in the domain and codomain. It is sometimes useful to discard some
information in one direction of the lens. The terminal lens does this,
recording the discarded information in the complement so that the other
direction of the lens can restore it.

\begin{defn}[Terminal lens]\ 
\lensdef{const}
{\infruleplain{x \in X}{\const_x \in X \lens \Unit}}
{
    C &=& X \\
    \missing &=& x \\
    \putr(x',c) &=& (\unit,x') \\
    \putl(\unit,c) &=& (c,c)
}
\end{defn}

\iffull
\begin{goodlens}
The \rn{PutLR} law is trivially true, since
\[\putr(\putl(\unit,c))=\putr(c,c)=(\unit,c)\]
and in particular since $c$ does not change at all in this round trip. We
also observe:
\[\putl(\putr(x,c))=\putl(\unit,x)=(x,x)\]
Since the complement $x$ does not change during the $\putl$ and we arrive
back at the value $x$ that we started with, this verifies that \rn{PutRL}
holds as well.
\end{goodlens}
\fi

\begin{prop}[Uniqueness of terminal lens]\label{conuni}
Lenses with the same type as a terminal lens are equivalent to a terminal
lens. More precisely, suppose $k \in X \lens \Unit$ and $k.\putl(\unit,
k.\missing) = (x, c)$ for some $c$. Then $k \equiv \const_{x}$.
\end{prop}

Of course, there may be many (pairwise non-equivalent) terminal lenses of a
particular type; for any two $x,y\in X$ with $x \ne y$, it's clear that
$\const_x \not\equiv \const_y$. Proposition~\ref{conuni} tells us 
that there are exactly as many arrows $\ell : X \lens \Unit$ as there are
elements of $X$.

\iffull
\begin{proof}
The behavior of $k$ is uniquely defined by the given data: $\putl$ must
return $x$ the first time and echo the last $\putr$ henceforth. Formally, we
may define a simulation relation as follows:
\[
R = \{(c,y)\mid \mlfst(k.\putl(\unit,c))=y\}
\]
It's clear that $k.\missing \relR x$, since we have chosen $x$ specifically
so that \dissdis\mlfst(k.\putl(\unit,k.\missing))=x.\dissdis

Let us show next that $k.\putl \sim_R \const_x.\putl$. Choose arbitrary
$v\in\Unit$ and choose $c$ and $y$ such that $\mlfst(k.\putl(\unit,c))=y$.
Clearly,
$v=\unit$, so we can compute:
\begin{align*}
    k.\putl(v,c) = k.\putl(\unit,c) &= (y,c') \\
    \const_x.\putl(v,y) = \const_x.\putl(\unit,y) &= (y,y)
\end{align*}
Clearly, $y=y$, and law \rn{PutL2} tells us that $k.\putl(\unit,c')=(y,c')$,
and hence that $c' \relR y$.

Finally, we must show that $k.\putr \sim_R \const_x.\putr$. Again, choose
$c$ and $y$ such that $\mlfst(k.\putl(\unit,c))=y$ and arbitrary $z \in X$.
\begin{align*}
    k.\putr(z,c) &= (\unit,c') \\
    \const_x.\putr(z,y) &= (\unit,z)
\end{align*}
It's clear that $\unit=\unit$, and law \rn{PutRL} tells us that
$k.\putl(\unit,c') = (z,c')$, and hence $c' \relR z$.
\end{proof}
\fi

\iffull\ifdissertation\else\clearpage\fi\fi

\begin{defn}[Disconnect lens]\ 
\lensdef{disconnect}
{\infruleplain{x \in X \qquad y \in Y}{\disconnect_{xy} \in X \lens Y}}
{\disconnect_{xy} &=& \const_x;\const_y\op}
The disconnect lens does not synchronize its two sides at all. The
complement, $\disconnect.C$, is $X \times Y$; inputs are squirreled away into
one side of the complement, and outputs are retrieved
from the other side of the complement.
\end{defn}

\iffull (Note that we do not need an explicit proof that $\disconnect$ is a
lens: this follows from the fact that $\const$ is a lens and $(-)\op$ and
$;$ construct lenses from lenses.)  \fi

\iflater
(\PENDING{symmetric.v says ``Is \LENS{} therefore a monoid?''})
\fi

\section{Products}\label{prod}

A few additional notions from elementary category theory will be useful for
\ifdissertation generating \else giving us \fi
ideas about what sorts of properties to look for and for
structuring the discussion of which of these properties hold and which fail
for lenses.

The \emph{categorical product} of two objects $X$ and $Y$ is an object
$X\times Y$ and arrows $\pi_1:X\times Y\rightarrow X$
and $\pi_2:X\times Y\rightarrow Y$ such that for any two arrows $f :
Z\rightarrow X$ and $g:Z\rightarrow Y$ there is a unique arrow
$\langle f,g\rangle:Z\rightarrow X\times Y$---the {\em pairing} of $f$ and
$g$---satisfying $\langle f,g\rangle;\pi_1=f$ and $\langle
f,g\rangle;\pi_2=g$. It is well known that, if a categorical product
exists at all, it is unique up to isomorphism.
%
If a category \catC has a product for each pair of objects, we say that
\catC has products.

\iffull
\begin{theorem}[No products]\label{noprod}
\else
\begin{theorem}\label{noprod}
\fi
  \LENS{} does not have products.
\end{theorem}
{\bf Proof idea:} Suppose we have lenses $k \in Z \Lens X$ and $\ell \in Z
\Lens Y$. Informally, the lens $k$ includes a way to take any $Z$ and choose
a corresponding $X$ and a way to take any $X$ and find a corresponding $Z$.
Many common categories with products include the former, but the latter is
somewhat unique to lens categories, so we focus on the return trip here.

The lenses $k$ and $\ell$ together mean we have a way to take any $X$ and
choose a
corresponding $Z$, and we have a (separate) way to take any $Y$ and choose a
corresponding $Z$. Assume temporarily that the object part of the product of
two objects is simply the Cartesian product. To complete the product, we
must construct $\left<k,\ell\right> \in Z \Lens X \times Y$, that is, we
must find a way to take an $X$ and a $Y$ and choose a $Z$ that
corresponds to both simultaneously. But there may not be any such $Z$---the
$Z$ that $k$ gives us from $X$ may not be the same as the $Z$ that $\ell$
gives us from $Y$.

To complete the proof, we simply choose $X$ and $Y$ carefully to rule out
the possibility of a corresponding $Z$, regardless of whether we choose $X
\times Y$ to be the Cartesian product or to be some other construction.

\begin{proof}
Uniqueness of pairing shows that there is exactly one lens from $\Unit$ to
$\Unit\times \Unit$ (whatever this may be). Combined with Prop.~\ref{conuni}
this shows that $\Unit\times \Unit$ is a one-element set. Again by Prop.~\ref{conuni} 
this then means that lenses 
between $\Unit\times\Unit$ and any other set $X$ are constant which leads to cardinality clashes once $|X|>1$. 
\iffull 

In more detail: 
  Assume, for a contradiction, that \LENS{} does have products, and let $W$
  be the 
  product of $\Unit$ with itself. The two projections are maps into
  $\Unit$. By Proposition~\ref{conuni} there is exactly one lens from
  $\Unit$ to $\Unit$. By uniqueness of pairing we can then conclude
  that there is exactly one map from $\Unit$ to $W$. Now for each
  $w\in W$ the lens $(\const_w)\op$ is such a map, whence $W$ must be a
  singleton set, and we can without loss of generality assume
  $W=\Unit$.  But now consider the pairing of $\const_{0}$ and
  $\const_{1}$ from $\{0,1\}$ to $\Unit$. Their pairing is a lens from
  $\{0,1\}$ to $W=\Unit$, hence itself of the form $\const_x$ for some
  $x\in\{0,1\}$. But each of these violate the naturality laws.
%
\else
(A more detailed proof
appears in the full paper.)
\fi
\end{proof}

However, \LENS{} \emph{does} have a similar (but weaker) structure: a
\emph{tensor product}---i.e., an associative, two-argument functor.
For
any two objects $X$ and $Y$, we have an object $X\otimes Y$, and for any two
arrows $f : A\rightarrow X$ and $g : B \rightarrow Y$, an arrow
$f\otimes g : A \otimes B \rightarrow X \otimes Y$ such that
$(f_1;f_2)\otimes (g_1;g_2) = (f_1 \otimes g_1) ; (f_2 \otimes g_2)$ and
$\id_X \otimes \id_Y = \id_{X \otimes Y}$. Furthermore, for any three objects
$X,Y,Z$ there is a natural isomorphism $\alpha_{X,Y,Z} : (X \otimes Y)
\otimes Z \to X \otimes (Y \otimes Z)$ satisfying certain coherence
conditions (which specify that all ways of re-associating
a quadruple are equal).

% do we need to define ``natural transformation'', or not? I think maybe
% it's okay not to, as long as we explain what it means for a thing to be a
% natural transformation each time we introduce one
A categorical product is always a tensor product (by defining $f \otimes g =
\left<\pi_1 ; f,\pi_2 ; g\right>$), and conversely a tensor product is a
categorical product if there are natural transformations $\pi_1,\pi_2,\diag$
\[
\begin{array}{r@{\;\in\;}l}
\pi_{1,X,Y} & X \otimes Y \to X \\
\pi_{2,X,Y} & X \otimes Y \to Y \\
\diag_{X}   & X \to X \otimes X
\end{array}
\]
such that (suppressing subscripts to reduce clutter)
\iffull
\setcounter{equation}{0}
% the above command should probably go both in the full and not-full
% version, but let's not rewrite history -- we didn't make this change
% before the submission deadline for the conference version
\begin{eqnarray}
(f \otimes g) ; \pi_1 &=& \pi_1 ; f \label{beta_1}\\
(f \otimes g) ; \pi_2 &=& \pi_2 ; g \label{beta_2}\\
\diag ; (f \otimes f) &=& f ; \diag \label{beta_3}
\end{eqnarray}
\else
\begin{eqnarray}
(f \otimes g) ; \pi_1 &=& \pi_1 ; f \label{beta_1}\\
(f \otimes g) ; \pi_2 &=& \pi_2 ; g \label{beta_2}\\
\diag ; (f \otimes f) &=& f ; \diag \label{beta_3}\\
\diag ; \pi_1 &=& \id \\
\diag ; \pi_2 &=& \id \\
\diag ; (\pi_1 \otimes \pi_2) &=& \id 
\end{eqnarray}
\fi
for all arrows $f$ and $g$.
%
\iffull
Moreover, the following diagrams must commute, in the sense that composite
arrows with the same endpoints represent equal arrows:
\begin{center}
\tikz \draw[node distance=8em]
    node                (prod)  {$X \otimes X$}
    node[right of=prod] (right) {$X$}
        edge[<-] node[below] {$\pi_{2}$} (prod)
    node[left of=prod]  (left)  {$X$}
        edge[<-] node[below] {$\pi_{1}$} (prod)
    node[above=3.5em of prod] (bool) {$X$}
        edge[->] node[left=1em,near start]  {$\id$}  (left)
        edge[->] node[right=1em,near start] {$\id$} (right)
        edge[->] node[right] {$\diag$} (prod)
    ;

\medskip

\tikz \draw[node distance=11em]
    node                (prod)  {$X \otimes Y$}
    node[right of=prod] (right) {$(X \otimes Y)\otimes(X \otimes Y)$}
        edge[<-] node[above] {$\diag$} (prod)
    node[below=3.5 em of right] (bool) {$X\otimes Y$}
        edge[<-] node[right]  {$\pi_1 \otimes \pi_2$}  (right)
        edge[<-] node[left=1em]  {$\id$}  (prod)
    ;
\end{center}
The former diagram says that the result of applying $\diag$ is an element
whose components are both equal to the original. The latter diagram says
that the application of $\diag$ results in independent copies of the
original.
\fi % full
%
\iffull
See Proposition~13 in~\cite{AbrTze09} for a proof that these conditions are
equivalent to the standard presentation of products in terms of universal
properties.
\else
Building a categorical product from a tensor product is not the most
familiar presentation, but it can be shown to be equivalent
(see Proposition~13 in~\cite{AbrTze09}, for example).  
\fi

In the category \LENS{}, we can build a tensor product and can also build
projection lenses with reasonable behaviors.  However, these projections are
not quite natural transformations---laws \ref{beta_1} and \ref{beta_2}
above hold only with an additional indexing constraint
for particular $f$ and $g$. More seriously, while it seems we can define some
reasonable natural transformations with the type of $\diag$ (that is, arrows
satisfying law \ref{beta_3}), none of them
\iffull make the additional diagrams commute.
\else satisfy the final three laws.
\fi

\breakifnearbottom
\begin{defn}[Tensor product lens]\ 
\lensdef{product}
{
    \infruleplain
        {k \in X \lens Z \qquad \ell \in Y \lens W}
        {k \otimes \ell \in X \times Y \lens Z \times W}
}
{
    C &=& k.C \times \ell.C \\
    \missing &=& (k.\missing, \ell.\missing) \\
    \putr((x, y), (c_k, c_\ell))
    &=& \mllet (z, c_k') = k.\putr(x, c_k) \mline \\
    & & \mllet (w, c_\ell') = \ell.\putr(y, c_\ell) \mline \\
    & & ((z, w), (c_k', c_\ell')) \\
    \putl((z, w), (c_k, c_\ell))
    &=& \mllet (x, c_k') = k.\putl(z, c_k) \mline \\
    & & \mllet (y, c_\ell') = \ell.\putl(w, c_\ell) \mline \\
    & & ((x, y), (c_k', c_\ell'))
}
\end{defn}
\iffull

\begin{goodlens}
We will show that \rn{PutRL} holds; a similar argument shows that \rn{PutLR}
holds. Suppose
\begin{align*}
k.\putr(x,c_k)&=(z,c_k') \\
\ell.\putr(y,c_\ell)&=(w,c_\ell')
\end{align*}
so that:
\[(k \otimes \ell).\putr((x,y),(c_k,c_\ell))=((z,w),(c_k',c_\ell'))\]
Applying \rn{PutRL} to the lenses $k$ and $\ell$, we learn that
\begin{align*}
k.\putl(z,c_k')&=(x,c_k') \\
\ell.\putl(w,c_\ell')&=(y,c_\ell')
\end{align*}
so that:
\[(k \otimes \ell).\putl((z,w),(c_k',c_\ell')) = ((x,y),(c_k',c_\ell'))\]
But this is exactly what we need to show for rule \rn{PutRL}.
\end{goodlens}

\begin{lenseqv}
If $R_k$ is a witness that $k \equiv k'$ and $R_\ell$ is a witness that
$\ell \equiv \ell'$, then $R = R_k \swizzle R_\ell$ witnesses $k \otimes
\ell \equiv k' \otimes \ell'$.

Since $k.\missing \relRk k'.\missing$ and $\ell.\missing
\relRl \ell'.\missing$, we know that
\dissdis(k.\missing,\ell.\missing) \relR (k'.\missing,\ell'.\missing),\dissdis
that is:
\[(k \otimes \ell).\missing \relR (k' \otimes \ell').\missing\]

Choose arbitrary $(x,y) \in X \times Y$ and related complements
$(c_k,c_\ell) \relR (c_{k'},c_{\ell'})$. Define:
\begin{align*}
    (z,c_k')        &= k.\putr(x,c_k) \\
    (z',c_{k'}')    &= k'.\putr(x,c_{k'}) \\
    (w,c_\ell')     &= \ell.\putr(y,c_\ell) \\
    (w',c_{\ell'}') &= \ell'.\putr(y,c_{\ell'})
\end{align*}
Since $c_k \relRk c_{k'}$ and $k.\putr \sim_{R_k} k'.\putr$, we can
conclude that $z=z'$ and $c_k' \relRk c_{k'}'$. Similarly, $w = w'$
and $c_\ell' \relRl c_{\ell'}'$. But we can compute
\begin{align*}
    (k \otimes \ell).\putr((x,y),(c_k,c_\ell)) &= ((w,z),(c_k',c_\ell')) \\
    (k' \otimes \ell').\putr((x,y),(c_{k'},c_{\ell'})) &=
    ((w',z'),(c_{k'}',c_{\ell'}'))
\end{align*}
where $(w,z)=(w',z')$ and $(c_k',c_\ell') \relR (c_{k'}',c_{\ell'}')$. Thus,
$(k \otimes \ell).\putr \sim_R (k' \otimes \ell').\putr$.

Showing that $(k \otimes \ell).\putl \sim_R (k' \otimes \ell').\putl$ is
similar.
\end{lenseqv}

\begin{lemma}[Functoriality of $\otimes$]
The tensor product operation on lenses induces a bifunctor on the category
\LENS{}, that is,
\begin{itemize}
    \item[] $\id_X \otimes \id_Y \equiv \id_{X \times Y}$, and
    \item[] $(k_1 ; \ell_1) \otimes (k_2 ; \ell_2) \equiv (k_1 \otimes k_2)
; (\ell_1 \otimes \ell_2)$.
\end{itemize}
\end{lemma}

\begin{functoriality}
Corollary~\ref{singleton_id} implies the former equivalence. The latter has
an intricate (but uninteresting) witness:
\[((c_{k_1},c_{\ell_1}),(c_{k_2},c_{\ell_2})) \relR
((c_{k_1},c_{k_2}),(c_{\ell_1},c_{\ell_2}))\]
That is, one state is related to another precisely when it is a
rearrangement of the component states. It is clear that this relates the
$\missing$ states of each lens, and the $\putr$ and $\putl$ components do
identical computations (albeit in a different order), so they are related by
$\sim_R$ as necessary.
\end{functoriality}
\else
The verification that this forms a lens is straightforward.
\fi

\begin{lemma}[Product bijection]\label{lemma:bij_product}
For bijections $f$ and $g$,
\[\bij_f\otimes\bij_g \equiv \bij_{f \times g}.\]
\iffull
\begin{proof}
Write $k = \bij_f\otimes\bij_g$ and $\ell = \bij_{f \times g}$.  The total
relation $R \in (\Unit \times \Unit) \times \Unit$ is a witness.  It's clear
that $k.\missing\relR\ell.\missing$, so let's show that the puts are
similar. Since all complements are related, this reduces to showing that
equal input values yield equal output values.
\begin{eqnarray*}
    k.\putr((x,y),(\unit,\unit))
    &=& \mllet (x',c_1) = \bij_f.\putr(x,\unit) \mline \\
    & & \mllet (y',c_2) = \bij_g.\putr(y,\unit) \mline \\
    & & ((x',y'),(c_1,c_2)) \\
    &=& ((f(x),g(y)),(\unit,\unit)) \\
    \ell.\putr((x,y),\unit) &=& ((f(x),g(y)),\unit)
\end{eqnarray*}
The $\putl$ direction is similar.
\end{proof}
\fi
\end{lemma}

In fact, the particular tensor product defined above is very well behaved:
it induces a \emph{symmetric monoidal category}---i.e., a
category with a unit object $1$ and the following natural isomorphisms:
\begin{eqnarray*}
    \alpha_{X,Y,Z}  &:& (X \otimes Y) \otimes Z \to X \otimes (Y \otimes Z) \\
    \lambda_X       &:& 1 \otimes X \to X \\
    \rho_X          &:& X \otimes 1 \to X \\
    \gamma_{X,Y}    &:& X \otimes Y \to Y \otimes X
\end{eqnarray*}
These are known as the \emph{associator}, \emph{left-unitor},
\emph{right-unitor}, and \emph{symmetry}, respectively. In addition to the
equations implied by these being natural isomorphisms, they must also
satisfy
\iffull
the coherence equations:
\begin{eqnarray*}
    \alpha;\alpha &=&
        (\alpha\otimes\id);\alpha;(\id\otimes\alpha) \\
    \rho\otimes\id &=& \alpha;(\id\otimes\lambda) \\
    \alpha;\gamma;\alpha &=&
        (\gamma\otimes\id);\alpha;(\id\otimes\gamma) \\
    \alpha^{-1};\gamma;\alpha^{-1} &=&
        (\id\otimes\gamma);\alpha^{-1};(\gamma\otimes\id) \\
    \gamma;\gamma &=& \id
\end{eqnarray*}
\else
some coherence conditions (given in the full version).
\fi

\begin{prop}[\LENS{},$\otimes$ is \ifdissertation symmetric monoidal\else a symmetric monoidal category\fi]
In the category \SET, the Cartesian product is a bifunctor with $\Unit$ as
unit, and gives rise to a symmetric monoidal category. Let
$\alpha^\times,\lambda^\times,\rho^\times,\gamma^\times$ be associator,
left-unitor, right-unitor, and symmetry natural isomorphisms. Then the
$\otimes$ bifunctor also gives rise to a symmetric monoidal category of
lenses, with $\Unit$ as unit and $\alpha^\otimes=\bij\circ\alpha^\times$,
$\lambda^\otimes=\bij\circ\lambda^\times$,
$\rho^\otimes=\bij\circ\rho^\times$, and
$\gamma^\otimes=\bij\circ\gamma^\times$ as associator, left-unitor,
right-unitor, and symmetry, respectively.
\end{prop}

Knowing that \LENS{} is a symmetric monoidal category is useful for several
reasons.  First, it tells us that, even though the tensor construction is not quite a full-blown
product, it \iffull still supports many of the operations
traditionally associated with products. \else is algebraically quite well
behaved. \fi
Second, it justifies a convenient intuition where lenses built from multiple
tensors are pictured as graphical ``wiring diagrams\commaquote and suggests a
possible syntax for lenses that shuffle product components (which we briefly
discuss in \S\ref{sec:future}).

\iflater\finish{Nate: The discussion of "wiring diagrams" in the context of
  symmetric monoidal categories made me wonder, can you explain Janis's
  stuff?  Especially his latest in ICFP '10?}\fi
% TODO: yeah, I think there is something interesting to say there; perhaps
% semantic bidirectionalization can be seen as defining a lens on the type
% that represents containers of exactly the shape currently under review
% (since semantic bidirectionalization doesn't permit containers' shape to
% change)

\iffull
\begin{proof}
We know $\alpha^\otimes$, $\lambda^\otimes$, $\rho^\otimes$, and
$\gamma^\otimes$ are all isomorphisms because every bijection lens is an
isomorphism. Showing that they are natural is a straightforward
calculation\footnote{For example, showing that $\gamma^\otimes$ is natural
requires showing that for any two lenses $k : X \lens Z$ and $\ell : Y \lens
W$,
\[(k \otimes \ell);\gamma^\otimes_{Z,W} \equiv \gamma^\otimes_{X,Y};(\ell
\otimes k).\]
The complements for these two lenses are $(k.C \times \ell.C) \times \Unit$
and $\Unit \times (\ell.C \times k.C)$; the isomorphism that simply
rearranges the parts of the complement is a witness to the lenses'
equivalence.  The story is similar for the other naturality properties.}.
The five coherence conditions follow from coherence in \SET, functoriality of
$\bij$, and Lemma~\ref{lemma:bij_product}.
\end{proof}
\fi

%\iftext So the tensor really is a tensor. \fi

\begin{defn}[Projection lenses]\ 
In \LENS{}, the projection is parametrized by an extra element to return
when executing a $\putl$ with a $\missing$ complement.
\lensdef{projection}
{\infruleplain{y \in Y}{\pi_{1y} \in X \times Y \lens X}}
{\pi_{1y} &=& (\id_X \otimes \const_y);\rho^\otimes_X}
The other projection is defined similarly.
\end{defn}

Returning to the example in the introduction, recall that we wish to
create a lens $e : X \times Y \lens Y \times Z$ with missing elements $m \in
X$ and $M \in Z$. We now have the machinery necessary to construct this
lens: 
\[e = \pi_{2m}\,;\,\pi_{1M}\op\]

The extra parameter to the projection (e.g. $m$ or $M$ above) needs to be
chosen with some care.  Some sets may have clear neutral elements; for
example, a projection from $A \times B\LIST \to A$ will likely use the empty
list $\NIL$ as its neutral element. Other projections may need additional
domain knowledge to choose a good neutral element---for example, a
projection $A \times \mathrm{Country} \to A$ might use the country with the
most customers as its default.

In some cases, the algebraic laws that one wants the projection to satisfy
may guide the choice as well. The extra parameter prevents full naturality
from holding, and therefore prevents this from being a categorical product,
but the following ``indexed'' version of the naturality law does hold.

\begin{lemma}[Naturality of projections] Suppose $k \in X_k \lens Y_k$ and
$\ell \in X_\ell \lens Y_\ell$ and choose some initial value $y_i \in
Y_\ell$. Define $(x_i,c_i) = \ell.\putl(y_i,\ell.\missing)$. Then
$(k \otimes \ell); \pi_{1y_i} \equiv \pi_{1x_i};k$.
\end{lemma}

\iffull
\begin{proof} We show that the following diagram commutes:

\begin{center}
\tikz \draw[node distance=4em]
    node              (ab) {$X_k \times X_\ell$}
    node[below of=ab] (au) {$X_k \times \Unit$}
    node[below of=au] (a)  {$X_k$}
    node[right=7em of ab] (cd) {$Y_k \times Y_\ell$}
    node[below of=cd] (cu) {$Y_k \times \Unit$}
    node[below of=cu] (c)  {$Y_k$}
    (ab) edge[->] node[above] {$k \otimes \ell$}                 (cd)
    (ab) edge[->] node[left]  {$\id_{X_k} \otimes \const_{x_i}$} (au)
    (cd) edge[->] node[right] {$\id_{Y_k} \otimes \const_{y_i}$} (cu)
    (au) edge[->] node[above] {$k \otimes \id_\Unit$}            (cu)
    (au) edge[->] node[left]  {$\rho_{X_k}$} (a)
    (cu) edge[->] node[right] {$\rho_{Y_k}$} (c)
    (a)  edge[->] node[above] {$k$}          (c)
    ;
\end{center}

To show that the top square commutes, we invoke functoriality of $\otimes$
and the property of identities; all that remains is to show that
\[\ell;\const_{y_i} \equiv \const_{x_i}\]
which follows from the uniqueness of terminal lenses and the definition of
$x_i$. The bottom square commutes because $\rho$ is a natural isomorphism.
\end{proof}
\fi

The most serious problem, though, is that there is no diagonal. There are, of
course, lenses with the {\em type} we need for $\diag$---for example,
$\disconnect$.  Or, more usefully, the lens that coalesces
the copies of $X$ whenever possible, preferring the left one when it cannot
  coalesce (this is essentially the \emph{merge} lens
  from~\cite{Focal2005-shortcite})
%
\lensdef{diagleft}
{\diag \in X \to X \times X}
{
    C &=& \Unit + X \\
    \missing &=& \mlinl \unit \\
    \putr(x, \mlinl \unit) &=& ((x, x), \mlinl \unit) \\
    \putr(x, \mlinr x') &=& ((x, x'), \eq(x, x')) \\
    \putl((x, x'), c) &=& (x, \eq(x, x'))
}
where here the $\eq$ function tests its arguments for equality\iffull:
\[\eq(x,x') = \cond{
    \mlinl \unit & x = x' \\
    \mlinr x' & x \ne x'
}\]
\fi---$\eq(x,x')$ yields $\mlinl \unit$ if $x = x'$ and 
yields $x'$ if not.
\iffull
This assumes that $X$ possesses a decidable equality, a reasonable
assumption for the applications of lenses that we know about.
\fi
However, neither of these proposals satisfy all the required laws.

\iffull
\breakifnearbottom
\begin{goodlens}\ 

\noindent\rn{PutLR}:
\begin{eqnarray*}
    \putr(\putl((x,x'),c))
    &=& \putr(x,\eq(x,x')) \\
    &=& \cond{
        \putr(x,\mlinl\unit) & x = x' \\
        \putr(x,\mlinr x') & x \ne x'
        } \\
    &=& \cond{
        ((x,x),\mlinl\unit) & x = x' \\
        ((x,x'),\mlinr x') & x \ne x'
        } \\
    &=& ((x,x'),\eq(x,x'))
\end{eqnarray*}
\rn{PutRL}:
\begin{eqnarray*}
    \putl(\putr(x,\mlinl\unit))
    &=& \putl((x,x),\mlinl\unit) \\
    &=& (x,\mlinl\unit) \\
    \putl(\putr(x,\mlinr x'))
    &=& \putl((x,x'),\eq(x,x')) \\
    &=& (x,\eq(x,x'))\endofpf
\end{eqnarray*}
\end{goodlens}
\fi

\section{Sums and Lists}\label{sumlist}

\iffull Historically, the \else The \fi status of sums has been even more
mysterious than
that of products.  In particular, the {\em injection arrows} from $A$ to $A
+ B$ and $B$ to $A + B$ do not even make sense in the asymmetric setting; as
functions, they are not surjective, so they cannot satisfy \rn{PutGet}.

\iffull
Before we study the question for \LENS{}, let us formally define a sum.
\fi
%
A \emph{categorical sum} of two objects $X$ and $Y$ is an object $X+Y$ and
arrows $\inl : X \to X+Y$ and $\inr : Y \to X+Y$ such that for any two
arrows $f : X \to Z$ and $g : Y \to Z$ there is a unique arrow $[f,g] : X +
Y \to Z$---the \emph{choice} of $f$ or $g$---satisfying $\inl;[f,g] = f$
and $\inr;[f,g] = g$. As with products, if a sum exists, it is unique up to
isomorphism.

Since products and sums are dual, Corollary~\ref{self_duality} and
Theorem~\ref{noprod} imply that \LENS{} does not have sums.
But we do have a tensor whose object part is a set-theoretic
sum---in fact, there are at least two interestingly different ones---and we
can define useful associated structures, including 
a choice operation on lenses.  \iffull But these constructions are
even farther away from being categorical sums than what we saw with
products.

As with products, a tensor $\oplus$ can be extended to a sum by providing three
natural transformations---this time written $\inl$, $\inr$, and $\codiag$;
that is, for each pair of objects $X$ and $Y$, there must be arrows
\[\begin{array}{r@{\;\in\;}l}
\inl_{X,Y} & X \to X \oplus Y \\
\inr_{X,Y} & Y \to X \oplus Y \\
\codiag_X  & X \oplus X \to X
\end{array}\]
such that
\iffull
\[\begin{array}{r@{\;=\;}l}
\inl ; (f \oplus g) & f ; \inl \\
\inr ; (f \oplus g) & g ; \inr \\
(f \oplus f) ; \codiag & \codiag ; f 
\end{array}\]
\else
\[\begin{array}{r@{\;=\;}l}
\inl ; (f \oplus g) & f ; \inl \\
\inr ; (f \oplus g) & g ; \inr \\
(f \oplus f) ; \codiag & \codiag ; f \\
\inl ; \codiag & \id \\
\inr ; \codiag & \id \\
(\inl \oplus \inr) ; \codiag & \id 
\end{array}\]
\fi
and making the following diagrams commute:
\begin{center}
\tikz \draw[node distance=8em]
    node               (sum)   {$X \oplus X$}
    node[right of=sum] (right) {$X$}
        edge[->] node[above] {$\inr$} (sum)
    node[left of=sum]  (left)  {$X$}
        edge[->] node[above] {$\inl$} (sum)
    node[below=3.5em of sum] (sink) {$X$}
        edge[<-] node[left=1em]  {$\id$}     (left)
        edge[<-] node[right=1em] {$\id$}     (right)
        edge[<-] node[right]     {$\codiag$} (sum)
    ;

\tikz \draw[node distance=11em]
    node               (sum)    {$X \oplus Y$}
    node[right of=sum] (right)  {$(X \oplus Y)\oplus(X \oplus Y)$}
        edge[->] node[below]    {$\codiag$} (sum)
    node[above=3.5 em of right] (src) {$X\oplus Y$}
        edge[->] node[right]    {$\inl \oplus \inr$}  (right)
        edge[->] node[left=1em] {$\id$}  (sum)
    ;
\end{center}
These diagrams are identical to the product diagrams, with the exception
that the arrows point in the opposite directions (that is, the sum diagrams
are the dual of the product diagrams).
\else
As with products, a tensor can be extended to a sum by providing injection
and \emph{co-diagonal} natural transformations satisfying a family of
equations, but these constructions are even farther away from being
categorical sums than what we saw with products.
\fi

The two tensors, which we called \emph{retentive} and \emph{forgetful} in
\S\ref{symm}, differ in how they handle
the complement when the new value being \PUT{}
is from a different branch of the sum than the old value that was \PUT{}.
The retentive sum keeps complements for {\em both} sublenses in its own
complement and switches between them as needed.  The forgetful sum keeps
only one complement, corresponding to whichever branch was last \PUT{}.  If
the next \PUT{} switches sides, the complement is replaced with $\missing$.
\iffull\else
We give just the retentive sum here, since it seems more useful; the
forgetful sum can be found in the long version. 
\fi

\ifdissertation\breakifnearbottom\fi
\begin{defn}[Retentive tensor sum lens]\ 
\lensdef{sum}
{
    \infruleplain
        {k \in X \lens Z \qquad \ell \in Y \lens W}
        {k \oplus \ell \in X + Y \lens Z + W}
}
{
    C &=& k.C \times \ell.C \\
    \missing &=& (k.\missing, \ell.\missing) \\
    \putr(\mlinl x, (c_k, c_\ell))
    &=& 
    \mllet (z, c_k') = k.\putr(x, c_k) \mline \\
    &&  (\mlinl z, (c_k', c_\ell))
\\
    \putr(\mlinr y, (c_k, c_\ell))
    &=& 
    \mllet (w, c_\ell') = \ell.\putr(y, c_\ell) \mline \\
    &&  (\mlinr w, (c_k, c_\ell'))
\\
    \putl(\mlinl z, (c_k, c_\ell))
    &=& 
    \mllet (x, c_k') = k.\putl(z, c_k) \mline \\
    &&  (\mlinl x, (c_k', c_\ell))
\\
    \putl(\mlinr w, (c_k, c_\ell))
    &=& 
    \mllet (y, c_\ell') = \ell.\putl(y, c_\ell) \mline \\
    &&  (\mlinr y, (c_k, c_\ell'))
}
\end{defn}

\iffull
\begin{goodlens}
We show that \rn{PutRL} holds; the proof that \rn{PutLR} holds is similar.
Choose arbitrary $c_k \in k.C$ and $c_\ell \in \ell.C$. There are two cases
to consider for the starting value: it will be either $\mlinl x$ for some $x
\in X$ or $\mlinr y$ for some $y \in Y$. In the former case, define
$(z,c_k') = k.\putr(x,c_k)$ so that applying \rn{PutRL} to $k$ tells us that
$k.\putl(z,c_k')=(x,c_k')$. But now we can compute:
\[\putl(\putr(\mlinl x,(c_k,c_\ell))) = \putl(\mlinl z,(c_k',c_\ell)) =
    (\mlinl x,(c_k',c_\ell)).\]
Thus, the value has round-tripped exactly as $\mlinl x$, and the complement
changed only after the $\putr$ (and not after the $\putl$) -- exactly what
we needed to show.

The other case is similar: define $(w,c_\ell') = \ell.\putr(y,c_\ell)$ so
that applying \rn{PutRL} to $\ell$ tells us that
$\ell.\putl(w,c_\ell')=(y,c_\ell')$. Computation then shows that:
\[\putl(\putr(\mlinr y,(c_k,c_\ell))) = \putl(\mlinr w,(c_k,c_\ell')) =
    (\mlinr y,(c_k,c_\ell'))\text{.\endofpf}\]
\end{goodlens}

\begin{lenseqv}
Suppose $k \equiv k'$ and $\ell \equiv \ell'$, as witnessed by relations
$R_k$ and $R_\ell$, respectively. Then $R = R_k \swizzle R_\ell$
witnesses the equivalence $k \oplus \ell \equiv k' \oplus \ell'$. Since
$k.\missing \relRk k'.\missing$ and $\ell.\missing \relRl \ell'.\missing$,
we have $(k\oplus\ell).\missing \relR (k'\oplus\ell').\missing$.

We now show that $(k\oplus\ell).\putr \sim_R (k'\oplus\ell').\putr$. Choose
arbitrary $v \in X+Y,c_k \in k.C,c_{k'} \in k'.C,c_\ell \in
\ell.C,c_{\ell'} \in \ell'.C$ such that $(c_k,c_\ell) \relR
(c_{k'},c_{\ell'})$. By the definition of $R$, we can conclude that $c_k
\relRk c_{k'}$ and that $c_\ell \relRl c_{\ell'}$.  There are two cases to
consider: either $v = \mlinl x$ for some $x \in X$ or $v = \mlinr y$ for
some $y \in Y$. In the first case, define
\begin{align*}
    (z,c_k') &= k.\putr(x,c_k) \\
    (z',c_{k'}') &= k'.\putr(x,c_{k'})
\end{align*}
Since $c_k \relRk c_{k'}$, we can conclude $z=z'$ and $c_k' \relRk c_{k'}'$.
Therefore,
\begin{align*}
    (k\oplus\ell).\putr(v,(c_k,c_\ell)) &= (\mlinl z,(c_k',c_\ell)) \\
    (k'\oplus\ell').\putr(v,(c_{k'},c_{\ell'})) &= (\mlinl z,(c_{k'}',c_{\ell'}))
\end{align*}
where $(c_k',c_\ell) \relR (c_{k'}',c_{\ell'})$ as desired. The second case,
where $v = \mlinr y$, is similar.

Showing that $(k\oplus\ell).\putl \sim_R (k'\oplus\ell').\putl$ is symmetric
to the argument for $\putr$.
\end{lenseqv}

\iffull
\begin{lemma}[Functoriality of $\oplus$]
\else
\begin{lemma}
\fi
The tensor sum operation on lenses induces a bifunctor on \LENS{}.
\end{lemma}

\begin{functoriality}
Corollary~\ref{singleton_id} gives us $\id_X \oplus \id_Y \equiv \id_{X+Y}$
with fairly minor computation. \ifdissertation We must also show that
composition is preserved. Suppose we have four lenses:
\begin{align*}
    k &\in X \lens Y & k' &\in X' \lens Y' \\
    \ell &\in Y \lens Z & \ell' &\in Y' \lens Z'
\end{align*}
The obvious
\else
For composition, the obvious
\fi
isomorphism between complements witnesses the equivalence
$(k;\ell)\oplus(k';\ell') \equiv (k \oplus k');(\ell \oplus \ell')$, namely:
\[((c_k,c_\ell),(c_k',c_\ell'))\relR((c_k,c_k'),(c_\ell,c_\ell'))\]
\iffull
Define abbreviations $a=(k;\ell)\oplus(k';\ell')$ and
$b=(k \oplus k');(\ell\oplus\ell')$.
\else
Define abbreviations $a$ and $b$:
\begin{align*}
    a &= (k;\ell)\oplus(k';\ell') \\
    b &= (k \oplus k');(\ell \oplus \ell')
\end{align*}
\fi
Expanding definitions,\iffull\else we find\fi
\begin{align*}
    a.\missing &= ((k.\missing,\ell.\missing),(k'.\missing,\ell'.\missing)) \\
    b.\missing &= ((k.\missing,k'.\missing),(\ell.\missing,\ell'.\missing))
\end{align*}
so $a.\missing \relR b.\missing$. We must also show $a.\putr \sim_R b.\putr$
and $a.\putl \sim_R b.\putl$. We will show only the former; the proof of the
latter is similar.

Choose arbitrary $v \in X+X',c_a \in a.C,c_b \in b.C$ such that $c_a
\relR c_b$. This means there are $c_k \in k.C,c_{k'} \in k'.C,c_\ell \in
\ell.C,c_{\ell'} \in \ell'.C$ such that $c_a =
((c_k,c_\ell),(c_{k'},c_{\ell'}))$ and $c_b =
((c_k,c_{k'}),(c_\ell,c_{\ell'}))$. There are two cases to consider: either
$v=\mlinl x$ or $v=\mlinr x'$. In the first case, we can define
\begin{align*}
    (y,c_k') &= k.\putr(x,c_k) \\
    (z,c_\ell') &= \ell.\putr(y,c_\ell),
\end{align*}
and compute:
\begin{align*}
    a.\putr(\mlinl x,((c_k,c_\ell),(c_{k'},c_{\ell'}))) &= (\mlinl
    z,((c_k',c_\ell'),(c_{k'},c_{\ell'}))) \\
    b.\putr(\mlinl x,((c_k,c_{k'}),(c_\ell,c_{\ell'}))) &= (\mlinl
    z,((c_k',c_{k'}),(c_\ell',c_{\ell'})))
\end{align*}
Since $\mlinl z = \mlinl z$ and
\ifcomplement\[\else$\fi
((c_k',c_\ell'),(c_{k'},c_{\ell'})) \relR
((c_k',c_{k'}),(c_\ell',c_{\ell'})),
\ifcomplement\]\else$\ \fi
we have finished the first case. The second case, where $v=\mlinr x'$, is
nearly identical, and we conclude that $a.\putr \sim_R b.\putr$.
\end{functoriality}
\fi

\iffull
\begin{definition}[Forgetful tensor sum]\ 
\lensdef{forgetful_sum}
{
    \infruleplain
        {k \in X \lens Z \qquad \ell \in Y \lens W}
        {k \oplus^f \ell \in X + Y \lens Z + W}
}
{
    C &=& k.C + \ell.C \\
    \missing &=& \mlinl k.\missing \\
    \putr(\mlinl x,\mlinl c_k)
    &=& \mlletinbreak{(z,c_k') = k.\putr(x,c_k)}
                     {(\mlinl z,\mlinl c_k')}
    \putr(\mlinl x,\mlinr c_\ell)
    &=& \mlletinbreak{(z,c_k) = k.\putr(x,k.\missing)}
                     {(\mlinl z,\mlinl c_k)}
    \putr(\mlinr y,\mlinl c_k)
    &=& \mlletinbreak{(w,c_\ell) = \ell.\putr(y,\ell.\missing)}
                     {(\mlinr w,\mlinr c_\ell)}
    \putr(\mlinr y,\mlinr c_\ell)
    &=& \mlletinbreak{(w,c_\ell') = k.\putr(y,c_\ell)}
                     {(\mlinr w,\mlinr c_\ell')}
    \\
    \putl\mbox{ is similar}
}
\end{definition}
\fi

\iffull
\begin{goodlens}
As for the retentive sum, the round-trip laws for $k$ and $\ell$ guarantee
that $k \oplus^f \ell$ round-trips. The only difference is that there are
additional cases to consider when the tag on the value and the tag on the
complement do not match at the beginning of the trip; however, this poses no
real difficulty, as the tags \emph{will} match after the first put.
\end{goodlens}

\begin{lenseqv}
Let $a=k \oplus^f \ell$ and $b=k' \oplus^f \ell'$.  If $R_k$ witnesses
$k\equiv k'$ and $R_\ell$ witnesses $\ell\equiv \ell'$ then
$a \equiv b$ may be witnessed by
\[
R = \{(\mlinl c,\mlinl c')\mid c \relRk c'\}\cup\{(\mlinr c,\mlinr c')\mid c \relRl c'\}
\]
Since $k.\missing \relRk k'.\missing$, we know $a.\missing \relR
b.\missing$.

We must still show that $a.\putr \sim_R b.\putr$ and that $a.\putl \sim_R
b.\putl$; for each of these proofs, there are cases to consider where the
input is tagged $\mlinlx$ and cases where the input is tagged $\mlinrx$.
Below, we will consider only the $\mlinlx$ case for $\putr$; the remaining
cases are similar.

Therefore, consider arbitrary $x \in X, c_a \in a.C, c_b \in b.C$ such that
$c_a \relR c_b$. Project these complements into $k.C$ and $k'.C$,
respectively, as follows:
\begin{align*}
    c_a' &= \left\{\begin{array}{ll}
        c_k & c_a = \mlinl c_k \\
        k.\missing & c_a = \mlinr c_\ell
    \end{array}\right. \\
    c_b' &= \left\{\begin{array}{ll}
        c_{k'} & c_b = \mlinl c_{k'} \\
        k'.\missing & c_b = \mlinr c_{\ell'}
    \end{array}\right.
\end{align*}
Since $c_a \relR c_b$, we know they have the same tag, and hence that $c_a'$
and $c_b'$ follow the same ``branch'' in their definition; in either branch,
we find that $c_a' \relRk c_b'$, because $c_a \relR c_b$ and $k.\missing
\relRk k'.\missing$. But now we can compute:
\begin{align*}
    a.\putr(x,c_a) &= \mllet (z,c_k') = k.\putr(x,c_a') \mlinm (\mlinl z,\mlinl c_k') \\
    b.\putr(x,c_b) &= \mllet (z,c_{k'}') = k'.\putr(x,c_b') \mlinm (\mlinl z, \mlinl c_{k'}')
\end{align*}
The desired properties now arise because $k.\putr \sim_{R_k} k'.\putr$ and
$c_a' \relRk c_b'$.
\end{lenseqv}

\begin{functoriality}
There are two things to show:
\[\id_X \oplus^f \id_Y \equiv \id_{X+Y}\]
\[(k \oplus^f k');(\ell \oplus^f \ell') \equiv (k;\ell)\oplus^f(k';\ell')\]

For identity preservation, we use the total
\ifdissertation
relation which has $c \relR \unit$ for all $c$.
\else
relation:
\[c \relR \unit\]
\fi
Clearly the initial condition $(\id \oplus^f \id).\missing \relR
\id.\missing$ holds; we will also show that $(\id \oplus^f \id).\putr \sim_R
\id.\putr$, eliding the similar proof relating the $\putl$ functions. So,
choose arbitrary $v \in X+Y$ and $c \in \Unit + \Unit$.
\begin{align*}
    (\id \oplus^f \id).\putr(v,c) &= \left\{\begin{array}{ll}
        \mllet (x',c') = \id.\putr(x,()) \\
        \mlinb (\mlinl x',\mlinl c') & v = \mlinl x \\
        \mllet (y',c') = \id.\putr(y,()) \\
        \mlinb (\mlinr y',\mlinr c') & v = \mlinr y
    \end{array}\right. \\
    &= \left\{\begin{array}{ll}
        (\mlinl x,\mlinl\unit) & v = \mlinl x \\
        (\mlinr y,\mlinr\unit) & v = \mlinr y
    \end{array}\right. \\
    &= \left(v,\left\{\begin{array}{ll}\mlinl\unit & v = \mlinl
        x\\\mlinr\unit & v = \mlinr y\end{array}\right\}\right) \\
    \id.\putr(v,c) &= (v,\unit)
\end{align*}
Since $v=v$ and the complements are always related, this shows that
\dissdis(\id\oplus^f\id).\putr\sim_R\id.\putr.\dissdis

For preservation of composition, we use the relation $R$ defined by:
\[\begin{array}{l}
\{((\mlinl c_k,\mlinl c_\ell),\mlinl (c_k,c_\ell)) \mid c_k \in k.C,c_\ell
\in \ell.C\} \mathrel\cup \\
\{((\mlinr c_k,\mlinr c_\ell),\mlinr (c_k,c_\ell)) \mid c_k \in k'.C,c_\ell
\in \ell'.C\}
\end{array}\]
Abbreviating $a = (k\oplus^fk');(\ell\oplus^f\ell')$ and $b =
(k;\ell)\oplus^f(k';\ell')$,
we can quickly see that $a.\missing = (\mlinl k.\missing,\mlinl
\ell.\missing) \relR \mlinl (k.\missing,\ell.\missing) = b.\missing$. We
will also show that $a.\putr \sim_R b.\putr$, eliding the similar proof that
$a.\putl \sim_R b.\putl$.

Choose arbitrary $v \in X_0+X_1,c_a \in a.C,c_b \in b.C$ such that $c_a
\relR c_b$. There are many cases to consider, but two of them are
representative of the remainder. In the first representative case, we have
\begin{align*}
    v &= \mlinl x_0 \\
    c_a &= (\mlinl c_k, \mlinl c_\ell) \\
    c_b &= \mlinl (c_k,c_\ell)
\end{align*}
Then:
\begin{align*}
    a.\putr(v,c_a) ={}
    & \mllet (y_0,c_k') = k.\putr(x_0,c_k) \mline \\
    & \mllet (z_0,c_\ell') = \ell.\putr(y_0,c_\ell) \mline \\
    & (\mlinl z_0,(\mlinl c_k',\mlinl c_\ell')) \\
    b.\putr(v,c_b) ={}
    & \mllet (z_0,(c_k',c_\ell')) = (k;\ell).\putr(x_0,(c_k,c_\ell)) \mline \\
    & (\mlinl z_0,\mlinl (c_k',c_\ell')) \\
    ={}
    & \mllet (y_0,c_k') = k.\putr(x_0,c_k) \mline \\
    & \mllet (z_0,c_\ell') = \ell.\putr(y_0,c_\ell) \mline \\
    & (\mlinl z_0,\mlinl (c_k',c_\ell'))
\end{align*}
Since $z_0,c_k',c_\ell'$ are computed identically in the two equations, the
relation is preserved in this case.

In the second representative case, we have
\begin{align*}
    v &= \mlinl x_0 \\
    c_a &= (\mlinr c_{k'}, \mlinr c_{\ell'}) \\
    c_b &= \mlinr (c_{k'},c_{\ell'})
\end{align*}
Then:
\ifdissertation
\begin{align*}
    a.\putr(v,c_a) ={}
    & \mllet(y_0,c_k) = k.\putr(x_0,k.\missing) \mline \\
    & \mllet(z_0,c_\ell) = \ell.\putr(x_0,\ell.\missing) \mline \\
    & (\mlinl z_0,(\mlinl c_k,\mlinl c_\ell)) \\
\end{align*}
\begin{align*}
    b.\putr(v,c_b) ={}
    & \mllet(z_0,c') = (k;\ell).\putr(x_0,(k;\ell).\missing) \mline \\
    & (\mlinl z_0,\mlinl c') \\
    ={}
    & \mllet(y_0,c_k) = k.\putr(x_0,k.\missing) \mline \\
    & \mllet(z_0,c_\ell) = \ell.\putr(y_0,\ell.\missing) \mline \\
    & (\mlinl z_0,\mlinl (c_k,c_\ell))
\end{align*}
\else
\begin{align*}
    a.\putr(v,c_a) ={}
    & \mllet(y_0,c_k) = k.\putr(x_0,k.\missing) \mline \\
    & \mllet(z_0,c_\ell) = \ell.\putr(x_0,\ell.\missing) \mline \\
    & (\mlinl z_0,(\mlinl c_k,\mlinl c_\ell)) \\
    b.\putr(v,c_b) ={}
    & \mllet(z_0,c') = (k;\ell).\putr(x_0,(k;\ell).\missing) \mline \\
    & (\mlinl z_0,\mlinl c') \\
    ={}
    & \mllet(y_0,c_k) = k.\putr(x_0,k.\missing) \mline \\
    & \mllet(z_0,c_\ell) = \ell.\putr(y_0,\ell.\missing) \mline \\
    & (\mlinl z_0,\mlinl (c_k,c_\ell))
\end{align*}
\fi
Again, since $z_0,c_k,c_\ell$ are computed identically in both equations,
the relation is preserved.
\end{functoriality}
\fi

\begin{lemma}[Sum bijection]\label{lemma:bij_sum}
For bijections $f$ and $g$,
\[\bij_f\oplus\bij_g \iffull \equiv \bij_f\oplus^f\bij_g \fi \equiv \bij_{f
  + g}\] 
\end{lemma}

\iffull
\begin{proof}
Write $k = \bij_f\oplus\bij_g$, $k^f = \bij_f\oplus^f\bij_g$, and $\ell =
\bij_{f+g}$.  The total relation $R \subseteq (\Unit \times \Unit) \times
\Unit$ is a witness that $k \equiv \ell$ and the total relation $R^f \subseteq
(\Unit + \Unit) \times \Unit$ is a witness that $k^f \equiv \ell$.  It's
clear that $k.\missing\relR\ell.\missing$ and
$k^f.\missing\mathrel{R^f}\ell.\missing$, so let's show that the puts are
similar. Since all complements are related, this reduces to showing that
equal input values yield equal output values.

\begin{eqnarray*}
    k.\putr(\mlinl x,(\unit,\unit))
    &=& \mllet (z,c_k) = \bij_f.\putr(x,\unit) \mline \\
    & & (\mlinl z,(c_k,\unit)) \\
    &=& \mllet (z,c_k) = (f(x),\unit) \mline \\
    & & (\mlinl z,(c_k,\unit)) \\
    &=& (\mlinl f(x),(\unit,\unit)) \\
    k.\putr(\mlinr y,(\unit,\unit)) &=& (\mlinr g(y),(\unit,\unit)) \\
    k^f.\putr(\mlinl x,c)
    &=& \mllet (z,c_k) = \bij_f.\putr(x,\unit) \mline \\
    & & (\mlinl z,\mlinl c_k) \\
    &=& \mllet (z,c_k) = (f(x),\unit) \mline \\
    & & (\mlinl z,\mlinl c_k) \\
    &=& (\mlinl f(x),\mlinl\unit) \\
    k^f.\putr(\mlinr y,c) &=& (\mlinr g(y),\mlinr\unit) \\
    \ell.\putr(\mlinl x,\unit)
    &=& ((f+g)(\mlinl x),\unit) \\
    &=& (\mlinl f(x),\unit) \\
    \ell.\putr(\mlinr y,\unit) &=& (\mlinr g(y),\unit)
\end{eqnarray*}

The $\putl$ direction is similar.
\end{proof}
\fi

\begin{prop}[\LENS{},$\oplus$\iffull,$\oplus^f$ are \else{} is a \fi
symmetric monoidal\ifcomplement\iffull categories\else category\fi\fi]
In \SET, the disjoint union gives rise to a symmetric monoidal category with
$\emptyset$ as unit. Let $\alpha^+,\lambda^+,\rho^+,\gamma^+$ be associator,
left-unitor, right-unitor, and symmetry natural isomorphisms.
Then the $\oplus$ bifunctor gives rise
to a symmetric monoidal category of lenses with $\emptyset$ as unit and
$\alpha^\oplus=\bij\circ\alpha^+$, $\lambda^\oplus=\bij\circ\lambda^+$,
$\rho^\oplus=\bij\circ\rho^+$, and $\gamma^\oplus=\bij\circ\gamma^+$ as
associator, left-unitor, right-unitor, and symmetry, respectively\iffull;
and similarly for $\oplus^f$. \else.\fi

The types of these natural isomorphisms are:
\begin{eqnarray*}
    \alpha^\oplus_{X,Y,Z}  &\in& (X + Y) + Z \lens X + (Y + Z) \\
    \lambda^\oplus_X       &\in& \emptyset + X \lens X \\
    \rho^\oplus_X          &\in& X + \emptyset \lens X \\
    \gamma^\oplus_{X,Y}    &\in& X + Y \lens Y + X
\end{eqnarray*}

\end{prop}

\iffull
\begin{proof}
We know $\alpha^\oplus$, $\lambda^\oplus$, $\rho^\oplus$, and
$\gamma^\oplus$ are all isomorphisms because every bijection lens is an
isomorphism. Showing that they are natural is a straightforward calculation.
The only subtlety comes in showing that $(k\oplus^f\ell);\gamma^\oplus \equiv
\gamma^\oplus;(\ell\oplus^fk)$. We must be careful to include the $\missing$
complements in the relation; the following relation will do:
\begin{eqnarray*}
    R &=& \{(\mlinl c,\mlinr c) \mid c \in k.C\}\cup \\
      & & \{(\mlinr c,\mlinl c) \mid c \in \ell.C\}\cup \\
      & & \{(\mlinl k.\missing,\mlinl \ell.\missing)\}
\end{eqnarray*}

The five coherence conditions follow from coherence in \SET, functoriality of
$\bij$, and Lemma~\ref{lemma:bij_sum}.
\end{proof}
\fi

Unlike the product unit, there are no interesting lenses whose domain is the sum's
unit, so this cannot be used to define the injection lenses; we have to do
it by hand.

\breakifnearbottom

\begin{defn}[Injection lenses]\ 
%
\lensdef{injection}
{\infruleplain{x \in X}{\inl_{x} \in X \lens X + Y}}
{
    C &=& X \times (\Unit + Y) \\
    \missing &=& (x,\mlinl \unit) \\
    \putr(x, (x', \mlinl \unit)) &=& (\mlinl x, (x, \mlinl \unit)) \\
    \putr(x, (x', \mlinr y)) &=& (\mlinr y, (x, \mlinr y)) \\
    \putl(\mlinl x, c) &=& (x, (x, \mlinl \unit)) \\
    \putl(\mlinr y, (x, c)) &=& (x, (x, \mlinr y))
}
%
We also define $\inr_y = \inl_y;\gamma^\oplus_{Y,X}$.
\end{defn}

\iffull
\begin{goodlens}
For \rn{PutRL}, we consider two cases: either the complement has the form
$(x_c, \mlinl \unit)$ or the form $(x_c,\mlinr y)$.
\begin{align*}
    \putl(\putr(x,(x_c,\mlinl \unit))) &= \putl(\mlinl x, (x, \mlinl \unit)) \\
    &= (x, (x, \mlinl \unit)) \\
    \putl(\putr(x,(x_c,\mlinr y))) &= \putl(\mlinr y, (x, \mlinr y)) \\
    &= (x, (x, \mlinr y))
\end{align*}
Thus, in each case, the output value is equal to the input value and the
complement is unaffected by the $\putl$, as required by \rn{PutRL}.

To show \rn{PutLR} holds, we again consider two cases: either we start with
$\mlinl x$ or $\mlinr y$.
\begin{align*}
    \putr(\putl(\mlinl x, (x_c, y_c))) &= \putr(x, (x, \mlinl \unit)) \\
    &= (\mlinl x, (x, \mlinl \unit)) \\
    \putr(\putl(\mlinr y, (x_c, y_c))) &= \putr(x_c, (x_c, \mlinr y)) \\
    &= (\mlinr y, (x_c, \mlinr y))
\end{align*}
In both cases, the value output matches the value input and the complement
remains unaffected by $\putr$.
\end{goodlens}

As with the projection lenses for tensor products, we may ask whether the
injection lenses for tensor sums are natural. If they were, we would expect
a diagram like the following one to commute for all $f$:
\begin{center}
\tikz \draw[node distance=4em]
    node                 (X)  {$X$}
    node[right=7em of X] (Y)  {$Y$}
    node[below of=X]     (XZ) {$X+Z$}
    node[below of=Y]     (YZ) {$Y+Z$}
    (X)  edge[->] node[above] {$f$}          (Y)
    (X)  edge[->] node[left]  {$\inl_x$}     (XZ)
    (Y)  edge[->] node[right] {$\inl_y$}     (YZ)
    (XZ) edge[->] node[above] {$f\oplus\id$} (YZ)
    ;
\end{center}
Now, even if we carefully choose $x$ and $y$ to be related by $f$
as we did for the projection lenses, this diagram may not commute. When
running the $\putr$ function, the path along the top always invokes
$f.\putr$, whereas the path along the bottom may sometimes invoke
$\id.\putr$ instead; at that moment, the complements of $f$ (on the top
path) and $f\oplus\id$ (on the bottom path) get out of synch. As we show in the following proposition this can be used to produce a subsequent observable difference, i.e., not only at the level of complements. 

The situation with the forgetful sum is similar, but offers an
additional way to desynchronize the two complements: when resetting
$f$'s complement along the bottom path to $\missing$.  \fi

\begin{proposition}
The injection lenses are not natural.
\end{proposition}

\iffull
\begin{proof}
We first define a lens that counts the number of changes it sees in the
$\putr$ direction, and allows puts of non-numbers to be overridden in the
$\putl$ direction:
\lensdef{count} {\infruleplain{x \in X}{\countlens_x \in X \lens \Unit +
    \NAT}} {
  C &=& X \times \Bool \times \NAT \\
  \missing &=& (x,\true,0) \\
  \putr(x,(x',b,n)) &=& \\
  \colspan{\cond{
      (\mlinl\unit,(x,b,n)) & x = x' \land \lnot b \\
      (\mlinr n,(x,b,n)) & x = x' \land b \\
      (\mlinr (n+1),(x,\true,n+1)) & x \ne x'
    }} \\
  \putl(\mlinl\unit,(x,b,n)) &=& (x,(x,\false,n)) \\
  \putl(\mlinr n,(x,b,n')) &=& (x,(x,\true,n)) }
We delay the proof that this lens is well-formed temporarily. Contrast the lens
$\inl_b;(\countlens_{b'}\oplus\id_\Unit)$ with $\countlens_{b'};\inl_n$
(where $b$ and $b'$ are arbitrary $\Bool$ values and $n$ is an arbitrary
$\Unit+\NAT$ value).  Consider the put objects
\[\left<\mlinl\true,\mlinr(\mlinr\unit),\mlinl\false,\mlinr(\mlinl(\mlinl\unit)),\mlinl\true,\mlinl\false\right>\]
The first two put objects in the list are simply initializing the lens: we
first put $\true$ to the right, getting an $\mlinlx$ object out on the right
from both lenses, then put back an $\mlinrx$ object, switching sides.

The next put of $\false$ to the right is where the problem really arises.
For the $\countlens_{b'};\inl_n$ lens, the counting lens first registers the
change from $\true$ to $\false$, then its output gets thrown away. On the
other hand, in the $\inl_b;(\countlens_{b'}\oplus\id_\Unit)$ lens, the
$\false$ gets thrown away before the counting lens can see it, so the complement
in the counting lens doesn't get updated.

The remainder of the objects simply manifest this problem by switching the sum
back to the counting side, and getting an output from the counting lenses;
one will give a higher count than the other.

The proof for $\inr$ is symmetric. 
\end{proof}

\begin{goodlens}
For completeness, we must also show that $\countlens_x$ satisfies the lens
laws.

\noindent\rn{PutLR}: There are two cases to consider. Both are simple calculations.
\begin{align*}
    \putr(\putl(\mlinl\unit,(x,b,n')))
        &= \putr(x,(x,\false,n')) \\
        &= (\mlinl\unit,(x,\false,n')) \\
    \putr(\putl(\mlinr n,(x,b,n')))
        &= \putr(x,(x,\true,n)) \\
        &= (\mlinr n,(x,\true,n))
\end{align*}

\noindent\rn{PutRL}: There are three cases to consider. For the first case,
choose distinct $x \ne x'$.
\begin{align*}
    \putl(\putr(x,(x',b,n)))
        &= \putl(\mlinr(n+1),(x,\true,n+1)) \\
        &= (x,(x,\true,n+1))
\end{align*}
In the remaining cases, both the value and the complement round-trip
exactly, which is even more than the \rn{PutRL} law requires.
\begin{eqnarray*}
    \putl(\putr(x,(x,\false,n)))
        &=& \putl(\mlinl\unit,(x,\false,n)) \\
        &=& (x,(x,\false,n)) \\
    \putl(\putr(x,(x,\true,n)))
        &=& \putl(\mlinr n,(x,\true,n)) \\
        &=& (x,(x,\true,n)) \endofpf
\end{eqnarray*}
\end{goodlens}
\fi

%% Here's Martin's version:
%% 
%% Hi, I was supposed to find out why naturality of inl fails for the
%% gullible elephant sum. The diagram is
%%
%%                         C x D
%%           X + Y -------------------------> Z + W
%%             ^           l + k                ^
%% X x (1 + Y) |                                | Z x (1 + W)
%%             |             C                  |
%%             X ---------------------------->  Z
%%                           l
%%
%% Consider the following test sequence:
%%
%%           putr(x)
%%           putl(inr(w))
%%           putr(x')
%%
%% Writing l.putr(x,l.missing) = (z,c)
%%        l.putr(x',c) = (z',c')
%%
%% then after running the test sequence we find c in the complement of the
%% upper arrow whereas there is a c' in the complement of the lower arrow!
%%
%% Thus, if we now do a putl(inl(z)) for some z with the property that
%%            fst(l.putl(z,c)) =/= fst(l.putl(z,c'))
%%
%% then we get an observable difference.

As with products, where we have a useful lens of type $X \lens X \times X$ that
is nevertheless not a diagonal lens, we can craft a useful conditional lens
of type $X + X \lens X$ that is nevertheless not a codiagonal lens. In fact,
we define a more general lens $\union \in X + Y \lens X \cup Y$.
Occasionally, a value that is both an $X$ and a $Y$ may be put to the left
across one of these union lenses. In this situation, the lens may
legitimately choose either an $\mlinrx$ tag or an $\mlinlx$ tag.
\iffull Below, we propose two lenses that break this tie in different ways. \fi
 The $\union$ lens uses the most recent unambiguous put to break the tie.
\iffull\else (In the long version, we also define a variant that looks back
to the last tagged value that was put to the right that was in both
sets.)\fi
%
\iffull
The $\union'$ lens,
on the other hand, looks back to the last tagged value that was put to the
right that was in both sets.
\fi

\iflater
\finish{ We can also comment that the conditional can be extended with fixup
  functions in the style of the original asymmetric generalized conditional.
}
\PENDING{Daniel and I (BCP) were thinking that maybe the fixup functions
  could/should actually be fixup lenses.  Details need to be worked out.}
\fi

\iflater \formartin{In the .tex file there's some text explaining that, if
  \LENS{} had products, it would also have sums.  Before we typeset it, we
  should probably turn the argument around (we've already shown that there
  are no products; what we want to see is that there are no sums)...
} \mxh{This has kind of been incorporated into the iroductory paras on sums.} \fi
%% The following observation may help explain the nonexistence of products and
%% sums:
%% \begin{verbatim}
%% Because op is a contravariant _endofunctor_ and an involution, any
%% products are also sums. How come? Well, suppose that
%% (A * B, pi_1, pi_2) is a product, that is, for any f : C -> A and g :
%% C -> B, there is a unique <f, g> : C -> A * B that satisfies

%% <f, g>; pi_1 = f
%% <f, g>; pi_2 = g

%% Then, I claim that (A * B, pi_1^op, pi_2^op) is a sum, that is, for
%% any f : A -> C and g : B -> C, the arrow

%% f & g = <f^op, g^op>^op

%% is the unique arrow such that

%% f & g; pi_1^op = f
%% f & g; pi_2^op = g

%% The equalities are easy to check:

%% f & g; pi_1^op
%%  = <f^op, g^op>^op; pi_1^op    by definition of &
%%  = (<f^op, g^op>; pi_1)^op     because op is a functor
%%  = (f^op)^op                   property of <_, _>
%%  = f                           because op is an involution

%% and similarly for g. Uniqueness goes by contradiction; if there were
%% another arrow h satisfying the conditions, then h^op would be a
%% witness that <f^op, g^op> is not the unique commuting arrow in the
%% product diagram for f^op and g^op.
%% \end{verbatim}

\begin{definition}[Union lens]\ 
\lensdef{union}
{\union_{XY} \in X + Y \lens X \cup Y}
{
C &=& \Bool \\
\missing &=& \false \\
\putr(\mlinl x,c) &=& (x,\false) \\
\putr(\mlinr y,c) &=& (y,\true) \\
\putl(xy,c) \\
\colspan{
= \cond{
    (\mlinl xy,\false) & xy \notin Y \lor (xy \in X \land \lnot c) \\
    (\mlinr xy,\true ) & xy \notin X \lor (xy \in Y \land c)
    }
}
}
\end{definition}

\iffull
\begin{goodlens}\ 

\noindent\rn{PutRL}:
\begin{eqnarray*}
    \putl(\putr(\mlinl x,c))
    &=& \putl(x,\false) \\
    &=& (\mlinl x,\false) \\
    \putl(\putr(\mlinr y,c))
    &=& \putl(y,\true) \\
    &=& (\mlinr y,\true)
\end{eqnarray*}

\noindent\rn{PutLR}: There are six cases to consider, corresponding to which
of the sets $X$, $Y$, and $X \cap Y$ our value is a member of and to whether
the complement is $\true$ or $\false$.
\begin{eqnarray*}
    \putr(\putl(xy,\false))
    &=& \putr(\mlinl xy,\false) \\
    &=& (xy,\false) \\
    \putr(\putl(x,\false))
    &=& \putr(\mlinl x,\false) \\
    &=& (x,\false) \\
    \putr(\putl(y,\false))
    &=& \putr(\mlinr y,\true) \\
    &=& (y,\true)
\end{eqnarray*}
The cases for when the complement is $\true$ are symmetric.
\end{goodlens}
\fi

\iffull
\begin{definition}[Another union lens] Given two sets $X$ and $Y$,
\iffull let's define a few bijections:
\else there are a few easily-defined bijections:
\fi
\begin{eqnarray*}
    f &\in& X \to X \setminus Y + X \cap Y \\
    g &\in& Y \to X \cap Y + Y \setminus X \\
    h &\in& X \setminus Y + X \cap Y + Y \setminus X \to X \cup Y \\
\iffull
    f(x) &=& \cond{
        \mlinl x & x \notin Y \\
        \mlinr x & x \in Y
        } \\
    g(y) &=& \cond{
        \mlinl y & y \in X \\
        \mlinr y & y \notin X \\
        } \\
    h(\mlinl x) &=& x \\
    h(\mlinr (\mlinl xy)) &=& xy \\
    h(\mlinr (\mlinr y)) &=& y
\fi
\end{eqnarray*}
\lensdef{union_prime}
{\union'_{XY} \in X + Y \lens X \cup Y}
{
\union'_{XY}
&=& \bij_{(f+g);\alpha^+;(\id+(\alpha^+)^{-1})}; \\
& & (\id_X\oplus(\union_{X \cap Y,X \cap Y}\oplus\id_Y)); \\
& & \bij_h
}
\end{definition}
\fi

% a ``by-hand'' definition of the switch lens follows, in case we decide to
% drop the first kind of union
%\begin{definition}[Switch lens]\ 
%\lensdef{switch}
%{\switch_X \in X+X \lens X}
%{
%C &=& \Bool \\
%\missing &=& \false \\
%\putr(\mlinl x,c) &=& (x,\false) \\
%\putr(\mlinr x,c) &=& (x,\true) \\
%\putl(x,\false) &=& (\mlinl x,\false) \\
%\putl(x,\true) &=& (\mlinr x,\true)
%}
%\begin{goodlens}\ 
%
%\noindent\rn{PutRL}:
%\begin{eqnarray*}
%    \putl(\putr(\mlinl x,c)) &=& \putl(x,\false) \\
%    &=& (\mlinl x,\false) \\
%    \putl(\putr(\mlinr x,c)) &=& \putl(x,\true) \\
%    &=& (\mlinr x,\true)
%\end{eqnarray*}
%
%\noindent\rn{PutLR}:
%\begin{eqnarray*}
%    \putr(\putl(x,\false)) &=& \putr(\mlinl x,\false) \\
%    &=& (x,\false) \\
%    \putr(\putl(x,\true)) &=& \putr(\mlinr x,\true) \\
%    &=& (x,\true)
%\\[-\medskipamount]
%\end{eqnarray*}
%\end{goodlens}
%\end{definition}

\iffull These definitions  are \else This definition is \fi {not}
symmetric in $X$ and $Y$, because $\putl$ prefers
to return an $\mlinlx$ value if there have been no tie breakers yet.
Because of this preference, \iffull neither $\union$ nor $\union'$ can \else
$\union$ cannot \fi be used to
construct a true codiagonal. However, there are two useful related
constructions\ifdissertation, which we discuss below.\else:\fi

\ifdissertation\breakifnearbottom\fi
\begin{definition}[Switch lens]\ 
\lensdef{switch}
{\switch_X \in X+X \lens X}
{\switch_X &=& \union_{XX}}
\end{definition}

\iffull We've used $\union$ rather than $\union'$ in this definition, but it
actually doesn't matter: the two lenses' tie-breaking methods are equivalent
when $X=Y$:

\begin{lemma}
\[\union_{XX} \equiv \union'_{XX}\]
\end{lemma}

\begin{proof}
The relation that equates the states of the two $\union$ lenses is a
witness:
\(R = \{(b,((\unit,(b,\unit)),\unit)) \mid b \in \Bool\}\).
\end{proof}
\fi

\iffull\else\breakifnearbottom\fi

\begin{definition}[Retentive case lens]\ 
\lensdef{case}
{\infruleplain
    {k \in X \lens Z \andalso \ell \in Y \lens Z}
    {\caselens_{k,\ell} \in X + Y \lens Z}
}
{\caselens_{k,\ell} = (k \oplus \ell); \switch_X}
\end{definition}

\iffull
\breakifnearbottom
\begin{definition}[Forgetful case lens]\ 
\lensdef{case}
{\infruleplain
    {k \in X \lens Z \andalso \ell \in Y \lens Z}
    {\caselens^f_{k,\ell} \in X + Y \lens Z}
}
{\caselens^f_{k,\ell} = (k \oplus^f \ell); \switch_X}
\end{definition}
\else
A forgetful case lens appears in the long version.
\fi

\iflater
\paragraph*{Finite Maps}

\finishtext{Is it easy to say something --- at least something basic --- about
  these?  Look at old lenses paper for feature tree primitives.  But let's
  postpone this till other things are worked out.}
\fi

\paragraph*{Lists}\label{lists}

We can also define a variety of lenses operating on lists.  We only
consider mapping here, because in the next section we show how to
obtain this and a whole variety of other functions on lists as instances of
a powerful generic theorem, but it is useful to see one concrete instance
first.

Write $X\LIST$ for the set of lists with elements from the set $X$.  Write
$\NIL$ for the 
empty list and $x{\CONS}xs$ for the list with head $x$ and tail $xs$.  Write
$X\INFTY$ for the set of infinite lists over $X$. When $x \in X$ and $ss \in
X\INFTY$, write $x{\CONS}ss \in X\INFTY$ for the infinite list with head $x$
and tail $ss$.  Write $x\INFTY \in X\INFTY$ for the infinite
list of $x$'s.

\breakifnearbottom
\begin{defn}[Retentive list mapping lens]\ \label{delala}
\lensdef{map}
{\infruleplain{\ell \in X \lens Y}{\map(\ell) \in X\LIST \lens Y\LIST}}
{
    C &=& (\ell.C)\INFTY \\
    \missing &=& (\ell.\missing)\INFTY \\
    \putr(x,c) &=& 
           \mllet \left<x_1,\ldots,x_m\right> = x \mline \\
        && \mllet \left<c_1,\ldots\right> = c \mline \\
        && \mllet (y_i,c_i') = \ell.\putr(x_i,c_i) \mline \\
        && (\left<y_1,\ldots,y_m\right>,\left<c_1',\ldots,c_m',c_{m+1},\ldots\right>) \\
    \putl && (\mathrm{similar})
}
\end{defn}

\ifdissertation
The $\map$ lens gives us the machinery we need to complete the first example
in the introduction: simply define $e\LIST = \map(e)$. Additionally, as we
saw in \S\ref{symm}, there is also a forgetful variant of the list mapping
lens. Indeed, this is the one that corresponds to the known list mapping
operator on asymmetric, state-based lenses~\cite{Focal2005-shortcite,%
Boomerang07}.
\else
As we saw in \S\ref{symm}, there is also a forgetful variant of the
list mapping lens.  Indeed, this is the one that corresponds to the known
list mapping operator on asymmetric lenses~\cite{Focal2005-shortcite,%
Boomerang07}. Additionally, the $\map$ lens gives us the machinery we
need to complete the first example in the introduction: simply define
$e\LIST = \map(e)$.
\fi

\iffull
\breakifnearbottom
\begin{defn}[Forgetful list mapping lens]\ \label{dedaja}
\lensdef{map_prime}
{\infruleplain{\ell \in X \lens Y}{\map^f(\ell) \in X\LIST \lens Y\LIST}}
{
    C &=& \ell.C\LIST \\
    \missing &=& \left<\right> \\
    \putr(x,c)
    &=& \mllet \left<x_1,\ldots,x_m\right> = x \mline \\
    & & \mllet \left<c_1,\ldots,c_n\right> = c \mline \\
    & & \mllet \left<c_{n+1},\ldots\right> = (\ell.\missing)\INFTY \mline \\
    & & \mllet (y_i,c_i') = \ell.\putr(x_i,c_i) \mline \\
    & & (\left<y_1,\ldots,y_m\right>,\left<c_1',\ldots,c_m'\right>) \\
    \putl && (\mathrm{similar})
}
\end{defn}

Rather than proving that these two forms of list mapping are lenses, preserve
equivalence, induce functors, and so on, we show that these properties hold
for a generalization of their construction in the next section.

We can make the relationship between the retentive sum and map lenses and
the forgetful sum and map lenses precise; the following two diagrams
commute:

\begin{center}
\tikz \draw
    node                        (rfoldedY)   {$Y\LIST$\strut}
    node[above=of rfoldedY]     (rfoldedX)   {$X\LIST$\strut}
    node[left=3em of rfoldedY]  (runfoldedY) {$\Unit + Y \times Y\LIST$\strut}
    node[above=of runfoldedY]   (runfoldedX) {$\Unit + X \times X\LIST$\strut}
    (runfoldedX) edge[->] node[above] {$\bij$}                                       (rfoldedX)
    (runfoldedX) edge[->] node[left]  {$\id_\Unit\oplus(\ell\otimes\map(\ell))$}     (runfoldedY)
    (rfoldedX)   edge[->] node[right] {$\map(\ell)$}                                 (rfoldedY)
    (runfoldedY) edge[->] node[above] {$\bij$}                                       (rfoldedY)
%
    node[below=6em of rfoldedY] (ffoldedY)   {$Y\LIST$\strut}
    node[above=of ffoldedY]     (ffoldedX)   {$X\LIST$\strut}
    node[left=3em of ffoldedY]  (funfoldedY) {$\Unit + Y \times Y\LIST$\strut}
    node[above=of funfoldedY]   (funfoldedX) {$\Unit + X \times X\LIST$\strut}
    (funfoldedX) edge[->] node[above] {$\bij$}                                       (ffoldedX)
    (funfoldedX) edge[->] node[left]  {$\id_\Unit\oplus^f(\ell\otimes\map^f(\ell))$} (funfoldedY)
    (ffoldedX)   edge[->] node[right] {$\map^f(\ell)$}                               (ffoldedY)
    (funfoldedY) edge[->] node[above] {$\bij$}                                       (ffoldedY)
    ;
\end{center}
\fi % full

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Iterators}\label{iter} 

In functional programming, mapping
functionals are usually seen as instances of more general
``fold patterns\commaquote or defined by general recursion. In this section,
we investigate to what extent this path can be followed in the world
of symmetric lenses. 

Allowing general recursive definitions for symmetric lenses may be
possible, but in general, complements change when unfolding a recursive
definition; this means that the structure of the
complement of the recursively defined function would itself have to be
given by some kind of fixpoint construction. Preliminary investigation
suggests that this is possible, but it would considerably clutter the
development---on top of the general inconvenience of having to deal with
partiality.

Therefore, we choose a different path. We identify a ``fold'' combinator for
lists, 
reminiscent of the view of lists as initial algebras. We show that several
important lenses on lists---including\iffull, of course, the mapping
combinator\else{} mapping\fi---can
be defined with the help of a fold, and that, due to the self-duality of lenses,
folds can be composed back-to-back to yield general recursive patterns
in the style of {\em hylomorphisms} \cite{meijer1991functional}.
\iffull

\fi
We also discuss iteration patterns on trees and argue that the
methodology carries over to other polynomial inductive datatypes.

\subsect{Lists}

Let $\foldlist \in \Unit + (X \mathord{\times} X\LIST) \rightarrow
X\LIST$ be the bijection between ``unfolded'' lists and lists; $\foldlist$ takes $\mlinl
\unit$ to $\NIL$ and $\mlinr (x,xs)$ to $x{\CONS}xs$.  Note that $\bij_\foldlist
\in \Unit + (X \mathord{\times} X\LIST) \Lens X\LIST$ is then a bijective arrow
in the category \LENS{}.

\iffull
\begin{defn}[$X$-list algebra]
\else
\begin{defn}
\fi
An {\em $X$-list algebra} on a set $Z$ is an arrow $\ell \in \Unit + (X
\mathord{\times} Z) \Lens Z$ and a \ifdissertation weight \fi function $w \in Z \rightarrow \NAT$ such
that $\ell.\putl(z,c)=(\mlinr(x,z'),c')$ implies $w(z') < w(z)$.
%
We write $T\LIST_X$ for the functor that sends any lens $k$ to $\id_\Unit
\oplus (\id_X \otimes k)$.
\end{defn}

The function $w$ here plays the role of a termination measure in the right-to-left direction. We will be
iterating $\ell.\putl$, producing a stream of values of type $Z$, which we
would like to guarantee eventually ends.

\iffull\ifcomplement
\begin{theorem}[List iteration is well-defined]
\else
\begin{theorem}[Iteration is well-defined]
\fi\else
\begin{theorem}
\fi\label{listiter}
For $X$-list algebra $\ell$ on $Z$, there is a unique arrow
$\IT(\ell) \in X\LIST \Lens Z$ such that the following diagram
commutes:

\begin{center}
\tikz \draw[node distance=4em]
  node              (ul) {$T\LIST_X(X\LIST)$}
  node[below of=ul] (ll) {$T\LIST_X(Z)$}
  node[right=5em of ul] (ur) {$X\LIST$}
  node[below of=ur] (lr) {$Z$}
  (ul) edge[->] node[above] {$\bij_\foldlist$} (ur)
  (ul) edge[->] node[left]  {$T\LIST_X(\IT(\ell))$} (ll)
  (ur) edge[->] node[right] {$\IT(\ell)$} (lr)
  (ll) edge[->] node[below] {$\ell$} (lr)
  ;
\end{center}
% \vspace*{-\medskipamount}
%% \iffull
%% (Recall that a diagram commutes if composite arrows with the same endpoints
%% represent equal arrows.)
%% \fi
\end{theorem}
\iffull\else
\begin{pfsketch}
  We choose the complement of $\IT(\ell)$ to be $\ell.C^\omega$, so that the
  complements of the two arms of the commuting square are isomorphic.  We
  then take commutativity of the diagram as a suggestion for a recursive
  definition of both $\putr$ and $\putl$.  The length of the list in the
  case of $\putr$ and the weight function in the case of $\putl$ are used as
  ranking functions establishing totality of the recursive definitions. One
  must then prove, again by induction on these ranking functions, that the
  square does indeed commute.

  To show uniqueness, we take another lens $k$ which satisfies the above
  commutativity diagram. The diagram induces an ``unfolding'' of $k$'s
  complement into an infinite sequence of complements that satisfy a
  pairwise correspondence property with the infinite sequence in
  $\IT(\ell)$'s complement. We can then show that $\putr$ and $\putl$
  preserve this correspondence, which lets us construct a relation
  witnessing the equivalence of $k$ and $\IT(\ell)$.
\end{pfsketch}
\fi
In the terminology of universal algebra, an algebra for a functor $F$ from
some category to itself is simply an object $Z$ and an arrow
$F(Z)\rightarrow Z$.  An arrow between $F$-algebras $(Z,f)$ and
$(Z',f')$ is an arrow $u \in Z\rightarrow Z'$ such that $f;u = F(u);f'$.
The $F$-algebras thus form a category themselves. An initial $F$-algebra is
an initial object in that category (an initial object has exactly one arrow
to each other object, and is unique up to isomorphism).
$F$-algebras can be used to model a wide variety of inductive datatypes,
including lists and various kinds of trees~\cite{meijer1991functional,vene2000categorical}.
%
Using this terminology, Theorem~\ref{listiter}
says that $\bij_\foldlist$ is an initial object in the
subcategory consisting of those $T\LIST_X$-algebras for which a weight
function $w$ is available.

\iffull Before we give the proof, let \else Let \fi us consider some
concrete instances of the theorem. 
%
First, if $k \in X \Lens Y$ is a lens, then we can form an $X$-list
algebra $\ell$ on $Y\LIST$ by composing 
\iffull
two lenses as follows:
\begin{center}
\vspace*{-.5em}%
\tikz\draw
  node                  (l) {$\Unit + (X \mathord{\times} Y\LIST)$}
  node[right=10em of l] (c) {$\Unit + (Y \mathord{\times} Y\LIST)$}
  node[right=04em of c] (r) {$Y\LIST$}
  (l) edge[->] node[above] {$\id_\Unit \oplus (k \otimes \id_{Y\LIST})$} (c)
  (c) edge[->] node[above] {$\bij_\foldlist$} (r)
  ;
\vspace*{-.8em}%
\end{center}
\else
$\id_\Unit \oplus (k \otimes \id_{Y\LIST}) \in \Unit + (X \mathord{\times}
Y\LIST) \Lens \Unit + (Y \mathord{\times} Y\LIST)$
with
$\bij_\foldlist \in \Unit + (Y \mathord{\times} Y\LIST) \Lens Y\LIST$.
\fi %\iffull
A suitable weight function is given by $w(ys)=\length(ys)$.
The induced lens $\IT(\ell) \in X\LIST \Lens Y\LIST$ is the lens analog of
the familiar list mapping function. In fact, substituting
the lens $e \in X\times Y \Lens Y\times Z$ (from
\S\ref{symm}) for $k$ in the above diagram, we find
that $\IT(\ell)$ is the infinite-complement variant of the lens $e\LIST$.
(Again, we are ignoring the important question of alignment here. A
hand-written map lens could perform a more sophisticated alignment analysis
to associate ``similar'' items in a sequence of puts and recover more
appropriate data from the complement; the process described above results in
a simple positional alignment scheme.)

Second, suppose that $X = X_1 + X_2$ and let $Z$ be $X_1\LIST \times
X_2\LIST$. Writing $X_i^+$ for $X_i \times X_i\LIST$, we can define
isomorphisms
\begin{eqnarray*}
f &\in& (X_1 + X_2) \times X_1\LIST \times X_2\LIST \\
  &\to& (X_1^+ + X_2^+) + (X_1^+ \times X_2^+ + X_1^+ \times X_2^+) \\
g &\in& \Unit + ((X_1^+ + X_2^+) + X_1^+ \times X_2^+) \\
  &\to& X_1\LIST \times X_2\LIST
\end{eqnarray*}
by distributing the sum and unfolding the list type for $f$ and by factoring
the polynomial and folding the list type for $g$.%
\iffull
\footnote{The bijections $f$ and $g$ can be written in terms of the
associators, symmetries, unfolds, folds, and so forth that were already
introduced, so the lenses $\bij_f$ and $\bij_g$ would not have to be defined
``out of whole cloth'' as they are here, but these definitions get bogged
down in syntax without adding much value.}
\begin{eqnarray*}
f(\mlinl x_1,xs_1,\NIL) &=& \mlinl (\mlinl (x_1,xs_1)) \\
f(\mlinl x_1,xs_1,x_2 \CONS xs_2) &=& \mlinr (\mlinl ((x_1,xs_1),(x_2,xs_2))) \\
f(\mlinr x_2,\NIL,xs_2) &=& \mlinl (\mlinr (x_2,xs_2)) \\
f(\mlinr x_2,x_1 \CONS xs_1,xs_2) &=& \mlinr (\mlinr ((x_1,xs_1),(x_2,xs_2)))
\end{eqnarray*}
\begin{eqnarray*}
g(\mlinl\unit) &=& (\NIL,\NIL) \\
g(\mlinr(\mlinl(\mlinl(x_1,xs_1)))) &=& (x_1:xs_1,\NIL) \\
g(\mlinr(\mlinl(\mlinr(x_2,xs_2)))) &=& (\NIL,x_2:xs_2) \\
g(\mlinr(\mlinr((x_1,xs_1),(x_2,xs_2)))) &=& (x_1:xs_1,x_2:xs_2)
\end{eqnarray*}
\else\ 
\fi
\ifdissertation\breakifnearbottom\fi
Then we can create\iffull a lens to serve as the basis for a partitioning
iterator.\fi
\lensdef{filter_iterator}
{\ell \in \Unit + ((X_1+X_2) \times Z) \lens Z}
{
\ell
&=& (\id_\Unit \oplus \bij_f); \\
& & (\id_\Unit \oplus (\id_{X_1^++X_2^+} \oplus \switch_{X_1^+ \times X_2^+})); \\
& & \bij_g
}

A suitable weight function for $\ell$ is given by
\dissdis w((xs_1,xs_2))=\length(xs_1)+\length(xs_2). \dissdis
The lens $\IT(\ell) \in (X_1+X_2)\LIST \Lens X_1\LIST \times X_2\LIST$ that
we obtain from iteration partitions the input list in one direction and uses
a stream of booleans from the state to put them back in the right order in
the other direction. Indeed, $\IT(\ell)$ is exactly the $\partition$ lens
described in the introductory examples. 

Composing it with the second projection
yields a lens whose forward direction removes all the inl-entries and thus forms a special case of the well-known filter functional. Alternatively, this ``filter lens'' could be obtained
directly by iterating a slightly more complicated $\ell$.) Consequently, we now have
the machinery we need to define $\comp$ from the introduction:
\begin{align*}
    \filter &= \partition;\pi_{1\NIL} \\
    \comp   &= \filter;\filter\op
\end{align*}

\iflater
\item \dmwit{How about the lens $\mathit{size} \in \Unit + (X \times \NAT)
  \lens \NAT$ that maps $\unit$ to $0$ and $(x,n)$ to $n+1$ in the $\putr$
  direction? In the $\putl$ direction, it maps $0$ to $\unit$, maps $n+1$ to
  $(x,n)$ if it's got an $x$ to give from its complement, and uses some
  default $x$ otherwise.  Would iterating this give us a ``list-length''
  lens? (Can this lens even be made?)}\bcp{Should be easy to check whether
  the conditions demanded by the theorem are satisfied... :-)}
\fi


\iffull
\begin{pfof}{\ref{listiter}}
We define the lens $\IT(\ell)$ explicitly. 
%
\lensdef{iteration}
{\infruleplain{\ell \in T\LIST_X(Z) \lens Z \andalso \exists\mbox{ suitable
} w\iffull\mbox{ (discussed below)}\fi}
   {\IT(\ell) \in X\LIST \lens Z} }
{
\IT(\ell).C &=& (\ell.C)\INFTY \\
\IT(\ell).\missing &=& (\ell.\missing)\INFTY \\ 
\IT(\ell).\putr(\NIL,c{\CONS}cs) &=& \mllet (z,c') = \ell.\putr(\mlinl\unit,c) \mline
   \\ && (z,c'{\CONS}cs) \\
\IT(\ell).\putr(x{\CONS}xs,c{\CONS}cs) &=& \mllet (z,cs') =
               \IT(\ell).\putr(xs,cs) \mline \\
        && \mllet (z',c') = \ell.\putr(\mlinr(x,z),c) \mline \\
        && (z',c'{\CONS}cs') \\
\IT(\ell).\putl(z,c{\CONS}cs) &=& \mlmatch \ell.\putl(z,c) \mlwith \\
                      && \quad (\mlinl\unit,c') \rightarrow (\NIL,c'{\CONS}cs) \\
                      && | \ \ \ (\mlinr(x,z'),c') \rightarrow \\
                      &&  \ \quad \mllet (xs,cs') = \IT(\ell).\putl(z',cs) \mline \\
                      && \ \quad (x{\CONS}xs, c'{\CONS}cs') 
}
%
Note that the first element of the complement list holds {\em both} the
complement that is used when we do a $\putr$ of an empty list {\em and} the
complement that is used for the first element when we do a $\putr$ of a
non-empty list.  Similarly, the second element of the complement list holds
both the complement that is used at the end of the $\putr$ of a
one-element list {and} the complement that is used for the second
element when we do a $\putr$ of a two or more element list.

The recursive definition of $\IT(\ell).\putr$ is clearly terminating because
the first argument to the recursive call is always a shorter list; the
recursive definition of $\IT(\ell).\putl$ is terminating because the value
of $w$ is always smaller on the arguments to the recursive call.  The
round-trip laws are readily established by induction on $xs$ and on $w(z)$,
respectively.  So this is indeed a lens.

Commutativity of the claimed diagram is a direct consequence of the defining
equations (which have been crafted so as to make commutativity hold).

To show uniqueness, let $k \in X\LIST \Lens Z$ be another lens for which the
diagram commutes---i.e., such that:
\begin{center}
\tikz \draw[node distance=4em]
  node              (ul) {$T\LIST_X(X\LIST)$}
  node[below of=ul] (ll) {$T\LIST_X(Z)$}
  node[right=6em of ul] (ur)
                         {$X\LIST$}
  node[below of=ur] (lr) {$Z$}
  (ul) edge[->] node[above] {$\bij_\foldlist$} (ur)
  (ul) edge[->] node[left]  {$T\LIST_X(k)$} (ll)
  (ur) edge[->] node[right] {$k$} (lr)
  (ll) edge[->] node[below] {$\ell$} (lr)
  ;
\end{center}
Choose representatives of the equivalence classes $k$ and $\ell$---for
convenience, call these representatives $k$ and $\ell$.  Let $R \subseteq
k.C \times (k.C \times \ell.C)$ be a simulation relation witnessing the
commutativity of this diagram (recalling that equality of \LENS{}-arrows
means lens-equivalence of representatives). Notice that $k.C$ is the
complement of (a representative of) the upper path through the diagram, and
$k.C \times \ell.C$ is the complement of (a representative of) the lower
path through the diagram.  (Strictly speaking, the complements are $\Unit
\times k.C$ and $\Unit \times \Unit \times k.C \times \ell.C$; using
these isomorphic forms reduces clutter.)
% 
Thus, the commutativity of the diagram means: \infax{(k.\missing,
  (k.\missing, \ell.\missing)) \in R} \infrule {(d,(d',c)) \in R \\
  k.\putr(\NIL,d)=(z,d_1) \andalso \ell.\putr(\mlinl\unit,c)=(z',c_1)}
{(d_1,(d',c_1)) \in R \ \land \ z = z'} \infrule {(d,(d',c)) \in R
  \andalso
  k.\putr(x{\CONS}xs,d)=(z,d_1)  \\
  k.\putr(xs,d')=(z',d'_1) \andalso
  \ell.\putr(\mlinr(x,z'),c)=(z'',c_1)} {(d_1,(d'_1,c_1)) \in R \ \land
  \ z = z''} \infrule {(d,(d',c)) \in R \\ k.\putl(z,d)=(\NIL,d_1)}
{\ell.\putl(z,c) = (\mlinl\unit,c_1)\land (d_1,(d',c_1)) \in R }
\infrule {(d,(d',c)) \in R \andalso k.\putl(z,d)=(x{\CONS}xs,d_1)}
{
  \begin{array}{ll}
   &\ell.\putl(z,c) = (\mlinr(x,z'),c_1) \\
\land & k.\putl(z',d')=(xs,d'_1) \\
\land & (d_1,(d'_1,c_1)) \in R
  \end{array}
}
%
The variables $c_1, z', d'_1$ in the last two rules are existentially
quantified.

In order to show that $\IT(\ell) \equiv k$ we define a relation $S \subseteq
\IT(\ell).C \times k.C$ inductively as follows: 
\infax
  {(\IT(\ell).\missing,k.\missing) \in S}
\infrule
  {(d,(d',c)) \in R  \andalso  (cs,d') \in S}
  {(c{\CONS}cs,d) \in S}
Notice that if $(c{\CONS}cs,d)\in S$ by either one of the rules, then there
exists 
$d'$ such that $(d,(d',c)) \in R$ and $(cs,d') \in S$.  In particular, for
the first rule, $c{\CONS}cs=\IT(\ell).\missing$ and we choose $d'=k.\missing$.

It remains to show that $S$ is compatible with $\putl$ and $\putr$.  So
assume that $(c{\CONS}cs,d) \in S$, hence $(d,(d',c)) \in R$ and $(cs,d')
\in S$ for some $d'$. We proceed by induction on $\length(xs)$ in the $\putr$
cases and by induction on $w(z)$ in the $\putl$ cases.

\smallskip \noindent
\underline{Case for $\putr$ of empty list}: 
By definition,
%
\dissdis\IT(\ell).\putr(\NIL,c{\CONS}cs) = (z,c'{\CONS}cs),\dissdis where $(z,c') =
\ell.\putr(\mlinl\unit,c)$.
%        
Let $(z_1,d_1) = k.\putr(\NIL,d)$. 
%
Commutativity of the diagram
then tells us that $(d_1,(d',c')) \in R$ and $z_1=z$.  Since $(cs,d') \in S$, we
can conclude $(c'{\CONS}cs,d_1) \in S$, as required.
        
\smallskip \noindent
\underline{Case for $\putr$ of nonempty list}:  This time, the definition
gives us
\dissdis\IT(\ell).\putr(x{\CONS}xs, c{\CONS}cs) = (z',c'{\CONS}cs'),\dissdis
where
\[
\begin{array}{lcl}
(z,cs') &=& \IT(\ell).\putr(xs,cs) \\
(z',c') &=& \ell.\putr(\mlinr(x,z),c).
\end{array}
\]
%
Let 
\[
\begin{array}{lcl}
(z_1,d_1) &=& k.\putr(x{\CONS}xs,d) \\
(z_2,d_2) &=& k.\putr(xs,d')  \\
(z_3,c_3) &=& \ell.\putr(\mlinr(x,z_2),c).
\end{array}
\]
Inductively, we get $z_2=z$ and $(cs',d_2) \in S$. Thus, $z_3=z'$ and
$c_3=c'$.  From commutativity we get $z_1 = z'$ and $(d_1,(d_2,c')) \in R$, so
$(c'{\CONS}cs',d_1) \in S$ and we are done.  

\smallskip \noindent
\underline{Case where $\IT.\putl$ on $z$ returns the empty list}: 
Suppose we have
%
        $\IT(\ell).\putl(z,c\CONS{}cs) = (\NIL,c'\CONS{}cs)$, where 
        $(\mlinl\unit,c') = \ell.\putl(z,c)$.
        %
        Let $k.\putr(z,d) = (xs,d_1)$.  Commutativity of the diagram
        asserts that $(d_1,(c',d')) \in R$ and $xs=\NIL$. Now, since
        $(cs,d')\in S$, we can conclude $(c'\CONS{}cs,d_1) \in S$, as
        required.

\smallskip \noindent
\underline{Case where $\IT.\putl$ on $z$ returns a non-empty list}: 
Suppose we have
\begin{align*}
    \IT(\ell).\putl(z, c\CONS{}cs) &= (x\CONS{}xs,c'\CONS{}cs')\\
    (\mlinr(x,z'),c') &= \ell.\putl(z,c)\\
    (xs,cs') &= \IT(\ell).\putl(z',cs).
\end{align*}
%
        Since $\ell.\putl(z,c)$ returns an $\mlinr$ we are in the
        situation of the fourth rule above and we have
        $k.\putl(z,d)=(x\CONS{}xs',d_1)$ for some $xs'$ and $d_1$.
        Furthermore, we have $k.\putl(z',d')=(xs',d'_1)$ and
        $(d_1,(d'_1,c_1)) \in R$. The induction hypothesis applied to $z'$ in view of
        $w(z')<w(z)$ then yields $xs'=xs$ and also $(cs',d'_1)\in S$.
        It then follows $(c'\CONS{}cs',d_1)\in S$ and we are done.
\end{pfof}
\fi % \iffull

\iffull
\begin{corollary}[Hylomorphism]\label{hylo}
\else
\begin{corollary}\label{hylo}
\fi
Suppose $k\op$ is an $X$-list algebra on $W$ and $\ell$ is an $X$-list
algebra on $Z$. Then there is a lens
$\HYLO(k,\ell) \in W \Lens Z$ such that the following diagram commutes: 
\begin{center}
\tikz \draw[node distance=4em]
  node              (ul) {$T\LIST_X(W)$}
  node[below of=ul] (ll) {$T\LIST_X(Z)$}
  node[right=5em of ul] (ur) {$W$}
  node[below of=ur] (lr) {$Z$}
  (ul) edge[<-] node[above] {$k$} (ur)
  (ul) edge[->] node[left]  {$T\LIST_X(\HYLO(k,\ell))$} (ll)
  (ur) edge[->] node[right] {$\HYLO(k,\ell)$} (lr)
  (ll) edge[->] node[below] {$\ell$} (lr)
  ;
\end{center}
\end{corollary}
\begin{pf}
Define $\HYLO(k,\ell)$ as the composition $\IT(k\op)\op;\IT(\ell)$. 
\end{pf}
One can think of $\HYLO(k,\ell)$ as a recursive definition of a
lens. The lens $k$ tells whether a recursive call should be made, and
if so, produces the argument for the recursive call and some auxiliary
data. The lens $\ell$ then describes how the result is to be built
from the result of the recursive call and the auxiliary data.
%
This gives us a lens version of the hylomorphism pattern from
functional programming \cite{meijer1991functional}.
%
Unfortunately, we were unable to prove or disprove the uniqueness of
$\HYLO(k,\ell)$. However, given that hylomorphisms are usually not
unique, e.g.\ in the categories of relations or complete partial
orders this might not be considered an important issue.

We have not formally studied the question of whether $\IT(\ell)$
is actually an initial algebra, i.e., whether it can
be defined and is unique even in the absence of a weight function. However,
this seems unlikely, because then it would apply to the case where $Z$ is the
set of finite and infinite $X$ lists and $\ell$ the obvious bijective lens.
The $\putl$ component of $\IT(\ell)$ would then have to truncate an infinite
list, which would presumably break the commuting square.

\subsect{Other Datatypes}
Analogs of Theorem~\ref{listiter} and
Corollary~\ref{hylo} are available for a number of other functors, in
particular those that are built up from variables by $+$ and $\times$.
All of these can also be construed as containers (see
\S\ref{contain}), but the iterator and hylomorphism patterns
provide more powerful operations for the construction of lenses than
the mapping operation available for general containers.\footnote{One anonymous referee remarked that suitable categories of containers have initial algebras thus providing ``the usual fold stuff''. We disagree with this; the morphisms in the categories of containers are rather restricted and require, for instance, any reordering of the positions to be independent of the actual data contained in those. Thus, for example, a sorting function is not a container morphism and can thus not be construed as an initial algebra map in the category of containers.} 
 Moreover, the
universal property of the iterator provides a modular proof method,
allowing one to deduce equational laws which can be cumbersome to
establish directly because of the definition of equality as behavioral
equivalence. For instance, we can immediately deduce that list mapping
is a functor. Containers, on the other hand, subsume datatypes such as labeled graphs that are not initial algebras. 

\paragraph{Iterators with multiple arguments}
The list iterator allows us to define a lens between $X\LIST$ and some
other set $Z$, but Theorem~\ref{listiter} cannot be directly used to define
a lens between $X\LIST \times Y$ and $Z$ (think of $Y$ as modeling
parameters).  In standard functional programming, a
map from $X\LIST\times Y$ to $Z$ is tantamount to a map from $X\LIST$
to $Y{\rightarrow}Z$, so iteration with parameters is subsumed by
the parameterless case. Unfortunately, \LENS{} does not seem to have the
function spaces required to play this trick.

Therefore, we introduce the functor $T\LIST_{X,Y}(Z)=Y + X \times
Z$ and notice that $T\LIST_{X,Y}(X\LIST \times Y)\simeq X\LIST \times
Y$. Just as before, 
an algebra for that functor is a lens $\ell \in T\LIST_{X,Y}(Z)\lens Z$ together with a function $w:Z\rightarrow \mathbb{N}$ such that 
$\ell.\putl(z,c) = (\mlinr(x,z'),c')$ implies $w(z')<w(z)$.

As an example, let $Y=Z=X\LIST$ and define
\lensdef{concat_iterator}
{\ell \in X\LIST + X \times X\LIST \lens X\LIST}
{
    C &=& \Bool \\
    \missing &=& \true \\[1ex]
    \ell.\putr(\mlinl xs,b) &=& (xs,\true) \\
    \ell.\putr(\mlinr(x,xs),b) &=& (x \CONS xs,\false) \\[1ex]
    \ell.\putl(\NIL,b) &=& (\mlinl \NIL,\true) \\
    \ell.\putl(x \CONS xs,\true) &=& (\mlinl (x \CONS xs),\true) \\
    \ell.\putl(x \CONS xs,\false) &=& (\mlinr(x,xs),\false)
}
Iteration yields a lens $X\LIST \times X\LIST \lens X\LIST$ that can
be seen as a bidirectional version of list concatenation. The commuting
square for the iterator corresponds to the familiar recursive definition of
concatenation: $\textit{concat}(\NIL,{ys})=ys$ and $\textit{concat}(x\CONS
xs,ys) = x\CONS\textit{concat}(xs,ys)$.
%
In the bidirectional case considered here the complement will automatically retain enough information to allow splitting in the $\putl$-direction.

\medskip

We can use a version of Corollary~\ref{hylo} for this data structure
to implement tail recursive constructions. Consider, for instance,
the $T\LIST_{\Unit,X\LIST}$-algebra $k:X\LIST + X\LIST \times X\LIST \lens
X\LIST \times X\LIST$ where
\[
\begin{array}{l@{\;}l}
k.\putl((\mathit{acc},\NIL),\true)&=(\mlinl \mathit{acc},\true) \\
k.\putl((\mathit{acc},x{\CONS}xs),\true)&=(\mlinr(x{\CONS}\mathit{acc},xs),\true)\\
k.\putl((\mathit{acc},xs),\false)&=(\mlinr(\mathit{acc},xs),\false).
\end{array}
\]
Together with the $T\LIST_{\Unit,X\LIST}$-algebra $\switch_{X\LIST}:X\LIST +
X\LIST\lens X\LIST$, this
furnishes a bidirectional version of the familiar tail recursive
list reversal that sends $(\mathit{acc},xs)$ to
$\mathit{xs}^{\mathit{rev}}\mathit{acc}$.

\paragraph{Trees}
For set $X$ let $\Tree(X)$ be the set of binary $X$-labeled trees given
inductively by $\Leaf \in \Tree(X)$ and $x \in X, \ell \in \Tree(X), r \in \Tree(X) \Rightarrow \Node(x,\ell,r) \in Tree(X)$.
Consider the endofunctor \iffull $T^{Tree}_X$ given by \fi $T^{Tree}_X(Z)$ =
$\Unit + X \times Z \times Z$. Let $c \in T^\Tree_X(\Tree(X)) \lens
\Tree(X)$ denote the obvious bijective lens.  

An $X$-tree algebra is a lens $\ell \in T^\Tree_X(Z)\lens Z$
and a function $w \in Z\rightarrow \mathbb{N}$ 
 with the property that if 
$\ell.\putl(z,c) = (\mlinr(x,z_l,z_r),c')$
 then $w(z_l) < w(z)$ and $w(z_r) < w(z)$. 
%
The bijective lens $c$ is then the initial object in the category of
$X$-tree algebras; that is, every $X$-tree algebra on $Z$ defines a unique
lens in $\Tree(X)\lens Z$.

Consider, for example, the concatenation lens
$\mathit{concat}:X\LIST \times X\LIST\lens X\LIST$. Let\label{concatprime}
$\mathit{concat'}:\Unit + X \times X\LIST \times X\LIST \lens
X\LIST$ be the lens obtained from $\mathit{concat}$ by precomposing
with the fold-isomorphism and the terminal lens $\const_{\NIL}$.
Intuitively, this lens sends $\mlinl\unit$ to $\NIL$ and $x,xs,xs'$ to
$x \CONS xs @ xs'$, using the complement to undo this operation
properly. This lens forms an example of a tree algebra (with number of
nodes as weight functions) and thus iteration furnishes a lens
$\Tree(X)\lens X\LIST$ which does a pre-order traversal, keeping enough
information in the complement to rebuild a tree from a modified traversal.

The hylomorphism pattern can also be applied to trees,
yielding the ability to define symmetric lenses by
divide-and-conquer, i.e., by dispatching one call to two parallel
recursive calls whose results are then appropriately merged.


%% \ell \in Lens(T^{Tree}_X(Z),Z) there is a unique lens \IT(\ell) \in Lens(Tree(X),Z)
%% such that the following diagram commutes. 

%%                                   bij(c)
%%      Unit + X * Tree(X) * Tree(X) -------> Tree(X)
%%                       |                      |
%%    Unit+X*\IT(\ell)*\IT(\ell) |                      | \IT(\ell)
%%                       |                      |
%%                       V                      V
%%                 Unit + X * Z *Z  ----------> Z
%%                                       \ell

%% Proof: This is analogous to the proof of Theorem [Lists]. 

%% We define the lens \IT(\ell) explicitly. For set S let St (to the t)
%% denote infinite binary trees over S. If s \in S and ssl \in St and ssr \in St we
%% write Node(s,ssl,ssr) \in St for the infinite tree whose root is
%% labelled s and whose left and right subtrees are ssl, ssr. If s \in S then
%% st \in St is the infinite binary tree satisfying st = Node(s,st,st).

%% \IT(\ell).C = \ell.Ct
%% \IT(\ell).\missing = \ell.\missingt 
%% \IT(\ell).\putr(Leaf,Node(c,csl,csr) = let (z,c') := \ell.\putr(\inl(),c) in 
%%                        (z,Node(c',csl,csr))
%% \IT(\ell).\putr(Node(x,xsl,xsr),Node(c,csl,csr)) =
%%         let (zl,csl') := \IT(\ell).\putr(xsl,csl) in
%%         let (zr,csr') := \IT(\ell).\putr(xsr,csr) in
%%         let (z',c') := \ell.\putr(\inr(x,zl,zr),c) in
%%                           (z',Node(c',csl',csr'))
%% \IT(\ell).\putl(z,Node(c,csl,csr)) = match \ell.\putl(z,c) with 
%%                           (\inl(),c') -> (\NIL,Node(c',csl,csr))
%%                         | (\inr(x,zl,zr),c') -> 
%%                                let (xsl,xsl') := \IT(\ell).\putl(zl,csl) in
%%                                let (xsr,csr') := \IT(\ell).\putl(zr,csr) in
%%                                     (Node(x,xsl,xsr), Node(c',csl',csr'))

%% The verification of roundtrip laws and commutativity are again direct
%% from the definition. 
%% As for uniqueness let k \in Lens(X*, Z) be another lens for which the
%% diagram commutes. I.e. 

%%                                   bij(c)
%%      Unit + X * Tree(X) * Tree(X) -------> Tree(X)
%%             |                                |
%%  Unit+X*k*k |                                | k
%%             |                                |
%%             V                                V
%%      Unit + X * Z * Z  --------------------> Z
%%                                  \ell

%% Let R <= k.C * (\ell.C * k.C * k.C) be a simulation relation witnessing
%% commutativity. Commutativity means that 

%%       ---------------------------------------------------
%%        (k.\missing, (\ell.\missing, k.\missing, k.\missing)) \in R

%%         (d,(c,dl,dr)) \in R    k.\putr(Leaf,d)=(z,d1)    \ell.\putr(\inl(),c)=(z,c1)
%%      ------------------------------------------------------------------------
%%                         (d1,(c1,dl,dr)) \in R

%%         (d,(c,dl,dr)) \in R    k.\putr(Node(x,xsl,xsr),d)=(z,d1)  
%%                   k.\putr(xsl,dl)=(z,dl1)  k.\putr(xsr,dr)=(z,dr1)
%%             \ell.\putr(\inr(x,z),c)=(z',c1)
%% ---------------------------------------------------------------------------
%%                         (d1,(c1,dl1,dr1)) \in R

%% and analogous laws for putl. 


%% In order to show that \IT(\ell) = k we define a relation S <= \IT(\ell).C * k.C
%% inductively by the following rules: 

%%                                  (d,(c,dl,dr)) \in R  (csl,dl) \in S (csr,dr) \in S
%% -----------------------------    --------------------------------------------  
%% (\IT(\ell).\missing,k.\missing) \in S            (Node(c,csl,csr),d) \in S


%% Again, if (Node(c,csl,csr),d) \in S no matter by which rule then there exists
%% dl, dr such that (d,(c,dl,dr)) \in R and (csl,dl) \in S and (csr,dr) \in S.

%% The remaining verifications are now analogous to the case of lists. 
%% End of proof. 




%% 3. Forgetful lists:
%% ------------------

%% There is actually another tensor product on the category of lenses
%% which is disjoint union on objects. Given lenses \ell \in Lens(X,Y) and
%% k \in Lens(Z,W) one defines a lens \ell +a k \in Lens(X+Z, Y+W) as follows: 

%%  [ include definition of the forgetful sum from the Coq ] 


%% Definition: The endofunctor T^aList_A on the category of lenses sends
%% \ell \in Lens(X,Y) to Unit +a A*X tp Unit +a A*Y. 

%% An forgetful  A-list algebra is a set Z and a  lens
%% \ell \in Lens(T_aList(Z),Z). Note that no weight function is required here. 

%% Theorem: Let \ell,Z be an T^aList_A-algebra. There is a unique lens
%% \IT(\ell) \in Lens(A*, Z) such that the following diagram commutes:

%%                     bij(c)
%%       Unit + A * A* -------> A*
%%              |               |
%% Unit+aA*\IT(\ell)|               |\IT(\ell)
%%              |               |
%%              V               V
%%       Unit + A * Z  -------> Z
%%                        \ell

%% In other words, bij(c) is the initial T^aList_A algebra. 

%% Proof of Theorem: 

%% We define \IT(\ell) explicitly: 

%% f \in \ell.C* -> \ell.C * \ell.C*
%% f(\NIL) = (\ell.\missing,\NIL)
%% f(c\CONS{}cs) = (c,cs)

%% \IT(\ell).C = \ell.C * \ell.C* 
%% \IT(\ell).\missing = (\ell.\missing,[\ell.\missing])

%% \IT(\ell).\putr(\NIL,(c,cs)) = let (z,c') = \ell.\putl(\inl(),c) 
%%                         in (z,(c',\NIL)) 

%% \IT(\ell).\putr(a\CONS as,(c,cs)) = 

%% (missing text here?)


\iflater
\paragraph*{Other Structure}
A -------> X*Y
--------------
 A*X -----> Y


Lens_C(X,Y) ----> Lens_F(C)(X,Y)

C = F(C) largest fixpoint

Bottom Lens

split : A* ---> Option(A * A* * A*)

reversing containers







\begin{itemize}
\item \PENDING{What about exponentials?  (We thought before that they
   probably did not work.)  Can we get any mileage out of the equation
   X -o Y == reverse (X * (reverse Y))?}

(This does not seem so important in the present story...)
\end{itemize}
\fi

\iflater
\subsect{Symmetric String Lenses}

\PENDING{We are postponing all this material for now and just
  promoting union to above}

\begin{itemize}
\item Fix an alphabet and write $\R$ for the set of regular languages over
    that alphabet.
\item For any given language $R \in \R$, we define $\mathit{copy}_R = \id_R$.
\item For language $R$ and single string $x$, we define $\mathit{clobber}_{Rx}
    = \const_{Rx}$.
\item concat; let's write $f \in R_1 \splits R_2$ to mean that the languages
    $R_1$ and $R_2$ are uniquely splittable, with $f$ the bijection that
    splits a string (i.e. $f \in R_1 \cdot R_2 \to R_1 \times R_2$)
    \lensdef{concat}
    {\infruleplain
        {
            R_1,R_2,R_3,R_4 \in \R \\
            k \in R_1 \lens R_3 \qquad \ell \in R_2 \lens R_4 \\
            f \in R_1 \splits R_2 \qquad g \in R_3 \splits R_4
        }
        {k . \ell \in R_1 \cdot R_2 \lens R_3 \cdot R_4}
    }
    {k . \ell &=& \bij_f;(k \otimes \ell);\bij_g\op}
\item union: two independent axes, each with two choices
\begin{enumerate}
    \item left- or right-biasing: on the first put, if the thing
        we put is in both languages, should we use the left lens or the
        right lens?
    \item forgetful or elephant: when we switch from using the left lens to
        using the right lens, should we remember the complement for the other
        lens or not?
\end{enumerate}
we arbitrarily choose left-biasing (the right-biased versions differ only in
the $\missing$ component), and choose elephant (as it seems simpler and
strictly more useful)
\lensdef{union}
{\infruleplain
    {R_1,R_2,R_3,R_4 \in \R \\ k \in R_1 \lens R_3 \qquad \ell \in R_2 \lens R_4}
    {k | \ell \in R_1 \cup R_2 \lens R_3 \cup R_4}
}
{
    C &=& \Bool \times k.C \times \ell.C \\
    \missing &=& (\false,k.\missing,\ell.\missing) \\
    \putr(r,(y,c_k,c_\ell)) &=& \\
    \colspan{\mlletarray{
        \mllet y' &=& (\lnot y \land r \notin R_1) \lor (y \land r \in R_2) & \mline \\
        \mllet (r',c_k') &=& \cond{
            (r,c_k) & y' \\
            k.\putr(r,c_k) & \lnot y'
        } & \mline \\
        \mllet (r'',c_\ell') &=& \cond{
            \ell.\putr(r',c_\ell) & y' \\
            (r',c_\ell) & \lnot y'
        } & \mline \\
        \colspan{(r'',(y',c_k',c_\ell'))}
    }} \\
    \putl(r,(y,c_k,c_\ell)) &=& \\
    \colspan{\mlletarray{
        \mllet y' &=&  (\lnot y \land r \notin R_3) \lor (y \land r \in R_4) & \mline \\
        \mllet (r',c_k') &=& \cond{
            (r,c_k) & y' \\
            k.\putl(r,c_k) & \lnot y'
        } & \mline \\
        \mllet (r'',c_\ell') &=& \cond{
            \ell.\putl(r',c_\ell) & y' \\
            (r',c_\ell) & \lnot y'
        } & \mline \\
        \colspan{(r'',(y',c_k',c_\ell'))}
    }}
}
\item star; writing $f \in R\starsplit$ to mean that $R$ is uniquely
    splittable and that $f \in R^* \to R\LIST$ is the bijection that splits
    its input,
    \lensdef{star}
    {\infruleplain
        {R_1,R_2 \in \R \qquad \ell \in R_1 \lens R_2 \qquad f \in R_1\starsplit \qquad g \in R_2\starsplit}
        {\ell^* \in R_1^* \lens R_2^*}
    }
    {
        \ell^* &=& \bij_f;\ell\LIST;\bij_g\op
    }
\item We also keep the compose operation, defined identically to the above.
\end{itemize}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Containers}\label{contain}

The previous section suggests a construction for a variety of operations on
datatypes built from polynomial functors. Narrowing the focus to the very
common ``map'' operation, we can generalize still further, to any kind of
\emph{container functor}~\cite{abbott2003categories}, i.e. a \emph{normal
functor} in the terminology of Hasegawa~\cite{hasegawa2002two} or an
\emph{analytic functor} in the terminology of
Joyal~\cite{joyal1986foncteurs}.  (These structures are also related to the
{\em shapely types} of Jay and Cockett~\cite{DBLP:conf/esop/JayC94}.) 

\begin{defn}[Container]
A {\em container} consists of a set $I$ together with an $I$-indexed family
of sets $B \in I \arrow \mathit{Set}$.  
\end{defn}

Each container $(I,B)$ gives rise to an endofunctor $F_{I,B}$ on
\SET{} whose object part is defined by $F_{I,B}(X) = \sum_{i\in I}
B(i)\arrow X$.  For example, if $I = \NAT$ and $B(n) =
\{0,1,\ldots,n\mathord{-}1\}$, then $F_{I,B}(X)$ is
$X\LIST$ (up to isomorphism).  Or, if $I = \mathit{Tree}(\Unit)$ is the set of binary trees with
trivial labels and $B(i)$ is the set of nodes of $i$, then $F_{I,B}(X)$ is
the set of binary trees labeled with elements of $X$.
%
In general, we can think of $I$ as a
set of shapes and, for each shape $i\in I$, we can think of $B(i)$ as the
set of ``positions'' in shape $i$. So an element $(i,f) \in F_{I,B}(X)$
consists of a shape $i$ and a function $f$ assigning an element $f(p)\in X$
to each position $p\in B(i)$.
\iffull

\fi
The arrow part of $F_{I,B}$ maps a function $u\in X\arrow Y$ 
to a function $F_{I,B}(u) \in F_{I,B}(X) \arrow F_{I,B}(Y)$ given by $(i,f)
\mapsto (i,f;u)$. 

Now, we would like to find a way to view a container as a functor on the
category of lenses.  In order to do this, we need a little extra structure.

\iffull\ifcomplement
\begin{defn}[Container with ordered shapes]
\else
\begin{defn}
\fi\else
\begin{defn}
\fi
A {\em container with ordered shapes} is a pair $(I,B)$ satisfying these
conditions:
\begin{longenum}
\item $I$ is a partial order with binary meets. We say $i$ is a
\emph{subshape} of $j$ whenever $i \le j$.
\item $B$ is a functor from $(I,\leq)$ viewed as a
category (with one object for each element and an arrow from $i$ to $j$ iff
$i\leq j$) into \SET{}.  When $B$ and $i$ are understood, we simply write
$b|i'$ for $B(i\leq i')(b)$ if $b\in B(i)$ and $i\leq i'$.
\item If $i$ and $i'$ are both subshapes of a common shape $j$ and we have
positions $b\in B(i)$ and $b'{\in}B(i')$ with $b|j = b'|j$, then there must
be a unique $b_0{\in}B(i{\wedge}i')$ such that $b=b_0|i$ and $b'=b_0|i'$.
Thus such $b$ and $b'$ are really the same position.
In other words, every diagram of the following form is a pullback:
\begin{center}
\tikz \draw[node distance=5em]
  node              (ul) {$B(i\wedge i')$}
  node[below=2em of ul] (ll) {$B(i')$}
  node[right=8em of ul] (ur) {$B(i)$}
  node[below=2em of ur] (lr) {$B(j)$}
  (ul) edge[->] node[above] {$B(i\wedge i'\leq i)$} (ur)
  (ul) edge[->] node[left]  {$B(i\wedge i'\leq i')$} (ll)
  (ur) edge[->] node[right] {$B(i\leq j)$} (lr)
  (ll) edge[->] node[below] {$B(i'\leq j)$} (lr)
  ;
\end{center}
% \vspace*{-\medskipamount}
%
\end{longenum}
\end{defn}

If $i\leq j$, we can apply the instance of the pullback diagram where $i=i'$
and hence $i\wedge i'=i$ and deduce that $B(i\leq j) \in B(i) \arrow B(j)$
is always injective.

For example, in the case of trees, we can define $t\leq{}t'$ if every path from
the root in $t$ is also a path from the root in $t'$. The arrow part of
$B$ then embeds positions of a smaller tree canonically into positions of a
bigger tree. The meet of two trees is the greatest common subtree starting
from the root.

\breakifoverfraction{0.7}

We remark that this ordered version of containers has been independently and in the meantime been discovered and studied by Ahman et al. \cite{ahman2012container}. 

\begin{defn}[Container mapping lens]\ 
\lensdef{container_map}
{\infruleplain{\ell \in X \lens Y}{F_{I,B}(\ell) \in F_{I,B}(X) \lens
F_{I,B}(Y)}}
{
C = \\\colspan{\mlletarray{
  \{t \in \prod_{i\in I}B(i)\arrow \ell.(C) \mid \\
  \ \ 
  \forall i, i'.\; i\leq{}i' \Rightarrow \forall b{\in}B(i).\;
  t(i')(b|i')=t(i)(b)\} 
  }}
\\
\missing(i)(b) &=& \ell.\missing
\\
\putr((i,f),t) &=& \\\colspan{\mlletarray{
    \mllet f'(b) &=& \mlfst(\ell.\putr(f(b),t(i)(b))) & \mline \\
    \mllet t'(j)(b) &=& \\\colspan{\mlletarray{
        \quad\mlif\exists b_0 \in B(i \wedge j).\ b_0|j = b \\
        \quad\mlthen \mlsnd(\ell.\putr(f(b_0|i),t(j)(b))) \\
        \quad\mlelse t(j)(b)
    }} & \mline \\
    \colspan{((i,f'),t')}
}}
\\
\putl && \mbox{(similar)}
}
(Experts will note that $C$ is the limit of the contravariant functor $i
  \mapsto (B(i)\arrow \ell.(C))$. Alternatively, we can construe $C$ as the
  function space $D\arrow \ell.(C)$ where $D$ is the colimit of the functor
  $B$. Concretely, $D$ is given by $\sum_{i \in I}B(i)$ modulo the
  equivalence relation $\sim$ generated by $(i,b)\sim (i',b')$ whenever
  $i\leq{}i'$ and $b'=B(i\leq i')(b)$.)
%
\end{defn}

\iffull
\begin{goodlens}
To show that this definition is a lens, we should begin by checking   that it
is well typed---i.e., that the $t'$ we build in $\putr$ really lies in the
complement (the argument for $\putl$ will be symmetric).
%
So suppose that $j\leq{}j'$ and $b{\in}B(j)$.  There are two cases to consider:
\begin{longenum}
\item $b=b_0|j$ for some (unique) $b_0{\in}B(i{\wedge}j)$. Then $b|j' = b_0|j'$
so we are in the ``$\ml{then}$'' branch in both $t'(j')(b|j')$ and
$t'(j)(b)$, and the results are equal by the fact that $t \in C$.
%
%\begin{eqnarray*}
%    t(j')((b_0|j)|j') &=& t(j)(b_0|j) \mbox{ because $t \in C$}\\
%    t(j')(b_0|j') &=& t(j)(b_0|j) \\
%    g(x) &\overset\triangle=& \mlsnd(\ell.\putr(f(b_0|i),x)) \\
%    g(t(j')(b_0|j')) &=& g(t(j)(b_0|j)) \\
%    t'(j')(b_0|j') &=& t'(j)(b_0|j) \\
%    t'(j')(b|j') &=& t'(j)(b)
%\end{eqnarray*}

\item $b$ is not of the form $b_0|j$ for some (unique)
$b_0{\in}B(i{\wedge}j)$. We claim that then $b|j'$ is not of the form
$b_1|j'$ for any $b_1{\in}B(i{\wedge}j')$, so that we are in the
``$\ml{else}$'' branch in both applications of $t'$. Since $t \in C$, this
will conclude the proof of this case. To see the claim, assume for a
contradiction that $b|j' = b_1|j'$ for some $b_1{\in}B(i{\wedge}j')$.
Applying the pullback property to the situation $i{\wedge}j \leq{} j \leq{}
j'$ and $i{\wedge}j \leq{} i{\wedge}j' \leq{} j'$ yields a unique
$b_0{\in}B(i{\wedge}j)$ such that $b=b_0|j$ and $b_1=b_0|(i{\wedge}j')$,
contradicting the assumption.
\end{longenum}
It now remains to verify the lens laws. We will check \rn{PutRL}; the
\rn{PutLR} law can be checked similarly. Suppose that
\begin{eqnarray*}
    F_{I,B}(\ell).\putr((i,f),t) &=& ((i,f_r),t_r) \\
    F_{I,B}(\ell).\putl((i,f_r),t_r) &=& ((i,f_{rl}),t_{rl})
\end{eqnarray*}
We must check that $f_{rl}=f$ and $t_{rl}=t_r$.

Let us check that $f_{rl}=f$. Choose arbitrary $b \in B(i)$. Then
\dissdis f_{rl}(b) = \mlfst(\ell.\putl(f_r(b),t_r(i)(b))).\dissdis Inspecting the
definition of $t_r$, we find that
$t_r(i)(b)=\mlsnd(\ell.\putr(f(b),t(i)(b)))$, and from the definition of
$f_r$, we find that $f_r(b)=\mlfst(\ell.\putr(f(b),t(i)(b)))$. Together,
these two facts imply that
\[f_{rl}(b) = \mlfst(\ell.\putl(\ell.\putr(f(b),t(i)(b))))\]
Applying \rn{PutRL} to $\ell$, this reduces to $f_{rl}(b)=f(b)$, as desired.

Finally, we must show that $t_{rl}=t_r$. Choose arbitrary $j \in I$ and $b
\in B(j)$. There are two cases: either we have $b_0|j = b$ or not.
\begin{longitem}
    \item Suppose $b_0|j = b$. Then we find that
        \[t_{rl}(j)(b) = \mlsnd(\ell.\putl(f_r(b_0|i),t_r(j)(b)))\]
        Now, inspecting the definitions of $f_r$ and $t_r$, we find that
        this amounts to saying
        \[t_{rl}(j)(b) = \mlsnd(\ell.\putl(\ell.\putr(f(b_0|i),t(j)(b))))\]
        Furthermore, we have $t_r(j)(b) =
        \mlsnd(\ell.\putr(f(b_0|i),t(j)(b)))$, so the \rn{PutRL} law applied
        to $\ell$ tells us that $t_{rl}(j)(b)=t_r(j)(b)$, as desired.
    \item Otherwise, there is no $b_0$ with that property. Then we find
        that $t_{rl}(j)(b)=t_r(j)(b)$ immediately from the definition of
        $t_{rl}$.
\endofpf
\end{longitem}
\end{goodlens}

\begin{lenseqv}
If $R$ witnesses $k \equiv \ell$, then we relate functions that yield
related outputs for each possible input:
\[R_{I,B} = \{(t_k,t_\ell) \mid \forall i,b.\ t_k(i)(b) \relR t_\ell(i)(b)\}\]
For any $i$ and $b$, we can show
\begin{eqnarray*}
F_{I,B}(k).\missing(i)(b) &=& k.\missing \\
k.\missing &\relR& \ell.\missing \\
\ell.\missing &=& F_{I,B}(\ell).\missing(i)(b)
\end{eqnarray*}
so the $\missing$ elements are related by $R_{I,B}$. Now suppose the
following relationships hold:
\[t_k \relRx{I,B} t_\ell\]
\vspace{-4ex} % is there a better way to tie these two paragraphs together?
\begin{eqnarray*}
    F_{I,B}(k).\putr((i,f),t_k) &=& ((i,f_k),t_k') \\
    F_{I,B}(\ell).\putr((i,f),t_\ell) &=& ((i,f_\ell),t_\ell')
\end{eqnarray*}
We must show that $f_k = f_\ell$ and that $t_k'\relRx{I,B}t_\ell'$.
The former follows directly; for any $b$, we have $f_k(b)=f_\ell(b)$ because
$t_k(i)(b) \relR t_\ell(i)(b)$. For the latter, consider an arbitrary $j$
and $b$. There are two cases. If $b_0|j = b$ for some $b_0 \in B(i \wedge
j)$, then $t_k'(j)(b) \relR t_\ell'(j)(b)$ because $k$ and $\ell$ preserve
$R$-states; otherwise, $t_k'(j)(b) \relR t_\ell'(j)(b)$ because
$t_k'(j)(b)=t_k(j)(b)$ and $t_\ell'(j)(b)=t_\ell(j)(b)$.
\end{lenseqv}

\begin{functoriality}
The complete relation (which has only one element) witnesses the equivalence
$F_{I,B}(\id_X)\equiv\id_{F_{I,B}(X)}$. The relation
\[\{(t,(t_l,t_r))\mid\forall i,b.\ t(i)(b)=(t_l(i)(b),t_r(i)(b))\}\]
witnesses the equivalence $F_{I,B}(k;\ell) \equiv F_{I,B}(k);F_{I,B}(\ell)$.
\end{functoriality}
\fi

For the case of lists, this mapping lens coincides with the retentive map
that we obtained from the iterator in \S\ref{iter}.
%
In general, two pieces of data synchronized by one of these mapping lenses
will have exactly the same shape; any shape change to one of the sides will
be precisely mirrored in the other side.
%
For example, the tree version of this lens will transport the deletion of a
node by deleting the node in the same position on the other side.
%
We believe it should also be possible to define a forgetful version where the
complement is just $F_{I,B}(\ell.C)$.

\iffull
The notion of {\em combinatorial species} provides an alternative to the
container framework. One of their attractions is that there are species
corresponding to containers whose $B(i)\arrow X$ family is quotiented by
some equivalence relation; we can obtain multisets in this way, for example.
However, we have not explored this generalization in the case of lenses,
because it is then not clear how to match up positions.
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Asymmetric Lenses as Symmetric Lenses}\label{asymm}

The final step in our investigation is to formalize the connection between
symmetric lenses and the more familiar asymmetric ones, and to
show how known constructions on asymmetric lenses correspond to the
constructions we have considered.

Write $X \alens Y$ for the set of asymmetric lenses from $X$ to $Y$ (using
the first presentation of asymmetric lenses from \S\ref{symm}, with
\GET, \PUT, and \CREATE{} components).  

\iffull
\begin{defn}[Symmetrization]
\else
\begin{defn}
\fi
\label{symmeze}
Every asymmetric lens can be embedded in a symmetric one.
%
\lensdef{symmetrize}
{\infruleplain{\ell \in X \alens Y}{\ell\sym \in X \lens Y}}
{
    C &=& \{f \in Y \to X \mid \forall y \in Y.\ \ell.\aget(f(y)) = y\} \\
    \missing &=& \ell.\acreate \\
    \putr(x,f) &=& (\ell.\aget(x),f_x) \\
    \putl(y,f) &=& \mllet x = f(y) \mlinm (x, f_x) \\
}
(Here, $f_x(y)$ means $\ell.\aput(y,x)$.) Viewing $X$ as the source of an
asymmetric lens (and therefore as having ``more information'' than $Y$), we
can understand the definition of the complement here as being a value from
$X$ stored as a closure over that value. The presentation is complicated
slightly by the need to accommodate the situation where a complete $X$ does
not yet exist---i.e. when defining $\missing$---in which case we can use
$\acreate$ to fabricate an $X$ value out of a $Y$ value if necessary.
\end{defn}

\iffull
\begin{goodlens}
The \rn{CreateGet} law guarantees that $\ell.\acreate \in C$ and the
\rn{PutGet} law guarantees that $f_x \in C$ for all $x \in X$, so we need
merely check the round-trip laws.

\noindent \rn{PutRL}:
\begin{eqnarray*}
    \putl(\putr(x,c))
    &=& \putl(\ell.\aget(x),f_x) \\
    &=& \mllet x' = f_x(\ell.\aget(x)) \mlinm (x', f_{x'}) \\
    &=& \mllet x' = \ell.\aput(\ell.\aget(x),x) \mlinm (x', f_{x'}) \\
    &=& (x, f_x)
\end{eqnarray*}

\noindent \rn{PutLR}:
\begin{eqnarray*}
    \putr(\putl(y,f))
    &=& \putr(\mllet x = f(y) \mlinm (x,f_x)) \\
    &=& \putr(f(y),f_{f(y)}) \\
    &=& (\ell.\aget(f(y)),f_{f(y)}) \\
    &=& (y,f_{f(y)}) 
\end{eqnarray*}

\ifdissertation\vspace{-5.2ex}\fi
\end{goodlens}
\fi

\begin{definition}[Asymmetric lenses]
\iffull
Here are several useful asymmetric lenses (based on string lenses from
\cite{Boomerang07}).

\ifdissertation
\begin{minipage}{0.4\linewidth}
\fi
\lensdef{a_copy}
{\acopy_X \in X \alens X}
{
    \aget(x) &=& x \\
    \aput(x,x') &=& x \\
    \acreate(x) &=& x
}
\ifdissertation
\end{minipage}
\hfil
\begin{minipage}{0.4\linewidth}
\lensdef{a_const}
{\infruleplain{v \in X}{\aconst_v \in X \alens \Unit}}
{
    \aget(x) &=& \unit \\
    \aput(\unit,x) &=& x \\
    \acreate(\unit) &=& v
}
\end{minipage}
\fi%dissertation

\lensdef{a_composition}
{\infruleplain
    {k \in X \alens Y \andalso \ell \in Y \alens Z}
    {k;\ell \in X \alens Z}
}{
    \aget(x) &=& \ell.\aget(k.\aget(x)) \\
    \aput(z,x) &=& k.\aput(\ell.\aput(z,k.\aget(x)),x) \\
    \acreate(z) &=& k.\acreate(\ell.\acreate(z))
}

\ifcomplement
\lensdef{a_const}
{\infruleplain{v \in X}{\aconst_v \in X \alens \Unit}}
{
    \aget(x) &=& \unit \\
    \aput(\unit,x) &=& x \\
    \acreate(\unit) &=& v
}
\fi%complement

\lensdef{a_product}
{\infruleplain
    {k \in X \alens Y \andalso \ell \in Z \alens W}
    {k\cdot\ell \in X \times Z \alens Y \times W}
}{
    \aget(x,z) &=& (k.\aget(x),\ell.\aget(z)) \\
    \aput((y,w),(x,z)) &=& (k.\aput(y,x),\ell.\aput(w,z)) \\
    \acreate((y,w)) &=& (k.\acreate(y),\ell.\acreate(w))
}

\lensdef{a_sum}
{\infruleplain
    {k \in X \alens Y \andalso \ell \in Z \alens W}
    {k|\ell \in X + Z \alens Y \cup W}
}
{
\aget(\mlinl x) &=& k.\aget(x) \\
\aget(\mlinr z) &=& \ell.\aget(z) \\
\aput(yw,\mlinl x) &=& \cond{
    \mlinl k.\aput(yw,x)       & yw \in Y \\
    \mlinr \ell.\acreate(yw)   & yw \in W \setminus Y
    } \\
\aput(yw,\mlinr z) &=& \cond{
    \mlinr \ell.\aput(yw,z)    & yw \in W \\
    \mlinl k.\acreate(yw)      & yw \in Y \setminus W \\
    } \\
\acreate(yw) &=& \cond{
    \mlinl k.\acreate(yw)    & yw \in Y \\
    \mlinr \ell.\acreate(yw) & yw \in W \setminus Y
    }
}

\lensdef{a_iterate}
{\infruleplain{\ell \in X \alens Y}{\ell\LIST \in X\LIST \alens Y\LIST}}
{
\aget(\left<x_1,\ldots,x_n\right>) &=& \left<\ell.\aget(x_1),\ldots,\ell.\aget(x_n)\right> \\
\multicolumn{3}{@{}l}{
\aput(\left<y_1,\ldots,y_m\right>,\left<x_1,\ldots,x_n\right>)
} \\
&=& \left<x_1',\ldots,x_m'\right> \\
\multicolumn{1}{r}{\mbox{where }x_i'} &=& \cond{
    \ell.\aput(y_i,x_i) & i \le \min(m,n) \\
    \ell.\acreate(y_i) & n+1 \le i
    } \\
\acreate(\left<y_1,\ldots,y_n\right>) &=& \left<\ell.\acreate(y_1),\ldots,\ell.\acreate(y_n)\right>
}

\else
Here are several useful asymmetric lenses, based on string lenses from
\cite{Boomerang07}. 
(We give only their names and types here; 
full definitions appear in the long version.) We use
$\ell_{X,Y}$ to stand for any asymmetric lens $\ell \in X \alens Y$.
\begin{eqnarray*}
    \acopy_X &\in& X \alens X \\
    \ell_{X,Y};\ell_{Y,Z} &\in& X \alens Z \\
    \aconst_x &\in& X \alens \Unit \mbox{ whenever } x \in X \\
    \ell_{X,Y}\cdot\ell_{Z,W} &\in& X \times Z \alens Y \times W \\
    \ell_{X,Y}|\ell_{Z,W} &\in& X + Z \alens Y \cup W \\
    \ell_{X,Y}\LIST &\in& X\LIST \alens Y\LIST
\end{eqnarray*}
\fi % full
\end{definition}

\begin{theorem} The symmetric embeddings of these lenses correspond nicely
    to definitions from earlier in this \ifdissertation chapter: \else
    paper: \fi
\setcounter{equation}{0}
\begin{eqnarray}
    \acopy_X\sym        &\equiv& \id_X \\
    (k;\ell)\sym        &\equiv& k\sym;\ell\sym \\
    \aconst_x\sym       &\equiv& \const_x \\
    (k\cdot\ell)\sym    &\equiv& k\sym\otimes\ell\sym \\
    (k|\ell)\sym        &\equiv& (k\sym \oplus^f \ell\sym);\union \\
    (\ell\LIST)\sym     &\equiv& \map^f(\ell\sym)
\end{eqnarray}
The first two show that $(-)\sym$ is a functor. \iffull\else The $\oplus^f$ operator is
the forgetful variant of $\oplus$; see the long version for the full
definition.\fi
\end{theorem}

\iffull
\begin{proof} Throughout the proofs, we will use $a$ to refer to the
left-hand side of the equivalence, and $b$ to refer to the right-hand side.

\begin{longenum}
\item The singleton
relation $\id \relR \unit$ witnesses the equivalence (where here $\id$ is
the identity \emph{function} on $X$). Since $a.\missing(x) =
x$, we have $a.\missing \relR b.\missing$. Furthermore:
\begin{align*}
    a.\putr(x,\id) &= (x,x' \mapsto \acopy_X.\aput(x',x)) \\
    &= (x, x' \mapsto x') \\
    &= (x, \id) \\
    b.\putr(x,\unit) &= (x,\unit) \\
    a.\putl(x,\id) &= (\id(x),x' \mapsto \acopy_X.\aput(x',x)) \\
    &= (x,\id) \\
    b.\putl(x,\unit) &= (x,\unit)
\end{align*}
This establishes that $a.\putr \sim_R b.\putr$ and that $a.\putl \sim_R
b.\putl$.

\item The relation
\[R = \{(f_{k\ell},(f_k,f_\ell)) \mid f_{k\ell} = f_\ell;f_k\}\]
witnesses the equivalence. The fact that $a.\missing \relR b.\missing$ is
immediate from the definitions.

Now, to show that $a.\putr \sim_R b.\putr$, suppose
$f_{k\ell}\relR(f_k,f_\ell)$. We first compute $a.\putr(x,f_{k\ell})$.
\begin{eqnarray*}
    a.\putr(x,f_{k\ell}) &=& ((k;\ell).\aget(x),z \mapsto (k;\ell).\aput(z,x)) \\
    &=& (\ell.\aget(k.\aget(x)), \\
    & & z \mapsto k.\aput(\ell.\aput(z,k.\aget(x)),x)) \\
    &=:& (x_a,f_{k\ell}')
\end{eqnarray*}
And now $b.\putr(x,(f_k,f_\ell))$. We have
\begin{eqnarray*}
    k\sym.\putr(x,f_k) &=& (k.\aget(x),y \mapsto k.\aput(y,x)) \\
    \ell\sym.\putr(k.\aget(x),f_\ell) &=& (\ell.\aget(k.\aget(x)), \\
    & & z \mapsto \ell.\aput(z,k.\aget(x))) 
\end{eqnarray*}
Therefore, $b.\putr(x,(f_k,f_\ell)) = (x_b,(f_k',f_\ell'))$ where
\begin{eqnarray*}
x_b &=& (\ell.\aget(k.\aget(x)))\\
f_k' &=& y \mapsto k.\aput(y,x)\\
f_\ell' &=& z \mapsto \ell.\aput(z,k.\aget(x))) 
\end{eqnarray*}
It's now clear that
\begin{eqnarray*}
    f_k'(f_\ell'(z)) &=& f_k'(\ell.\aput(z,k.\aget(x))) \\
    &=& k.\aput(\ell.\aput(z,k.\aget(x)),x) \\
    &=& f_{k\ell}'(z)
\end{eqnarray*}
and that $x_a=x_b$, so $a.\putr \sim_R b.\putr$.

Finally, to show that $a.\putl \sim_R b.\putl$, suppose again that
$f_{k\ell}\relR(f_k,f_\ell)$.
\begin{eqnarray*}
    a.\putl(z,f_{k\ell})
    &=& \mllet x = f_{k\ell}(z) \mline \\
    & & (x,z'\mapsto(k;\ell).\aput(z',x)) \\
    &=& \mllet x = f_{k\ell}(z) \mline \\
    & & (x,z' \mapsto k.\aput(\ell.\aput(z',k.\aget(x)),x))
\end{eqnarray*}
Similarly,
\begin{eqnarray*}
    \ell\sym.\putl(z,f_\ell)
    &=& \mllet y = f_\ell(z) \mline \\
    & & (y,z' \mapsto \ell.\aput(z',y)) \\
    k\sym.\putl(f_\ell(z),f_k)
    &=& \mllet x = f_k(f_\ell(z)) \mline \\
    & & (x,y' \mapsto k.\aput(y',x)) \\
    b.\putl(z,(f_k,f_\ell))
    &=& (f_k(f_\ell(z)), \\
    & & (y' \mapsto k.\aput(y',f_k(f_\ell(z))), \\
    & & z' \mapsto \ell.\aput(z',f_\ell(z))))
\end{eqnarray*}
Now, we want to show that the first parts of the outputs are equal, that is,
that $f_{kl}(z) = f_k(f_\ell(z))$, which is immediate from
$f_{kl}\relR(f_k,f_\ell)$, and that the second parts of the outputs are
related:
\begin{eqnarray*}
    f_k'(f_\ell'(z')) &=& f_k'(\ell.\aput(z,f_\ell(z))) \\
    &=& k.\aput(\ell.\aput(z,f_\ell(z)),f_k(f_\ell(z)))
\end{eqnarray*}
Observing that
\begin{align*}
    k.\aget(f_k(f_\ell(z))) &= f_\ell(z) && \mbox{because }f_k \in k\sym.C \\
    f_k(f_\ell(z)) &= f_{k\ell}(z) && \mbox{because }f_{k\ell} \relR(f_k,f_\ell),
\end{align*}
that last line becomes
\begin{eqnarray*}
    f_k'(f_\ell'(z'))
    &=& k.\aput(\ell.\aput(z,k.\aget(f_{k\ell}(z))),f_{k\ell}(z)) \\
    &=& f_{k\ell}'(z')
\end{eqnarray*}
so the second parts of the outputs are related after all, and $a.\putl
\sim_R b.\putl$.

\item The relation
\[R = \{(\unit \mapsto c,c) \mid c \in X\}\]
witnesses the equivalence. Since $a.\missing = \unit \mapsto x$ and
$b.\missing = x$, we see $a.\missing \relR b.\missing$.

To show that $a.\putr \sim_R b.\putr$, choose arbitrary $x,c \in X$:
\begin{align*}
    a.\putr(x,\unit \mapsto c) &= (\unit,\unit \mapsto x) \\
    b.\putr(x,c) &= (\unit,x)
\end{align*}
These clearly satisfy $\unit = \unit$ and $(\unit \mapsto x) \relR x$, so we
can conclude that $a.\putr \sim_R b.\putr$.

To show that $a.\putl \sim_R b.\putl$, choose arbitrary $c \in X$ as before.
Then:
\begin{align*}
    a.\putl(\unit,\unit \mapsto c) &= ((\unit \mapsto c)(\unit),u \mapsto
    \aconst_x.\aput(u,(\unit \mapsto c)(\unit)) \\
    &= (c,u \mapsto c) \\
    b.\putl(\unit,c) &= (c,c)
\end{align*}
Now, since  $(u \mapsto c) \relR c$ we conclude
$b.\putl \sim_R b.\putl$.

\item The relation
\[R = \{(f_{k\ell},(f_k,f_\ell)) \mid \forall y,w. f_{k\ell}(y,w)=(f_k(y),f_\ell(w)) \}\]
witnesses the equivalence. We can compute
\begin{align*}
    a.\missing &= (y,w) \mapsto (k.\acreate(y),\ell.\acreate(w)) \\
    b.\missing &= (y \mapsto k.\acreate(y),w \mapsto \ell.\acreate(w)),
\end{align*}
so clearly $a.\missing \relR b.\missing$.

Let us show that $a.\putr \sim_R b.\putr$. Choose $(x,z) \in X \times Z$ and
arbitrary $f_{k\ell},f_k,f_\ell$ (we will not need the assumption that
$f_{k\ell} \relR (f_k,f_\ell)$). Then:
\begin{align*}
    a.\putr((x,z),f_{k\ell}) ={}
    & ((k.\aget(x),\ell.\aget(z)), \\
    & (y,w) \mapsto (k.\aput(y,x),\ell.\aput(w,z))) \\
    b.\putr((x,z),(f_k,f_\ell)) ={}
    & ((k.\aget(x),\ell.\aget(z)), \\
    & (y \mapsto k.\aput(y,x),w \mapsto \ell.\aput(w,z))
\end{align*}
It's clear that the first elements of these tuples are equal, and the second
elements are just as clearly related by $R$, so it is indeed true that
$a.\putr \sim_R b.\putr$.

Similarly, choose $(y,w) \in Y \times W$ and suppose $f_{k\ell} \relR
(f_k,f_\ell)$ -- which in particular means that
$f_{k\ell}(y,w)=(f_k(y),f_\ell(w))$. Then we can define a few things:
\begin{align*}
    (v_a,f_a) ={}
    & a.\putl((y,w),f_{k\ell}) \\
    ={}
    & \mllet (x,z) = f_{k\ell}(y,w) \mline \\
    & ((x,z), (y',w') \mapsto (k.\aput(y',x),\ell.\aput(w',z)) \\
    ={}
    & \mllet (x,z) = (f_k(y),f_\ell(w)) \mline \\
    & ((x,z), (y',w') \mapsto (k.\aput(y',x),\ell.\aput(w',z)) \\
    ={}
    & ((f_k(y),f_\ell(w)), \\
    & (y',w') \mapsto (k.\aput(y',f_k(y)),\ell.\aput(w',f_\ell(w)))) \\
\end{align*}
\begin{align*}
    (v_b,f_b) ={}
    & b.\putl((y,w),(f_k,f_\ell)) \\
    ={}
    & \mllet x = f_k(y) \mline \\
    & \mllet z = f_\ell(w) \mline \\
    & ((x,z),(y' \mapsto k.\aput(y',x),w' \mapsto \ell.\aput(w',z))) \\
    ={}
    & ((f_k(y),f_\ell(w)), \\
    & (y' \mapsto k.\aput(y',f_k(y)),w' \mapsto \ell.\aput(w',f_\ell(w))))
\end{align*}
So $v_a=v_b$ and $f_a \relR f_b$ -- that is, $a.\putl \sim_R b.\putl$.

\item Suppose $k \in X \alens Y$ and $\ell \in Z \alens W$.  Define the
following functions:
\[g \in ((Y \to X) + (W \to Z)) \times (Y \cup W) \to X + Z\]
\begin{align*}
    g(\mlinl f_k,yw) &= \cond{
        \mlinl f_k(yw) & yw \in Y \\
        \mlinr \ell.\acreate(yw) & yw \in W \setminus Y
        } \\
    g(\mlinr f_\ell,yw) &= \cond{
        \mlinr f_\ell(yw) & yw \in W \\
        \mlinl k.\acreate(yw) & yw \in Y \setminus W
        }
\end{align*}
\[\mltag \in (Y \to X) + (W \to Z) \to \Bool\]
\begin{align*}
    \mltag(\mlinl f_k) &= \false \\
    \mltag(\mlinr f_\ell) &= \true
\end{align*}
Then we can define the relation
\[R = \{(g(f),(f,\mltag(f))) \mid f \in (k\sym \oplus^f \ell\sym).C\}.\]
It is tedious but straightforward to verify that this witnesses the
equivalence.
\item $(\ell^*)\sym.C$ comprises functions $f:Y^*\to X^*$ such that
\ifdissertation whenever \fi $f([y_1,\dots,y_n])=[x_1,\dots,x_m]$
\ifdissertation we can conclude \else implies \fi $m=n$ and
$\ell.\aget(x_i)=y_i$.

The complement $\map^f(\ell\sym).C$ on the other hand comprises lists
of functions $[f_1,\dots,f_n]$ where $f_i:Y\to X$ and
$\ell.\aget(f_i(y))=y$. Relate two such complements $f$ and
$[f_1,\dots,f_n]$ if $f([y_1,\dots,y_m])=[x_1,\dots,x_m]$ implies
$x_i=f_i(y_i)$ when $i\leq n$ and $x_i=\ell.\acreate(y_i)$ otherwise. 

Clearly, the two ``missings'' are thus related and it is also easy to see
that $\putr$ is respected. As for the $\putl$ direction consider that
$f$ and $[f_1,\dots,f_n]$ are related and that $ys=[y_1,\dots,y_m]$ is
to be $\putl$-ed. Let $[x_1,\dots,x_k]$ be the result in the
$(f^*)\sym$ direction. It follows $k=m$ and
$[x_1,\dots,x_m]=f([y_1,\dots,y_m])$. If $[x_1',\dots,x_m']$ is the
 result in the
$\map^f(\ell\sym)$ direction then $x_i'=f_i(y_i)$ if $i\leq n$ and
$x_i'=\ell.\acreate(y_i)$ otherwise. Now $x_i=x_i'$  follows by
relatedness. 

The new $(\ell^*)\sym$ complement then is $\lambda
ys.(\ell^*).\aput(ys,xs)$. The new $\map^f(\ell\sym)$ complement is
$[g_1,\dots,g_m]$ where $g_i(y)=\ell.\aput(x_i,y)$. These are clearly
related again. 
\endofpf
\end{longenum}
\end{proof}
\fi

We suspect that there might be an asymmetric $\aIT$ construction
similar to our iteration lens above satisfying an equivalence like
\[\aIT(\ell)\sym \equiv \IT(\ell\sym),\]
but have not explored this carefully.

The $(-)\sym$ functor is not {\em full}---that is,
there are some symmetric lenses which are not the image of any asymmetric
lens. Injection lenses, for example, have no analog in the category of
asymmetric lenses, nor do either of the example lenses presented in the
introduction. However, we \emph{can} characterize symmetric lenses in
terms of asymmetric ones in a slightly more elaborate way.

\iffull
\begin{theorem}[Lenses are spans]\label{asymmetrization_of_lenses}
\else
\begin{theorem}\label{asymmetrization_of_lenses}
\fi
  Given any arrow $\ell$ of \LENS{}, there are asymmetric lenses
  $k_1,k_2$ such that \displayifspace{ (k_1\sym)\op; k_2\sym \equiv \ell.
  } \iffull This suggests that the category \LENS{} could be
  constructed from spans in the category of asymmetric lenses.
  \ifcomplement
  We choose not to try this because
  it makes many things more awkward. While it is possible to define
  composition of spans with a pullback construction, it would---as in
  our account---not be associative unless some equivalence would be
  imposed. However, in the span presentation there does not seem to be
  a natural and easy-to-use candidate for such an equivalence. Of
  course, going back-and-forth via symmetric lenses does induce such
  an equivalence.
  \else
  A full account of the machinery necessary to realize this approach is
  given by Johnson and Rosebrugh~\cite{johnson2014spans}. It is quite
  involved for two reasons: first, composition of spans is typically given
  via a pullback construction, but pullbacks in the appropriate category do
  not always exist, and second, one must develop a span-based analog for our
  lens equivalence to retain associativity of composition.
  \fi%complement
  \fi%full
% \iftext \PENDING{Coq proof} \fi
\end{theorem}

To see this, we need to know how to ``asymmetrize'' a symmetric lens.
\iffull
\begin{defn}[Asymmetrization]
\fi
We can view a symmetric lens as a pair of asymmetric lenses
joined ``tail to tail'' whose common domain is consistent triples.  For any
lens $\ell \in X \lens Y$, define
\iffull\[\else$\fi
S_\ell = \{(x,y,c) \in X \times Y \times \ell.C \mid
\ell.\putr(x,c)=(y,c)\}.
\iffull\]\else$\fi{}
Now define:
%
\lensdef{asymmetrizer}
{\infruleplain
    {\ell \in X \lens Y}
    {\ell\asym_r \in S_\ell \alens X}
}
{
    \aget((x,y,c)) &=& x \\
    \aput(x',(x,y,c))
    &=& \mllet (y',c') = \ell.\putr(x',c) \\
    & & \mlinb (x',y',c') \\
    \acreate(x)
    &=& \mllet (y,c) = \ell.\putr(x,\ell.\missing) \\
    & & \mlinb (x,y,c)
}
\iffull
\lensdef{asymmetrizel}
{\infruleplain
    {\ell \in X \lens Y}
    {\ell\asym_l \in S_\ell \alens Y}
}
{
    \aget((x,y,c)) &=& y \\
    \aput(y',(x,y,c))
    &=& \mllet (x',c') = \ell.\putl(y',c) \\
    & & \mlinb (x',y',c') \\
    \acreate(y)
    &=& \mllet (x,c) = \ell.\putl(y,\ell.\missing) \\
    & & \mlinb (x,y,c)
}
\else
The definition of $\ell\asym_l \in S_\ell \alens Y$ is similar.
\fi % full
\iflater
\finish{
(This is the first lens former we have seen which does not behave nicely with
respect to lens equivalence. Equivalent lenses $k \equiv \ell$ may not lea
to equivalent asymmetrizations. Indeed, the types may not even match up;
$k\asym_r$ and $\ell\asym_r$ will in general have different domains.)
}\bcp{Don't know if this is relevant to the discussion.  Why would we expect
something like this to preserve equivalence?}
\fi
\iffull
\end{defn}
\fi

\iffull
\begin{goodlens} We show only that $\ell\asym_r$ is well-formed; the proof
for $\ell\asym_l$ is similar.

\noindent\rn{GetPut}:
\begin{eqnarray*}
    \aput(\aget((x,y,c)),(x,y,c)) &=& \aput(x,(x,y,c)) \\
    &=& \mllet (y',c') = \ell.\putr(x,c) \\
    & & \mlinb (x,y',c') \\
    &=& (x,y,c)
\end{eqnarray*}
The final equality is justified because $(x,y,c)$ is a consistent triple.

\noindent\rn{PutGet}:
\begin{eqnarray*}
    \aget(\aput(x',(x,y,c)))
    &=& \mllet (y',c') = \ell.\putr(x',c) \\
    & & \mlinb \aget((x',y',c')) \\
    &=& x'
\end{eqnarray*}

\noindent\rn{CreateGet}:
\begin{eqnarray*}
    \aget(\acreate(x))
    &=& \mllet (y,c) = \ell.\putr(x,\ell.\missing) \\
    & & \mlinb \aget((x,y,c)) \\
    &=& x
\end{eqnarray*}

In addition to the three round-trip laws, we must show that $\aput$ and
$\acreate$ yield consistent triples. But this is clear: the \rn{PutR2} law
is exactly what we need.
\end{goodlens}
\fi

\begin{pfof}{\ref{asymmetrization_of_lenses}}
Given \iffull arrow \fi $\EQCLASS{\ell}$, choose $k_1 = \ell\asym_r$ and $k_2 =
\ell\asym_l$.
\iffull
Writing $\ell_r$ for $((\ell\asym_r)\sym)\op$ and $\ell_l$ for
$(\ell\asym_l)\sym$, we then need to show that $\ell_r;\ell_l \equiv \ell$.
Define two functions:
\begin{eqnarray*}
    f_c(x) &=& \mllet (y,c') = \ell.\putr(x,c) \mlinm (x,y,c') \\
    g_c(y) &=& \mllet (x,c') = \ell.\putl(y,c) \mlinm (x,y,c')
\end{eqnarray*}
Then the relation $R = \{((f_c,g_c),c) \mid c \in C\}$ witnesses the
equivalence. We can check the definitions to discover that
\[\ell_r.\missing = \ell\asym_r.\acreate = f_{\ell.\missing}\]
\[\ell_l.\missing = \ell\asym_l.\acreate = g_{\ell.\missing}\]
and hence that $(\ell_r;\ell_l).\missing \relR \ell.\missing$.

We also need to show that $(\ell_r;\ell_l).\putr$ and $\ell.\putr$ are
well-behaved with respect to $R$. Suppose $\ell.\putr(x,c)=(y,c')$; then we
need to show that
\dissdis(\ell_r;\ell_l).\putr(x,(f_c,g_c))=(y,(f_{c'},g_{c'})).\dissdis
First we compute $\ell_r.\putr(x,f_c)$:
\begin{eqnarray*}
    \ell_r.\putr(x,f_c)
    &=& ((\ell\asym_r)\sym)\op.\putr(x,f_c) \\
    &=& (\ell\asym_r)\sym.\putl(x,f_c) \\
    &=& \mllet t = f_c(x) \mlinm (t,x' \mapsto \ell\asym_r.\aput(x',t)) \\
    &=& \mllet (y,c') = \ell.\putr(x,c) \mline \\
    & & ((x,y,c'),x' \mapsto \ell\asym_r.\aput(x',(x,y,c'))) \\
    &=& ((x,y,c'),x' \mapsto \ell\asym_r.\aput(x',(x,y,c'))) \\
    &=& ((x,y,c'),f_{c'})
\end{eqnarray*}
We then compute $\ell_l.\putr((x,y,c'),g_c)$:
\begin{eqnarray*}
    \ell_l.\putr((x,y,c'),g_c)
    &=& (\ell\asym_l)\sym.\putr((x,y,c'),g_c) \\
    &=& (\ell\asym_l.\aget((x,y,c')), \\
    & & y' \mapsto \ell\asym_l.\aput(y',(x,y,c'))) \\
    &=& (y,y' \mapsto \ell\asym_l.\aput(y',(x,y,c'))) \\
    &=& (y,g_{c'})
\end{eqnarray*}
We conclude from this that
$(\ell_r;\ell_l).\putr(x,(f_c,g_c))=(y,(f_{c'},g_{c'}))$ as desired.

The argument that $(\ell_r;\ell_l).\putl$ and $\ell.\putl$ are well-behaved
with respect to $R$ is almost identical.
\fi
\end{pfof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ifdelta
\section{Delta Lenses}

\iftext
Shortcomings of ordinary (state-based) symmetric lenses:
\begin{itemize}
\item inefficient
\item no alignment
\end{itemize}

Write something about ``generic edits'' vs. ``specific edits.''  We are
considering specific edits.

Discuss monoids of edits vs. sets of edits.  Mostly you want just the free
monoid, so then sets of fundamental edits is enough.  But there are some
important cases where the monoid structure is revealing:
\begin{itemize}
\item having a neutral element simplifies the definitions (e.g., the
product: you can just say a product edit is a pair of an edit on the left
instead and an edit on the right, rather than ``an edit on the left OR an
edit on the right OR both...'')
\item the product, for example, does have interesting laws: edits on the
left and on the right don't affect each other
\end{itemize}

Discuss the law making dput compatible with composition.  There is no loss
of power in doing so: we can always ``disable'' the law in particular cases
if desired by taking the free monoid over some other monoid.  \fi

Note that there is a fundamental tension between rich lens languages vs.
rich edit languages.  Here we're exploring the former and keeping the latter
rather basic---just ``rigid edits'' for most of the type constructors plus
insert/delete edits for lists.  Much richer edit languages can be imagined
(even for lists: we might well want to be able to swap the first and second
elements of a list while maintaining their connection to the hidden
information in the other view), but we're not there yet.  Moreover, we don't
know how to generalize the construction of iterators so as to obtain
something more interesting than the completely rigid edit language (without
insert/delete) for lists.

\paragraph*{Definitions}

Recall that a \emph{monoid action} is a function $\cdot \in M \times X \to
X$, where $M$ is a monoid and $X$ is a set, that satisfies two laws:
\begin{eqnarray*}
            1 \cdot x &=& x \\
            (mn)\cdot x &=& m\cdot(n\cdot x)
\end{eqnarray*}
%
A \emph{module} is a triple $\left<M,X,\cdot\right>$ where $M$ is a monoid,
$X$ is a set, and $\cdot$ is a monoid action; when there is no ambiguity, we
will use $M$ to refer to both the module and the monoid in that module, and
we will use juxtaposition to indicate both the monoid multiplication and the
monoid action.
%        
A \emph{module homomorphism} between $\left<M,X,\cdot\right>$ and
$\left<N,Y,\tr\right>$ is a pair $(h,f)$ of a monoid homomorphism $h \in M
\to N$ and a function $f \in X \to Y$ that preserves the edits, that is, for 
which 
\[f(mx) = h(m)f(x).\]

\begin{defn}[Delta lenses]
A $\Delta$-lens $\ell$ mapping from module
        $\left<M,X,\cdot\right>$ to module $\left<N,Y,\tr\right>$, 
        written $\ell \in \left<M,X,\cdot\right> \dlens
        \left<N,Y,\tr\right>$ comprises complement set
        $C$, an element 
        $\missing \in C$, and four functions
        \begin{eqnarray*}
            \putr  &\in& X \times C \to Y \times C \\
            \putl  &\in& Y \times C \to X \times C \\
            \dputr &\in& M \times C \to N \times C \\
            \dputl &\in& N \times C \to M \times C
        \end{eqnarray*}
obeying several laws.  
%
First, we have the same round-trip laws as before for the plain $\PUT$s:
%
        \infrule[PutRL]{\putr(x,c) = (y,c')}{\putl(y,c') = (x,c')}
        \infrule[PutLR]{\putl(y,c) = (x,c')}{\putr(x,c') = (y,c')}
%
Second, $\dputr$ and $\dputl$ must be compatible with the monoid structure:
%
\infax[dputr1]{\dputl(1,c) = (1,c)}
\infax[dputl1]{\dputr(1,c) = (1,c)}
\infrule[dputr$\cdot$]
    {\dputr(m,c) = (n,c') \\ \dputr(m',c') = (n',c'')}
    {\dputr(mm',c) = (nn',c'')}
\infrule[dputl$\cdot$]
    {\dputl(n,c) = (m,c') \\ \dputl(n',c') = (m',c'')}
    {\dputl(nn',c) = (mm',c'')}
%
And third, $\PUT$s and $\DPUT$s must behave consistently:
        \infrule[putr-dputr]{
            \putr(x,c) = (y, c) \\
            \dputr(m,c) = (n,c')
        }
        {\putr(mx,c') = (ny,c')}
        \infrule[putl-dputl]{
            \putl(y,c) = (x, c) \\
            \dputl(n,c) = (m,c')
        }
        {\putl(ny,c') = (mx,c')}
    \finishtext{we should add a note about coercing arbitrary edit languages to
    be monoids via the free monoids, and the compatibility of these laws
    with that construction}
\end{defn}


\paragraph*{Equivalence} The definition of equivalence is a straightforward
generalization of the one for plain symmetric lenses.

\begin{defn}
We say $k \equiv \ell$ if there is a relation $R$ such that
        \begin{enumerate}
            \item $(k.\missing,\ell.\missing) \in R$
            \item $k.\putr \sim_R \ell.\putr$
            \item $k.\putl \sim_R \ell.\putr$
            \item $k.\dputr \sim_R \ell.\dputr$
            \item $k.\dputl \sim_R \ell.\dputl$
        \end{enumerate}
\end{defn}

\PENDING{is it an equivalence relation? seems pretty likely}
\finish{we can skip observational equivalence, I think (BCP)}

We write use $\ell \in X \dLens Y$ for equivalence classes.

\paragraph*{Identity and Composition} Here and below, we give only the
definitions of $\dputr$ and $\dputl$, keeping $C$, $\missing$, $\putr$, and
$\putl$ from the corresponding vanilla lens.

\begin{defn}[Identity]\ 
        \lensdef{w_id}
        {\id_{MX} \in \left<M,X,\cdot\right> \dlens \left<M,X,\cdot\right>}
        {
            \dputr(m,\unit) &=& (m,\unit) \\
            \dputl(m,\unit) &=& (m,\unit)
        }
\end{defn}

\begin{defn}[Composition]\ 
        \lensdef{w_composition}
        {\infruleplain{k \in M \dlens N \qquad \ell \in N \dlens P}{k;\ell \in M \dlens P}}
        {
            \dputr(m, (c_k, c_\ell))
            &=& \mllet (n, c_k') = k.\dputr(m, c_k) \mline \\
            & & \mllet (p, c_\ell') = \ell.\dputr(n, c_\ell) \mline \\
            & & (p, (c_k', c_\ell')) \\
            \dputl(p, (c_k, c_\ell))
            &=& \mllet (n, c_\ell') = \ell.\dputl(p, c_\ell) \mline \\
            & & \mllet (m, c_k') = k.\dputl(n, c_k) \mline \\
            & & (m, (c_k', c_\ell'))
        }
\end{defn}

\PENDING{Conjecture: if $k \equiv k'$ and $\ell \equiv \ell'$, then $k;\ell
        \equiv k';\ell'$}

\PENDING{Conjecture: $\id_{MX};\ell \equiv \ell;\id_{NY} \equiv \ell$}

\paragraph*{Other Simple $\Delta$-lenses}

\begin{defn}[Terminal]
        \lensdef{d_term}
        {\infruleplain
            {x \in X}
            {\const_x \in \left<M,X,\cdot\right> \dlens \left<N,\Unit,\tr\right>}
        }
        {
            \dputr(m,c) &=& (1,mc) \\
            \dputl(n,c) &=& (1,nc)
        }
\end{defn}

\begin{defn}[Disconnect]
$\disconnect_{xy}=\const_x;\const_y\op$.
\end{defn}

\begin{defn}[Bijections]
Given a module homomorphism for which both
        components are bijections, we can define:
        \lensdef{d_bijection}
        {\infruleplain
            {(h,f) \in \left<M,X,\cdot\right> \to \left<N,Y,\tr\right>}
            {\bij_{(h,f)} \in \left<M,X,\cdot\right> \dlens \left<N,Y,\tr\right>}
        }
        {
            \dputr(m,\unit) &=& (h(m),\unit) \\
            \dputl(n,\unit) &=& (h^{-1}(n),\unit)
        }
\end{defn}

\paragraph*{Duality} Similar to the symmetric lens case:

\begin{defn}[Dual]
        \lensdef{w_dual}
        {\infruleplain{\ell \in M \dlens N}{\ell\op \in N \dlens M}}
        {
            \dputr(n, c) &=& \ell.\dputl(n, c) \\
            \dputl(m, c) &=& \ell.\dputr(m, c)
        }
\end{defn}

\PENDING{$(-)\op$ still an involution and a functor?}

\paragraph*{Tensor Product}

\begin{defn}[Tensor product]
Define $\left<M,X,\cdot\right>\times\left<N,Y,\tr\right>$ as
        follows:
        \begin{itemize}
            \item form monoid $M \times N$ where $1=(1,1)$ and $(m,n)(m',n')
                = (mm',nn')$
            \item define monoid action $\dot\tr$ as $(m,n)(x,y) = (mx,ny)$
            \item then form $\left<M \times N,X \times Y,\dot\tr\right>$
        \end{itemize}
Now:
        \lensdef{w_product}
        {\infruleplain{k \in M \dlens P \qquad \ell \in N \dlens Q}{k \otimes \ell \in M \times N \dlens P \times Q}}
        {
            \dputr((m, n), (c_k, c_\ell))
            &=& \mllet (p, c_k') = k.\dputr(m, c_k) \mline \\
            & & \mllet (q, c_\ell') = \ell.\dputr(n, c_\ell) \mline \\
            & & ((p, q), (c_k', c_\ell')) \\
            \dputl((p, q), (c_k, c_\ell))
            &=& \mllet (m, c_k') = k.\dputl(p, c_k) \mline \\
            & & \mllet (n, c_\ell') = \ell.\dputl(q, c_\ell) \mline \\
            & & ((m, n), (c_k', c_\ell'))
        }
\end{defn}

\PENDING{to prove: still a bifunctor, still associative}

\finishtext{To define a more useful diagonal in this setting, we could
  consider enriching the monoid structure with a $\mathit{merge}$
  operation...}

\paragraph*{Tensor Sum}

\begin{definition}[Sum edits]
Given monoids $M$ and $N$ and sets $X$ and $Y$, define the set $E(M,N,X,Y)$
to be their disjoint union, with injections
$\mlstay_l$, $\mlstay_r$, $\mlswitch_l$, and $\mlswitch_r$, respectively.
\end{definition}

\begin{definition}[Edit application]
Given modules $\left<M,X,\cdot\right>$ and $\left<N,Y,\tr\right>$, define
the function $\dot\tr \in E(M,N,X,Y) \times (X + Y) \to X + Y$ as follows:
\begin{eqnarray*}
    \mlstay_lm \dtrrel \mlinl x &=& \mlinl mx \\
    \mlstay_lm \dtrrel \mlinr y &=& \mlinr y \\
    \mlstay_rn \dtrrel \mlinl x &=& \mlinl x \\
    \mlstay_rn \dtrrel \mlinr y &=& \mlinr ny \\
    \mlswitch_lx \dtrrel xy &=& \mlinl x \\
    \mlswitch_ry \dtrrel xy &=& \mlinr y
\end{eqnarray*}
\end{definition}

\begin{definition}[Free monoid action]
Given sets $S$ and $X$ and a function $f \in S \times X \to X$, we can define
the \emph{free monoid action} $f\LIST \in S\LIST \times X \to X$ inductively:
\begin{eqnarray*}
    f\LIST(\left<\right>,x) &=& x \\
    f\LIST(\left<s_1,\ldots,s_n\right>,x) &=& f(s_1,f\LIST(\left<s_2,\ldots,s_n\right>,x))
\end{eqnarray*}
\end{definition}

\begin{definition}[Module addition]
Define
\[\left<M,X,\cdot\right>+\left<N,Y,\tr\right> =
\left<E(M,N,X,Y)\LIST,X+Y,\dot\tr\LIST\right>\]
For the monoid, we could use a more refined monoid than the free one; for
example, we could impose some equalities like
\[\left<\mlstay_lm,\mlstay_ln\right> = \left<\mlstay_l(mn)\right>\]
This can be viewed as an optimization; for simplicity, we do not attempt
these.
\end{definition}

\begin{definition}
Given a function $f \in M \times C \to N \times C$, we can generate a
function $f\LIST \in M\LIST \times C \to N\LIST \times C$ as follows:
\begin{eqnarray*}
    f\LIST(\NIL,c) &=& (\NIL,c) \\
    f\LIST(m \CONS ms,c)
    &=& \mllet (ns, c') = f\LIST(ms, c) \mline \\
    & & \mllet (n, c'') = f(m, c') \mline \\
    & & (n \CONS ns,c'')
\end{eqnarray*}
\end{definition}

\lensdef{d_sum}
{\infruleplain
    {k \in X \dlens Y \andalso \ell \in Z \dlens W}
    {k \oplus \ell \in X+Z \dlens Y+W}
}{
    \dputr(es,c) &=& r\LIST(es,c) \\
    \dputl(es,c) &=& l\LIST(es,c) \\
    \\
    r(\mlstay_lm,(c_k,c_\ell))
    &=& \mllet (n,c_k') = k.\dputr(m,c_k) \mline \\
    & & (\mlstay_ln,(c_k',c_\ell)) \\
    r(\mlstay_rm,(c_k,c_\ell))
    &=& \mllet (n,c_\ell') = \ell.\dputr(m,c_\ell) \mline \\
    & & (\mlstay_rn,(c_k,c_\ell')) \\
    r(\mlswitch_lx,(c_k,c_\ell))
    &=& \mllet (y,c_k') = k.\putr(x,c_k) \mline \\
    & & (\mlswitch_ly,(c_k',c_\ell)) \\
    r(\mlswitch_rz,(c_k,c_\ell))
    &=& \mllet (w,c_\ell') = \ell.\putr(z,c_\ell) \mline \\
    & & (\mlswitch_rw,(c_k,c_\ell')) \\
    \\
    l(\mlstay_ln,(c_k,c_\ell))
    &=& \mllet (m,c_k') = k.\dputl(n,c_k) \mline \\
    & & (\mlstay_lm,(c_k',c_\ell)) \\
    l(\mlstay_rn,(c_k,c_\ell))
    &=& \mllet (m,c_\ell') = \ell.\dputl(n,c_\ell) \mline \\
    & & (\mlstay_rm,(c_k,c_\ell')) \\
    l(\mlswitch_ly,(c_k,c_\ell))
    &=& \mllet (x,c_k') = k.\putl(y,c_k) \mline \\
    & & (\mlswitch_lx,(c_k',c_\ell)) \\
    l(\mlswitch_rw,(c_k,c_\ell))
    &=& \mllet (z,c_\ell') = \ell.\putl(w,c_\ell) \mline \\
    & & (\mlswitch_rz,(c_k,c_\ell')) \\
}

\iflater
\section{Recursive Delta Lenses}

\formartin{Zippers?  Paths?  (relevant paper by McBride --- The Derivative of
  a Regular Type is its Type of One-Hole Contexts)}

%% A_X = {e} union P_X . A_X
%% A_A = P_A union P_x . A_A

%% P_X and P_A are parameters
%% A_X and A_A are defined by these
\fi



\iflater
\section{Delta String Lenses}

\finish{We're probably also suppressing this material.}

\paragraph*{Definitions}

\begin{itemize}
    \item as before, use $\mathit{copy}_R = \id_R$ and $\mathit{clobber}_{Rx} =
        \const_{Rx}$ from normal $\Delta$-lenses (and composition, too)
    \item for concat, we continue to use the $k.\ell = \bij_f;(k \otimes
        \ell); \bij_g\op$ definition for $\dputr$ and $\dputl$
    \item also still use $\ell^* = \bij_f;\ell\LIST;\bij_g\op$

    \PENDING{haven't defined the delta-lens $\ell\LIST$}
    \item Given modules $\M=\left<M,X,\cdot\right>$ and
        $\N=\left<N,Y,\tr\right>$, define the set
        $E_{\M\N}$ as follows
        \infrule{m \in M}{\mlstay_l m \in E_{\M\N}}
        \infrule{n \in N}{\mlstay_r n \in E_{\M\N}}
        \infrule{x \in X \qquad x \notin Y}{\mlswitch_l x \in E_{\M\N}}
        \infrule{y \notin X \qquad y \in Y}{\mlswitch_r x \in E_{\M\N}}
        Define the $\dot\tr \in E_{\M\N} \to X \cup Y \to X \cup Y$
        operation by
        \[\begin{array}{rclr}
            \mlstay_l m \dtrrel x &=& mx & x \in X \\
            \mlstay_l m \dtrrel y &=& y  & y \notin X \\
            \mlstay_r n \dtrrel x &=& x  & x \notin Y \\
            \mlstay_r n \dtrrel y &=& ny & y \in Y \\
            \mlswitch_l x \dtrrel x &=& x \\
            \mlswitch_r y \dtrrel x &=& y
        \end{array}\]
        Finally, define $M|N$ to be the free monoid generated by
        $E_{\M\N}$, lift $\dot\tr$ to be a monoid action
        $\dot\tr\LIST$ in the obvious way, and define the module
        $\M|\N = \left<M|N,X \cup Y,\dot\tr\LIST\right>$.

        \PENDING{go on\dots}
\end{itemize}
\fi

\paragraph*{Lists}

\PENDING{Show the definition of list mapping and filtering with the rich
  edit language with inserts and deletes.  Work out a real example showing
  how an edit would look for a document with nested sections and
  subsections.} 

\paragraph*{Other edits}

\finish{What about swaps and such?  Other kinds of edits?  (To be considered
later, if time allows.)}
\fi % \ifdelta
\ifdissertation
\section{Conclusion}
We have proposed the first notion of symmetric bidirectional transformations
that supports composition. Composability opens up the study of symmetric
bidirectional transformations from a category-theoretic perspective. The
category of symmetric lenses is self-dual and has the category of bijections
and that of asymmetric lenses each as subcategories. We have surveyed
the structure of this category and found it to admit tensor product
structures that are the Cartesian product and disjoint union on objects. We
have also investigated data types both inductively and as ``containers'' and
found the category of symmetric lenses to support powerful mapping and
folding constructs. In the next chapter, we will extend this approach to
address performance---significantly reducing the amount of information a
lens must process---and alignment---giving precise details about the
correspondence between old and new copies of a complex repository.
\fi%dissertation
