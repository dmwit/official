* ###################################################################################
* ###################################################################################
* ##                                                                               ##
* ##                       ANNOTATED HARMONY BIBLIOGRAPHY                          ##
* ##                                                                               ##
* ###################################################################################
* ###################################################################################

Key:
  #  for especially important or interesting papers
  ?  for papers that we still need to read and comment on

BCP: This had gotten too big to be split into separate "inbox" and "read" sections
(and anyway we haven't been clear about moving things between).  So I merged
everything together and just used ? as a marker for things we have not yet read.
Some more tidying and structuring would still be nice.

@STRING{springer =  {Springer-Verlag} }
@STRING{elsevier =  "Elsevier" }
@STRING{entcs    =  "Electronic Notes in Theoretical Computer Science" }
@STRING{lncs =      "Lecture Notes in Computer Science" }


@STRING{cscw     = "{ACM} {C}onference on {C}omputer {S}upported {C}ooperative Work ({CSCW})"}
@STRING{cscw98   = cscw # ", Seattle, Washington"}
@STRING{cscw03   = cscw # ", Helsinki, Finland" }

@STRING{icdt =      "{I}nternational {C}onference on {D}atabase {T}heory ({ICDT})" }
@STRING{icdt90 =    icdt # ", Paris, France" }
@STRING{icdt97 =    icdt # ", Delphi, Greece" }
@STRING{icdt99 =    icdt # ", Jerusalem, Israel" }

@STRING{icfp =      "{ACM} {SIGPLAN} {I}nternational {C}onference on {F}unctional {P}rogramming ({ICFP})" }
@STRING{icfp96 =    icfp # ", Philadelphia, Pennsylvania" }
@STRING{icfp06 =    icfp # ", Portland, Oregon" }
@STRING{icfp08 =    icfp # ", Victoria, British Columbia" }

@STRING{sigmod   =  "{ACM} {SIGMOD} {S}ymposium on {M}anagement of {D}ata ({SIGMOD})" }
@STRING{sigmod77 =  sigmod # ", Toronto, Ontario" }
@STRING{sigmod79 =  sigmod # ", Boston, Massachusetts"}
@string{sigmod96 =  sigmod # ", Montreal, Quebec" }
@STRING{sigmod98 =  sigmod # ", Seattle, Washington" }
@STRING{sigmod01 =  sigmod # ", Santa Barbara, California"}

@STRING{podspre87     = "{ACM} {SIGACT--SIGMOD} {S}ymposium on {P}rinciples of {D}atabase {S}ystems" }
@STRING{pods     = "{ACM} {SIGACT--SIGMOD--SIGART} {S}ymposium on {P}rinciples of {D}atabase {S}ystems" }
@STRING{pods84   = podspre87 # ", Waterloo, Ontario"}
@STRING{pods85   = podspre87 # ", Portland, Oregon"}
@STRING{pods91   = pods # ", Denver, Colorado"}
@STRING{pods94   = pods # ", Minneapolis, Minnesota"}
@STRING{pods95   = pods # ", San Jose, California"}
@STRING{pods98   = pods # ", Seattle, Washington"}
@STRING{pods00   = pods # ", Dallas, Texas"}
@STRING{pods01   = pods # ", Santa Barbara, California"}
@STRING{pods02   = pods # ", Madison, Wisconsin"}
@STRING{pods03   = pods # ", San Diego, California"}
@STRING{pods04   = pods # ", Paris, France"}
@STRING{pods07   = pods # ", Beijing, China"}

@STRING{popl =      "{ACM} {SIGPLAN--SIGACT} {S}ymposium on {P}rinciples of {P}rogramming {L}anguages ({POPL})" }
@STRING{poplpre92 = "{ACM} {S}ymposium on {P}rinciples of {P}rogramming {L}anguages ({POPL})" }

@STRING{popl73 =    poplpre92 # ", Boston, Massachusetts" }
@STRING{popl75 =    poplpre92 # ", Palo Alto, California" }
@STRING{popl76 =    poplpre92 # ", {A}tlanta, {G}eorgia" }
@STRING{popl77 =    poplpre92 # ", Los Angeles, California" }
@STRING{popl78 =    poplpre92 # ", Tucson, Arizona" }
@STRING{popl79 =    poplpre92 # ", San Antonio, Texas" }
@STRING{popl80 =    poplpre92 # ", Las Vegas, Nevada" }
@STRING{popl81 =    poplpre92 # ", Williamsburg, Virginia" }
@STRING{popl82 =    poplpre92 # ", Albuquerque, New Mexico" }
@STRING{popl83 =    poplpre92 # ", Austin, Texas" }
@STRING{popl84 =    poplpre92 # ", Salt Lake City, Utah" }
@STRING{popl85 =    poplpre92 # ", New Orleans, Louisiana" }
@STRING{popl86 =    poplpre92 # ", St.\ Petersburg Beach, Florida" }
@STRING{popl87 =    poplpre92 # ", Munich, Germany" }
@STRING{popl88 =    poplpre92 # ", San Diego, California" }
@STRING{popl89 =    poplpre92 # ", Austin, Texas" }
@STRING{popl90 =    poplpre92 # ", {S}an {F}rancisco, {C}alifornia" }
@STRING{popl91 =    poplpre92 # ", Orlando, Florida" }
@STRING{popl92 =    popl # ", Albuquerque, New Mexico" }
@STRING{popl93 =    popl # ", Charleston, South Carolina" }
@STRING{popl94 =    popl # ", {P}ortland, {O}regon" }
@STRING{popl95 =    popl # ", San Francisco, California" }
@STRING{popl96 =    popl # ", St.~Petersburg Beach, Florida" }
@STRING{popl97 =    popl # ", Paris, France" }
@STRING{popl98 =    popl # ", San Diego, California" }
@STRING{popl99 =    popl # ", San Antonio, Texas" }
@STRING{popl00 =    popl # ", Boston, Massachusetts" }
@STRING{popl01 =    popl # ", London, England" }
@STRING{popl02 =    popl # ", Portland, Oregon" }
@string{popl03 =    popl # ", New Orleans, Louisiana" }
@STRING{popl04 =    popl # ", Venice, Italy" }
@STRING{popl05 =    popl # ", Long Beach, California" }

+@STRING{popl08 =    popl # ", San Francisco, California" }

@STRING{dbpl    =   {Database Programming Languages (DBPL)}}
@STRING{dbpl05 =   dbpl # ", Trondheim, Norway" }

@STRING{jfp    = {Journal of Functional Programming}}

@article   {Focal2005-shortcite,
author       =   "J. Nathan Foster and Michael B. Greenwald and Jonathan T. Moore 
                  and Benjamin C. Pierce and Alan Schmitt",
title        =   "Combinators for Bi-Directional Tree Transformations: 
                  {A} Linguistic Approach to the View Update Problem",
journal      =   toplas,
year         =   "2007",
volume       =   29,
number       =   3,
pages        =   17,
month        =   may,
note         =   "Extended abstract in {\em {P}rinciples of {P}rogramming {L}anguages} ({POPL}), 2005", 
conf         =   "http://www.cis.upenn.edu/~bcpierce/papers/newlenses-popl.pdf",
slides       =   "http://www.cis.upenn.edu/~bcpierce/papers/newlenses-popl-slides.pdf",
TR           =   "http://www.cis.upenn.edu/~bcpierce/papers/newlenses-full.pdf",
plclub       = yes,                  
bcp          =   yes,
keys         =   "harmony",
}

@article         {Sync2007,
author       =   "J. Nathan Foster and Michael B. Greenwald and Christian Kirkegaard
                  and Benjamin C. Pierce and Alan Schmitt",
title        =   "Exploiting Schemas in Data Synchronization",
journal      =   jcss,
year         =   2007,
month        =   jun,
pages        =   {669--689},
number       =   4,
volume       =   73,
note         =   "Extended abstract in 
                  {\em Database Programming Languages (DBPL)} 2005",
}


@manual{harmony-manual,
  title  = {Harmony Programmer's Manual},
  author = {J. Nathan Foster and Benjamin C. Pierce and Alan Schmitt},
  pdf    = {http://www.seas.upenn.edu/~harmony/doc/manual.pdf},
  note   = {Available from \URL{http://www.seas.upenn.edu/~harmony/}},
  year   = 2006,
}

@TechReport{QLenses2008-TR,
  author =       {J. Nathan Foster and Benjamin C. Pierce and Alexandre Pilkiewicz},
  title =        {Quotient Lenses},
  institution =  {Dept. of CIS University of Pennsylvania},
  year =         {2008},
  number =       { MS-CIS-08-08 },
}

@TechReport{Boomerang2007-TR,
  author =       {Aaron Bohannon and J. Nathan Foster and Benjamin C. Pierce and Alexandre Pilkiewicz and Alan Schmitt},
  title =        {Boomerang: Resourceful Lenses for String Data},
  institution =  {Dept. of CIS University of Pennsylvania},
  year =         {2007},
  month =        nov,
  number =       { MS-CIS-07-15 },
}

*
* ###################################################################################
  ###################################################################################
  ##                                                                               ##
* ##                             VIEWS AND VIEW UPDATE                             ##
  ##                                                                               ##
  ###################################################################################
* ###################################################################################

*
* WORK ON BIDIRECTIONAL PROGRAMMING IN THE MODEL TRANSFORMATION COMMUNITY
_____________________________________________________________________________________
**     Hettel et al, Model Synchronisation: Definitions for Round-Trip Engineering 

Model Synchronisation: Definitions for Round-Trip Engineering 
Thomas Hettel, Michael Lawley and Kerry Raymond
http://eprints.qut.edu.au/15331/1/15331.pdf

COMMENTS: Goals very similar to ours, but they seem quite confused about
what we did.  E.g.:

   Foster et al [6] present a model synchronisation approach based on so-called
   lenses, pairs of functions defining the forward and the reverse transformation.
   The forward function solely works on the source structure. Conversely, the reverse
   uses the old source structure and the new target structure to produce a new
   source. Assuming that target models are transient, no changes are allowed that
   cannot be reflected back, effectively confining synchronisation to the semantic
   overlap. Both functions of a lens have to be total and injective, such that every
   change to the target structure can be reflected back to the source.

The fundamental confusion is over what the words "total" and "injective"
mean, I think...

They use an operation-based approach.


*
* BI-DIRECTIONAL AND REVERSIBLE PROGRAMMING LANGUAGES
_____________________________________________________________________________________
**     Landauer, Irreversibility and heat generation in the computing process

Seminal paper on reversible computation.

@article{landauer61,
author = {Rolf Landauer},
title = {Irreversibility and heat generation in the computing process},
journal = {IBM Journal of Research and Development},
volume = {5},
number = {3},
pages = {183--191},
year = 1961,
note = {(Republished in IBM Jour. of Res. and Devel.,
44(1/2):261-269, Jan/Mar. 2000).}}

_____________________________________________________________________________________
**     Bennet, Logical Reversibility of Computation

Demonstrated that any function can be made invertible, by
including its history as part of its output.

@article{bennet73,
author = {Charles H. Bennet},
title = {Logical Reversibility of Computation},
journal = {IBM Journal of Research and Development},
volume = {17},
number = {6},
pages = {525--532},
year = 1973}

_____________________________________________________________________________________
** #   Matsuda et al, Bidirectionalization transformation based on automatic derivation of view complement functions

@inproceedings{matsuda2007btb-dup,
  title={{Bidirectionalization transformation based on automatic derivation of view complement functions}},
  author={Matsuda, K. and Hu, Z. and Nakano, K. and Hamana, M. and Takeichi, M.},
  booktitle=icfp,
  volume={42},
  number={9},
  pages={47--58},
  year={2007},
  publisher={ACM Press New York, NY, USA}
}


_____________________________________________________________________________________
** #   Hu et al, Model Sync ASE 07
@inproceedings{HuASE07,
  author    = {Yingfei Xiong and
               Dongxi Liu and
               Zhenjiang Hu and
               Haiyan Zhao and
               Masato Takeichi and
               Hong Mei},
  title     = {Towards automatic model synchronization from model transformations},
  booktitle = {{IEEE/ACM International Conference on Automated Software
               Engineering (ASE), Atlanta, Georgia}},
  booktitle = {ASE},
  year      = {2007},
  pages     = {164-173},
}

_____________________________________________________________________________________
** #   Mu et al, An Injective Language for Reversible Computation

@inproceedings{Mu2004,
  author = "Shin-Cheng Mu and Zhenjiang Hu and Masato Takeichi",
  title = "An Injective Language for Reversible Computation",
  booktitle = "Seventh International Conference on Mathematics of
  Program Construction (MPC)",
  year = "2004",
  }

[There are three recent papers by these authors; they are listed here in
chronological order.]

BCP: *VERY* relevant to us.  We need to read in (more) detail!

The basic project is very similar to us, with some important differences.
First, they are only interested in oblivious ("bijective") transformations;
second, they work in a relational setting (which makes the syntax a bit hard
to unravel!); third (related), they have no explicit type system, and they
do not deal much with totality/definedness issues.  [Later: I'm not so sure
about the "no type system" point.]  Another point is that they have some
difficulties with implementation, where they get involved with backtracking
even though their programs are semantically deterministic (their APLAS paper
also talks about implementation, but takes a different tack [which looks
rather heavy to me [bcp]!]).

One specific technical point that is not clear to me is their union
operator.  It's a bit like our "cond," with the same heavy type constraint
(the two branches must have disjoint source and target).  But are they
exactly the same?  Do they have anything like our ccond?  Also, how is the
disjointness constraint checked?  Do they envision anything like a type
system, or is it all ad hoc?  (Actually, now that I think about this, I see
it's really quite different from our cond: the branches to their union
operator must be *undefined* on each other's domains.  We don't require
this, since we have an explicit membership test.  Maybe they could do this
too?) 

Their section 6 (which is very related to the APLAS paper) seems more or
less isomorphic to Harmony.

The citations are EXTREMELY useful and thorough, especially since the
paper is quite recent (recent enough to cite us! :-).  In particular, they
cite several reversible programming languages -- Baker's PsiLisp [3], Lutz
and Derby's Janus [18], Frank's R [9], and Zuliani's model based on a
probabilistic guarded command language[27].  We should look at these.

notes from 8 July 2004 meeting:
        * take a Turing complete language Fun.
        * show how Fun programs can be made reversible using similar
          encoding to Bennett's (compute history, pair input with output).
        * no concrete description of put functions
        * no totality claims. clear that not always useful for
          doing view update.

_____________________________________________________________________________________
** #   Hu et al, A Programmable Editor... Based on Bi-directional Transformations

@inproceedings{Hu04-old,
  author = {Zhenjiang Hu and Shin-Cheng Mu and Masato Takeichi},
  title = {A Programmable Editor for Developing Structured
           Documents Based on Bidirectional Transformations},
  year = 2004,
  booktitle = "Partial Evaluation and Program Manipulation (PEPM)",
  pages = {178--189},
  note  = "Extended version to appear in {\em Higher Order and Symbolic
  Computation}, 2008"
  }

BCP: Nate and I wrote detailed comments in a conference review of this
paper.

  SUMMARY: A bi-directional programming language based on the "lenses" of
  Greenwald et al is proposed as the foundation for structured document
  editors in which the user directly manipulates a "view" of an underlying
  document, incrementally building up both the concrete document *and* the
  transformation from it to the view by means of special editing
  operations.

Their language is quite closely based on ours, but they've weakened the lens
laws in some interesting (but not fully explained) ways.

[After a second reading...]
The main differences can be summarized as follows:
  - their main innovation is to introduce a Dup primitive that duplicates
    its input in the get direction; in the put direction, it propagates the
    *edited* copy (it is assumed that at most one of the copies has been
    edited) back to the concrete view
  - since Dup doesn't satisfy the Focal lens laws, they weaken them by
    adding an extra GET or PUT to each one; the new laws are essentially
    (modulo some unclarity about treatment of partiality) the definition of
    a Galois connection
  - their Map combinator is MUCH less interesting than ours -- it cannot
    deal with the case where the domain changes
  - they do not say anything about recursion
  - they define something called Fold, but it actually doesn't seem to have
    much to do with functional language fold combinators (there is no
    "combining" function) -- it's more like a tree-map
  - a minor difference is that their data model is node-labeled and
    ordered

notes from 8 July 2004:
        * two contributions: a language and an editor.
        * language is just Focal (v 2003) + a Dup operator.
        * need to weaken laws to trip and a half laws (for Dup)
        * motivation for Dup is an editing framework. 
            - primarily interacting with abstract view
        * cost is weakened lens laws
            - can code up silly examples that satisfy theirs:
                  - constant in both directions
                  - get = fst, put pairs up abstract with arbitrary element.
        * can stress that merge, not copy, needed for sync.
_____________________________________________________________________________________
** #   Mu et al, An Algebraic Approach to Bi-directional Updating

@inproceedings{MuAlgebraic2004,
  author = {Shin-Cheng Mu and Zhenjiang Hu and Masato Takeichi},
  title = {An Algebraic Approach to Bi-directional Updating},
  booktitle = "ASIAN Symposium on Programming Languages and Systems (APLAS)",
  year = 2004,
  pages = {2--20},
  month = nov,
  }

stored locally as mu-bidirectional.pdf in papers/ToRead/lenses
or: http://www.ipl.t.u-tokyo.ac.jp/~scm/pub/bidirectional.pdf

_____________________________________________________________________________________
** #   Meertens, Designing Constraint Maintainers for User Interaction

@misc{Meertens98,
  author = {Lambert Meertens},
  title = {Designing Constraint Maintainers for User Interaction},
  year = 1998,
  note = "Manuscript"
  }

BCP: very interesting and relevant!

notes from 8 July 2004 meeting
        * framework is more general than ours: 
            - relations, not just functions
            - both directions are symmetric (two argument get)
        * Focal is a special case of his framework but
            - our lenses are partial so we can show that recursion makes sense
            - we add tree combinators, and some new general ones (e.g., ccond)
        * in his setting, changes updated whenever an element is perturbed.

______________________________________________________________________________________
** #   Spoonhower, View Updates Seen Through the Lens of Synchronization

@unpublished{Spoonhower04,
author = "Daniel Spoonhower",
title = "View Updates Seen Through the Lens of Synchronization",
note = "Manuscript",
year = 2004,
}

______________________________________________________________________________________
**  ?? Ross, Running Programs Backwards: The Logical Inversion of Imperative Computation

@article{ ross97running,
    author = "Brian J. Ross",
    title = "Running Programs Backwards: The Logical Inversion of Imperative Computation",
    journal = "Formal Aspects of Computing",
    volume = "9",
    number = "3",
    pages = "331--348",
    year = "1997",
    citeseerurl = "citeseer.ist.psu.edu/ross03running.html" 
}

BCP: I've been unable to get this from his web page.  Have asked him for a copy.
     bross at cosc.brocku.ca (but got no response)
MBGREEN: found it on citeseer, stored locally as ross-inversion.pdf

Appears to be yet another paper on computing function-inverse
(common examples seem to be algorithms for computing
a tree from its traversal, and fibonacci numbers, and sort). The
contribution of this paper is simply the use of logic programming
techniques to construct the inversion.

_____________________________________________________________________________________
**   ? Toffoli, Reversible Computing
in Automata, Languages, and Programming, 1980.

other articles by Toffoli look relevant -- check his pubs

_____________________________________________________________________________________
**   ? Glueck & Kawabe: A Program Inverter for a Functional Language with Equality and Constructors
see papers/ToRead/lenses/gluck-kawabe-PIFLEC.pdf
also  http://www.diku.dk/topps/bibliography/2003.html#D-491

Robert Glück, Masahiko Kawabe: A Program Inverter for a Functional Language with Equality and Constructors. APLAS 2003: 246-264

@InProceedings{GlueckKawabe:03:EQinv,
   AUTHOR       = {Gl{\"u}ck, Robert and Kawabe, Masahiko},
   YEAR         = {2003},
   TITLE        = {A Program Inverter for a Functional Language
                   with Equality and Constructors},
   BOOKTITLE    = {Programming Languages and Systems. Proceedings},
   editor       = {Ohori, Atsushi},
   Location     = {Beijing, China},
   publisher    = {Springer-Verlag},
   series       = {Lecture Notes in Computer Science},
   volume       = {2895},
   pages        = {246--264},
   keywords     = {
  program inversion, functional programming, program transformation},
   summary      = {
     We present a method for automatic program inversion in a first-order
     functional programming language. We formalize the
     transformation and illustrate it with several examples including the
     automatic derivation of a program for run-length decoding from a program
     for run-length encoding. This derivation is not possible with other
     automatic program inversion methods. One of our key observations is that
     the duplication of values and testing of their equality are two sides of
     the same coin in program inversion. This leads us to the design of a new
     self-inverse primitive function that considerably simplifies the
     automatic inversion of programs.},
   URL          = {},
   SEMNO        = {D-491},
   PUF          = {Artikel i proceedings (med censur)},
   ID           = {KonR}
}


_____________________________________________________________________________________
**   ? Abramov & Gluck, Principles of Inverse Computation and the Universal Resolving Algorithm

Sergei M. Abramov, Robert Gl\"uck Principles of Inverse Computation and
the Universal Resolving Algorithm. The Essence of Computation 2002: 269-295

@InCollection{AbrGlu:02:URAF,
   AUTHOR     = {Abramov, Sergei M. and Gl{\"u}ck, Robert},
   YEAR       = {2002},
   TITLE      = {Principles of Inverse Computation and the
                 Universal Resolving Algorithm},
   editor     = {Mogensen, Torben and Schmidt, David and Sudborough, I. Hal},
   BOOKTITLE  = {The Essence of Computation: Complexity, Analysis,
                 Transformation},
   PUBLISHER  = {Springer-Verlag},
   series     = {Lecture Notes in Computer Science},
   volume     = {2566},
   pages      = {269--295},
   keywords   = {inverse programming, perfect process tree,
                 program transformation, semantics modifier,
                 program inversion, functional programming},
   summary    = {We survey fundamental concepts in inverse programming and
     present the Universal Resolving Algorithm (URA), an algorithm for inverse
     computation in a first-order, functional programming language. We discuss
     the principles behind the algorithm, including a three-step approach based
     on the notion of a perfect process tree, and demonstrate our
     implementation with several examples of inverse computation. We explain
     the idea of a semantics modifier for inverse computation which allows us
     to perform inverse computation in other programming languages.},
   SEMNO      = {D-488},
   PUF        = {Bidrag til bog},
   ID         = {Bid}
}

BCP: I tried to read it quickly, but it is rather dense and full of partial
evaluation mumbo-jumbo.  My impression, though, is that it is related and
something we should understand.  Also, it forms part of a *huge* body of
related work that we have not really addressed at all.

An earlier related paper:
**   ? Abramov & Gluck, The universal resolving algorithm: inverse computation in a functional language

    @inproceedings{ abramov00universal,
    author = "Sergei M. Abramov and Robert Gl{\"u}ck",
    title = "The universal resolving algorithm: {I}nverse computation in a functional language",
    booktitle = "Mathematics of Program Construction",
    volume = "1837",
    publisher = "Springer-Verlag",
    editor = "R. Backhouse and J. N. Oliveira",
    pages = "187--212",
    year = "2000",
    citeseerurl = "citeseer.ist.psu.edu/abramov00universal.html" 
}

_____________________________________________________________________________________
**  ?? Abramov & Gluck, Derivation of deterministic inverse programs based on LR parsing

@InProceedings{GlueckKawabe:04:LRinv,
   AUTHOR       = {Gl{\"u}ck, Robert and Kawabe, Masahiko},
   YEAR         = {2004},
   TITLE        = {Derivation of deterministic inverse programs based
                   on {LR} parsing},
   BOOKTITLE    = {Functional and Logic Programming. Proceedings},
   editor       = {Kameyama, Yukiyoshi and Stuckey, Peter J.},
   publisher    = {Springer-Verlag},
   series       = {Lecture Notes in Computer Science},
   volume       = {2998},
   pages        = {291--306},
   keywords     = {program inversion, functional programming,
                   program transformation, LR parsing},
summary      = {We present a method for automatic program inversion of
     functional programs based on methods of LR parsing. We formalize the
     transformation and illustrate it with the inversion of a program for
     run-length encoding. We solve one of the main problems of automatic
     program inversion---the elimination of nondeterminism---by viewing an
     inverse program as a context-free grammar and applying to it methods
     of LR parsing to turn it into a recursive, deterministic inverse
     program. This improves the efficiency of the inverse programs and
     greatly expands the application range of our earlier method for
     program inversion.},
   URL          = {http://www.springerlink.com/link.asp?id=tfaxx9x8mxukcreb},
   SEMNO        = {D-506},
   PUF          = {Artikel i proceedings (med censur)},
   ID           = {KonR}
  }
 
_____________________________________________________________________________________
**  ?  Wei Chen and Jan Tijmen Udding, "Program Inversion: More than fun!"
Science Of Computer Programming, 15(1):1-13, November 1990

_____________________________________________________________________________________
**  ?  something by Abramsky on reversible computation

- Abramsky has apparently written some stuff on reversible
computation.

_____________________________________________________________________________________
**  ?  stuff by Toffoli and others on reversible cellular automata
    
- Toffoli and others have stuff on reversible cellular automata,
if we get interested in that sort of stuff.

_____________________________________________________________________________________
** ?   stuff by Mu that may be (marginally?) relevant

Mu's home page: http://web.comlab.ox.ac.uk/oucl/work/shin-cheng.mu/

Mu and R.S. Bird, "Rebuilding a tree from its traversals: a case
study of program inversion", Proceedings of the 1st Asian Symp. on
Programming Languages and Systems, LNCS # 2895, pp. 265-282,
Springer Verlag, 2003.
 
Mu and R.S. Bird, "Inverting functions as folds" LNCS # 2386, July 2002

_____________________________________________________________________________________
_____________________________________________________________________________________

_____________________________________________________________________________________
**     Ohori and Tajima, A Polymorphic Calculus for Views and Object Sharing

@inproceedings{ ohori94polymorphic,
author = "Atsushi Ohori and Keishi Tajima",
title = "A Polymorphic Calculus for Views and Object Sharing",
booktitle = pods94,
year = "1994",
citeseerurl = "citeseer.nj.nec.com/ohori94polymorphic.html",
summary = {

Ohori and Tajima develop a statically-typed polymorphic record calculus for
defining views on object-oriented databases. They specifically restrict
which fields of a view are updatable, and furthermore restrict that these
mutable fields have a ground (simple) type. The typing rules enforce that
there is a one-to-one correspondence between each updatable location in the
abstract view and a location in the underlying concrete view, so in some way
Hocus Focus is more general. There is also no guarantee that integrity
constraints on the underlying database are satisfied by these updates (so,
for example, it might be possible that their view functions do not satisfy
PutGet, although I don't have an example off the top of my head).

}
}
%booktitle = "{ACM} {PODS}'94",
%pages = "255--266",

_____________________________________________________________________________________
**     Chivers and Paige, XRound: Bidirectional Transformations and Unifications Via a Reversible Template Language

XRound: Bidirectional Transformations and Unifications Via a Reversible Template Language
Howard Chivers and Richard F. Paige

Abstract. Efficient tool support for transformations is a key requirement for the
industrialisation of MDA. While there is substantial and growing support for
unidirectional transformations (e.g., from PIM-to-PSM), for bidirectional
transformations there is little. This paper presents tool support for bidirectional
transformations, in the form of a language, called XRound, for specifying
reversible templates. The language supports round-trip transformations between
UML models and predicate logic. Its supporting tool also implements model
unification, so that new information encoded in logic can be seamlessly
integrated with information encoded in the model.

Stored as harmony/reading/papers-by-others/lenses/chiverspaigeECMDA05.pdf

BCP: This looks like interesting and sensible stuff.  I've given the paper
only a quick read -- not enough to grok details -- but I have the impression
there is something here worth understanding, particularly as we think about
UML model transformation applications.

_____________________________________________________________________________________
_____________________________________________________________________________________

*
* DB PAPERS ON VIEWS AND VIEW UPDATE

_____________________________________________________________________________________
**     Hegner, An order-based theory of updates for closed database views

@book{DateBook,
    author = {C. J. Date},
    title = {An Introduction to Database Systems (Eighth Edition)},
publisher = "Addison Wesley",
year = 2003,
}

_____________________________________________________________________________________
**     Johnson et al, View Updates in a Semantic Data Modelling Paradigm

@inproceedings{JohnsonRosebrughDampney2001,
 author = {Michael Johnson and Robert Rosebrugh and C. N. G. Dampney},
 title = {View updates in a semantic data modelling paradigm},
 booktitle = {ADC '01: Proceedings of the 12th Australasian conference on Database technologies},
 year = {2001},
 isbn = {0-7695-0966-5},
 pages = {29--36},
 location = {Queensland, Australia},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 source = "ACM DL 545541",
 }

_____________________________________________________________________________________
**     Hegner, Uniqueness of Update Strategies for Database Views 

@inproceedings{hegner02uniqueness,
  author = {Stephane J. Hegner},
  title = {Uniqueness of Update Strategies for Database Views},
  booktitle = {Foundations of Information and Knowledge Systems, Second
  International Symposium},
  pages = {230--249},
  volume = {2284},
  year = {2002},
  editor = {Thomas Eiter and Klaus-Dieter Schewe},
  url = {http://www.cs.umu.se/~hegner/Publications/PDF/foiks02.pdf},
  summary = {The problem of supporting updates to views of a database 
    schema has been the focus of a substantial amount of research over the 
    years. Since the mapping from base schema to view schema is seldom 
    injective, there is usually a choice of possibilities for the reflection of 
    view updates to base-schema updates. This work presents a solution to 
    this problem which augments the constant-complement strategy of Ban- 
    cilhon and Spyratos with order-theoretic properties to guarantee unique 
    reflection of view updates. Specifically, most database formalisms endow 
    the database states with a natural order structure, under which update 
    by insertion is an increasing operation, and update by deletion is de- 
    creasing. Upon augmenting the original constant-complement strategy 
    with compatible order-based notions, the reflection to the base schema 
    of any update to the view schema which is an insertion, a deletion, or a 
    modification which is realizable as a sequence of insertions and deletions 
    is shown to be unique and independent of the choice of complement.
  }
} 

BCP comments (I read just the intro): A very pretty and appealing piece of
work, very lucidly explained.  Not 100% relevant for Harmony because it
builds on the constant complement (very well behaved) framework, but well
worth a look.  The basic observation is that demanding that the translation
of an update hold some complement constant doesn't necessarily uniquely pin
down the update translation: there can be different ways of "computing the
complement" that lead to different update translation policies; however,
there is generally (always, he claims) a single "canonical" update
translation, and we want a theory that picks this one out.  This theory is
phrased in the language of "order-preserving morphism":

  The solution utilizes natural order structure. Most data models admit
  an order on the states under which insertions increase the position of
  the state in the order, while deletions decrease it. Furthermore, basic
  data morphisms are typically monotonic under this ordering. For example,
  in the relational model, the natural ordering is de ned by
  relation-by-relation inclusion, while the basic morphism operations of
  projection, selection, and join are monotonic with respect to this
  ordering. The context of this work is that of ordered schemata
  and monotonic morphisms. The central result is that, within this
  restricted context, the translation of insertions and deletions is
  unique, and independent of the particular choice of complement. This is a
  very versatile result, in that it does not depend upon establishing the
  uniqueness of a complement; indeed, it holds even across complements with
  different meets. 

There is also a very interesting and useful discusssion of "closed"
vs. "open" view update situations -- the latter being cases where it is
reasonable to expect that the updater of the view should know about the
rest of the database and be able to reason about the effects of updates on
the whole DB, while the former isolates situations where the updater wants
to think of the view as "all there is."  The latter demands more stringent
restrictions to make sure that users are not surprised: for example, the
PutPut condition makes sense becuase it ensures that all updates are
undo-able.  

_____________________________________________________________________________________
**     Hegner, An order-based theory of updates for closed database views

@article{hegner04order,
    author = {Stephane J. Hegner},
    title = {An order-based theory of updates for closed database views},
    journal = {Annals of Mathematics and Artificial Intelligence},
    pages = {63--125},
    volume = {40},
    year = {2004},
    url = {http://www.cs.umu.se/~hegner/Publications/PDF/amai03.pdf},
    note = {Summary in \emph{Foundations of Information and
               Knowledge Systems}, 2002,
               pp.~230--249.}
}

_____________________________________________________________________________________
**     Hegner, Foundations of canonical update support for closed database views

@inproceedings{hegner90closed,
  author = {Stephen J. Hegner},
  title = {Foundations of canonical update support for closed database views},
  booktitle = icdt90,
  year = {1990},
  isbn = {0-387-53507-1},
  pages = {422--436},
  location = {Paris, France},
  publisher = {Springer-Verlag New York, Inc.},
  address = {New York, NY, USA},
  url = {http://www.cs.umu.se/~hegner/Publications/PDF/icdt90.pdf},
  summary = { From introduction: 
    "Views may be (at least roughly) divided into two distinct classes. An
    open view is designed by the user as a "window" primarily for his
    own convenience. The user of such a view will typically have knowledge
    of and privileges to the entire database schema, or at least a
    substantial part of it. Proper use of such a view requires knowledge of
    the larger supporting schema. A closed view, on the other hand, is
    provided by the system administration to the user, the latter having no
    knowledge of the total system schema beyond that provided through the
    view. In this case, insofar as possible, the view should appear and
    behave as just another schema. Use of such a view must require no
    knowledge of the larger schema. "

    Hegner imposes several conditions on update polcies for closed schema
      u1) the question of which updates are permisible is decided soley
           by the view state and schema without reference to the underlying
           database state
      u2) legal updates should be "axiomatizable and specifiable".  I
            believe this means that updates should be functions.  This 
            different from our work.
      s1) view updates should have minimal, logical, effects on underlying
            database state---we agree.
      s2) updates must be reflected in "a canonical fashion, idependent of
            arbitrary choices."  I think this is a necessary condition for
            very well behavedness.

    This paper foreshadows hegner04order but the work is not nearly as 
    well developed.  Hegner defines the "meet" of views, but in this
    discussion, he does not actually define a latice of views, only states
    it is possible and gives a reference to then unpublished work
    which I think is hegner94unique. 

    I've only skimmed some techinical parts but this seems like the
    main interesting material.
  } 
}

_____________________________________________________________________________________
**     Hegner, Unique complements and decompositions of database schemata

@article{hegner94unique,
 author = {Stephen J. Hegner},
 title = {Unique complements and decompositions of database schemata},
 journal = {J. Comput. Syst. Sci.},
 volume = {48},
 number = {1},
 year = {1994},
 issn = {0022-0000},
 pages = {9--57},
 doi = {http://dx.doi.org/10.1016/S0022-0000(05)80021-2},
 publisher = {Academic Press, Inc.},
 address = {Orlando, FL, USA},
 summary = {Intoduced views as a poset}
 }


_____________________________________________________________________________________
**     Bentayeb and Laurent, View Update Translations in Relational Databases

@inproceedings{bentayeb98translations,
 author = {Fadila Bentayeb and Dominique Laurent},
 title = {View Updates Translations in Relational Databases},
 booktitle = {DEXA '98: Proceedings of the 9th International Conference on Database and Expert Systems Applications},
 year = {1998},
 isbn = {3-540-64950-6},
 pages = {322--331},
 publisher = {Springer-Verlag},
 address = {London, UK},
 summary = {
   Very unpolished.  Bentayeb and Laurent show that given a positive 
   (relational algebra not including set difference) query, E,
   and a tuple, t, you can calculate the the ``inverse image'' of t
   under E. The inverse image is a set of tuples and constraints.

   From the inverse image of t, you can calculated one or more translations
   which of a view update which inserts or deletes t.  If an update has
   precisely one possible translation, it is ``strongly deterministic.''
   If the update has many translations, but one is best for the *current*
   database state, it is ``weakly deterministic.''  Here, best is determined
   by minimizing the number of inserts or deletions.

   If an update is neither strongly nor weakly deterministic, this approach
   cannot make an update to the database state.  B and L suggest handling
   this by materializing (roughly: caching) the view and storing the update
   there.  This seems like a bad idea to me-- I would prefer failure.

   One intersting note: this paper uses a notion of insert-transactions
   and delete-transactions which correspond to the ordered updates Aaron
   proposed for PutPutOrd.  Unfortunately, I don't think their treatement
   will provide any useful techinical insight.
   }
}

_____________________________________________________________________________________
**     Shu, Using Contraint Statisfaction for View Update Translation

@inproceedings{ shu98using,
    author = "H. Shu",
    title = "Using Constraint Satisfaction for View Update Translation",
    booktitle = "European Conference on Artificial Intelligence",
    pages = "33-37",
    year = "1998",
    summary = {
       Both a tech report and journal version are available, but I've not
    tracked them down.
    
       Another paper using contraint satisfaction to do view update.  Shua
    uses a slightly different model than Bentayeb and Laurant.  Shua
    shows a naive encoding of tables and view updates as constraints, then 
    gives a brief overview of how to solve them.  Shua allows users to
    add constraints to model user-level semantics in the update policy.  It 
    appears that each view update requires an expenisive round of contraint
    solving.
   } 
}
 
_____________________________________________________________________________________
**     Abiteboul, On Views and XML

%% views (and update) for Semistructured Data, XML
% mbgreen
@inproceedings{abiteboul99views,
author = "Serge Abiteboul",
title = "On Views and {XML}",
booktitle = "Proceedings of the Eighteenth ACM Symposium on Principles of
  Database Systems",
pages = "1--9",
year = "1999",
publisher = "ACM Press",
citeseerurl = "citeseer.nj.nec.com/abiteboul99views.html",
mbgreencomment = {The author argues that although the data in XML
databases and XML views of databases is often irregular, we
should stick to standard
database technology whenever possible.  In particular, whenever
the data reveals structure or regularity, such structure should be part of the
(semi-structured) data model.  On the other hand, XML views on
the web refer to dynamic data, so we should distribute things a
lot more and provide change notification. This seems to be a
position paper and a summary, and treat the technical issues very
superficially.}
}

_____________________________________________________________________________________
**     Abiteboul et al, Incr Maint for Materialized Views over Semistruct Data

% mbgreen
@inproceedings{ abiteboul98incremental,
author = "Serge Abiteboul and Jason McHugh and Michael Rys and
          Vasilis Vassalos and Janet L. Wiener",
title = "Incremental Maintenance for Materialized Views over Semistructured
         Data",
booktitle = "Proc. 24th Int. Conf. Very Large Data Bases (VLDB)",
year = "1998",
citeseerurl = "citeseer.nj.nec.com/article/abiteboul98incremental.html",
summary = {The main thrust of this paper is improved efficiency
		  of keeping materialized views up-to-date.  The
		  transformation is unidirectional, and requires
		  you to know the specific updates to the
		  concrete view.  The algorithm consists of
		  checking whether each update affects the
		  abstract view and constructing a query to the
		  concrete database to get the info for the
		  abstract view.  The argument is that views look
		  at relatively small portions of the database,
		  and updates touch a relatively small portion of
		  the database, so the intersection of the two will be even
		  smaller.  In such cases, this incremental
		  query-based update is more efficient than
		  regenerating the entire view from scratch.  (If
		  updates cover large portions of the database,
		  then this approach is not relevant.  Nor
		  particularly relevant to our work.}
 }
% month = "24--27~",
% pages = "38--49",

_____________________________________________________________________________________
**     Rowe and Schoens, Data abstractions, views, and updates in RIGEL

@inproceedings{ RoweSchoens79,
    author = "L. Rowe and K. A. Schoens",
    title = "Data abstractions, views, and updates in {RIGEL}",
    booktitle = sigmod79,
    year = "1979",
bcpcomment = {Cited by Dayal and Bernstein as an example of the 'ADT
  approach' to update translation, where the view and its associated
  'update translation function' are defined together.  This sounds
  at least superficially quite similar to what we do; we should check it
  out.},
summary = {
  This paper describes a general purpose language integrating database
  constructs.

  It is mostly unrelated except for the following quote (copied and
  pasted from the pdf):

  For performance and consistency reasons, queries on a view are
  translated into queries on the base relations rather than being
  executed directly on a materialization of the view [Stonebraker 75].
  This translation is possible for all retrievals but not for all
  updates.  Views and updates exist for which no sequence of operations
  on the base relations will produce a correct update when the data is
  accessed through the view (i.e., undefined updates). Other examples
  exist for which more than one sequence of operations will produce a
  correct view update but each produces a very different meaning on the
  underlying data (i.e., ambiguous updates) [Dayal 78]. The problem is
  to decide how view update facilities should be provided in a language.
  There are four possibilities:

  (1) Views may not be updated.
  (2) Views may be updated but the programmer must specify what base
  relation updates are to be executed, i.e., for those updates that are
  to be allowed, the programmer must specify the translation of the
  high-level operation.
  (3) Views may be updated only by updates that can be unambiguously
  translated to base relation updates by some update translation
  algorithm
  (4) Views may be updated and language constructs are provided to allow
  a programmer to specify the translation of ambiguous and undefined
  updates that are not handled by the translation algorithm. i.e, all
  updates are allowed.

  The first alternative was rejected because it seriously restricts the
  utility of views.

  Several attempts were made to formulate language constructs to allow
  programmer-defined augmentations to an update translation algorithm,
  i.e., the fourth alternative. Each attempt introduced significant
  language complexity and, in most cases, resulted in programs that
  would be impractical to execute.

  The third alternative attempts to support arbitrary view updates by
  using the standard update constructs deflned for relations. However,
  should one desire an ambiguous update no convenient notation is
  supplied for the programmer to express that update. Another
  consequence of adopting this alternative is that a programmer would
  not know whether a particular view update was legal until it was
  translated, or in some cases, executed [Stonebraker 75. Astrahan .76.
  Dayal 73].  Moreover, the update translation algorithms depend on the
  view mapping specification which the programmer presumably cannot
  access. The second alternative, on the other hand, acknowledges that
  only a limited set of view updates are possible and provides a way to
  associate the appropriate semantics with the view update expressed as
  a high-level abstract operation. In most applications, because few
  distinct view updates are required, the burden on the programmer to
  specify the translation would be insignificant.  Moreover, data
  independence would be enhanced by the discipline of explicitly coding
  the view updates as high-level operations.  Consequently, the second
  alternative was judged superior to the third alternative.


  Our approach is identical to the second possibility. However, this
  paper does not provide a way to check the consistency of the update
  implementation in relation to the view definition.
},
}
%    pages = "71--81",

_____________________________________________________________________________________
**     Bancilhon and Spyratos, Update Semantics of Relational Views

@article         {DBLP:journals/tods/BancilhonS81,
author       =   {Fran\c{c}ois Bancilhon and Nicolas Spyratos},
title        =   {Update Semantics of Relational Views},
journal      =   "{ACM} {T}ransactions on {D}atabase {S}ystems",
volume       =   6,
number       =   4,
month        =   dec,
year         =   1981,
pages        =   "557--575",
ee           =   {db/journals/tods/BancilhonS81.html},
bibsource    =   {DBLP, http://dblp.uni-trier.de},
bcpcomment   =   {This one looks like it might be very relevant as a
                  source of intuitions and standard terminology!},
abstract = { A database view is a portion of the data structured in a
  way suitable to a specific application. Updates on views must be
  translated into updates on the underlying database. This paper
  studies the translation process in the relational model.

The procedure is as follows: first, a "complete" set of updates is
defined such that (1) together with every update the set contains a
"return" update, that is, one that brings the view back to the
original state; (2) given two updates in the set, their composition is
also in the set.  To translate a complete set, we define a mapping
called a "translator," that associates with each view update a unique
database update called a "translation." The constraint on a
translation is to take the database to a state mapping onto the
updated view. The constraint on the translator is to be a morphism.

We propose a method for defining translators. Together with the
user-defined view, we define a "complementary" view such that the
database could be computed from the view and its complement. We show
that a view can have many different complements and that the choice of
a complement determines an update policy. Thus, we fix a view
complement and we define the translation of a given view update in
such a way that the complement remains invariant ("translation under
constant complement"). The main result of the paper states that, given
a complete set U of view updates, U has a translator if and only if U
is translatable under constant complement.
} }

____________________________________________________________________________________
**     Keller, Comment on Bancilhon and Spyratos's Updated Semantics
                       and Relational Views
  
@article{keller87comment,
 author = {Arthur M. Keller},
 title = {Comment on {B}ancilhon and {S}pyratos' ``{U}pdate semantics
             and relational views''},
 journal = {ACM Trans. Database Syst.},
 volume = {12},
 number = {3},
 year = {1987},
 issn = {0362-5915},
 pages = {521--523},
 doi = {http://doi.acm.org/10.1145/27629.214296},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 summary = { A three page note giving an example of a reasonable update
             policy which does not obey constant complement}
 }


_____________________________________________________________________________________
**     Keller, Choosing a view update translator by dialog at view defn time

@inproceedings{keller86choosing,
author = "A. M. Keller",
title = "Choosing a view update translator by dialog at view definition
  time",
booktitle = "VLDB'86",
year = 1986,
url = "http://www.vldb.org/conf/1986/P467.PDF",
summary = {Keller~\cite{keller86choosing} later proposed allowing users to
  choose an update translator at view definition time by engaging in an
  interactive dialog with the system and answering questions about potential
  sources of ambiguity in update translation.}
}
% pages = "467--474",

_____________________________________________________________________________________
**     Bentayeb and Laurent, View Updates Translations in Relational Databases

@inproceedings{ bentayeb98view,
    author = "Fadila Bentayeb and Dominique Laurent",
    title = "View Updates Translations in Relational Databases",
    booktitle = "Database and Expert Systems Applications",
    pages = "322-331",
    year = "1998",
    schmittacomment = {
This paper shows that, under some (restricted)
circonstances (views defined by positive queries (that do not contain
the difference operator) that use each table at most once), it is
possible to establish a connexion between the inverse of a query for a
tuple t (ie the set of tuples that give t when applying the query to
them, this is said to have been formerly studied) and update
translations.

This is simple in the case of addition: if one adds a tuple to the view,
then one simply computes the inverse of the query at this tuple. If the
result is a singleton set, then it is a strongly deterministic update
(whatever the database is, then one can add the tuples returned by the
inverse and get a minimal modification solution). Otherwise it might be
a weakly deterministic update: compute the modification between the
current state of the DB and the one by adding the tuples for each
possible inverse, and try to see if there is a minimal modification.

Deletion is more complex, but they are able to say what to delete
according to the translation of the inverse of the query for the tuple
that is removed from the view.

The reason I find this paper uninteresting is that it does not say what
to do in the problematic case, when there are several smallest
modifications possible. We could cite this as a recent work on update
translations, but it does not seem to go very far. This might be
interesting to cite if someday we do something on Galois connections and
metrics to choose inverses, though.
    },
    citeseerurl = "citeseer.nj.nec.com/409074.html" 
}

_____________________________________________________________________________________
**     Cosmadakis and Papadimitriou, "Updates of Relational Views"

@article{cosmadakis84updates,
author = {S.~S.~Cosmadakis and Christos H.~Papadimitriou},
title = {Updates of Relational Views},
year = 1984,
journal = {Journal of the {ACM}},
volume = 31,
number = 4,
pages = {742--760}}

_____________________________________________________________________________________
_____________________________________________________________________________________
_____________________________________________________________________________________
**     Lechtenborger, The impact of the constant complement approach towards view updating

@inproceedings{lechtenborger:pods03,
author = {Jens Lechtenb\"orger},
title = {The impact of the constant complement approach towards View updating},
booktitle = pods03,
publisher = {ACM},
pages = {49--55},
month = {June 9--12},
year = 2003,
summary = "This work extends the view update translation under complement by
  establishing that translations of view updates under constant complements
  are possible precisely if view update effects may be undone using further
  view updates."}

We definitely also need to look at [4], [6], [7], and [9] from his
references.  -B

_____________________________________________________________________________________
**     Popa et al, Translating Web Data

@inproceedings{popa02translating,
author = "Lucian Popa and Yannis Velegrakis and Ren{\'{e}}e J. Miller and
  Mauricio A. Hern{\'{a}}ndez and Ronald Fagin",
title = "Translating Web Data",
booktitle = "VLDB'02",
year = 2002,
url = "http://www.almaden.ibm.com/cs/people/lucian/papers/vldb02.pdf",
summary = {Popa {\em et al.}~\cite{popa02translating} describe a system,
Clio, involving automatic generation of XML transformations given concrete
and abstract schemas. However, these transformations handle only the \GET{}
direction of our lenses.
}
}

_____________________________________________________________________________________
**     Chang and Hull, Using witness generators to support bi-directional update betw object-based databases

@inproceedings{changhull:pods95,
author = {Ti-Pin Chang and Richard Hull},
title = {Using witness generators to support bi-directional update between object-based databases},
booktitle = pods95,
publisher = {ACM},
pages = {196--207},
note = {San Jose, CA.},
year = 1995,
schmittacomment= "This paper is about incremental updates of views
when the database change, and extending that technique to isomorphic
databases to have bidirectional updates (ie they assume they have an
isomorphic mapping, and they use it to build an efficient incremental
way to propagate information)."}

_____________________________________________________________________________________
_____________________________________________________________________________________
** ##? Vidal and Winslett, Preserving update semantics in schema integration

http://portal.acm.org/citation.cfm?id=191291&jmp=indexterms&dl=GUIDE&dl=ACM
saved locally as vidal.pdf

@inproceedings{Vidal94,
 author = {V\^ania M. P. Vidal and Marianne Winslett},
 title = {Preserving update semantics in schema integration},
 booktitle = {Proceedings of the third international conference on Information and knowledge management},
 year = {1994},
 isbn = {0-89791-674-3},
 pages = {263--271},
 location = {Gaithersburg, Maryland, United States},
 doi = {http://doi.acm.org/10.1145/191246.191291},
 publisher = {ACM Press},
 }

BCP: How did we miss this one before???  We should read it carefully, and
also do a citeseer check on who has cited it since (it's from 1994).

_____________________________________________________________________________________
** ##? Anthony Tomasic: Determining Correct View Update Translations via Query Containment.

stored locally as TomasicICLPWDD1994.pdf

Workshop on Deductive Databases and Logic Programming 1994: 75-83

Anthony Tomasic, "Correct View Update Translations via Containment," in
Proceedings of the Workshop on Deductive Database and Logic Programming,
Second International Conference on Logic Programming (ICLP), Santa
Margherita Ligure, Italy, also as Gesellschaft für Mathematik und
Datenverarbeitung, GMD-Studien Nr. 231, 1994.   

Abstract  
  Given an intensional database (IDB) and an extension database (EDB), the
  view update problem translates updates on the IDB into updates on the EDB.
  One approach to the view update problem uses a translation langauge to
  specify the meaning of a view update.  In this paper we prove properties of
  a translation language.  This approach to the view update problem studies
  the expressive power of the translation language and the computational cost
  of demonstrating properties of a translation.  We use an active rule based
  database language for specifying translations of view updates.  This paper
  uses the containment of one datalog program (or conjunctive query) by
  another to demonstrate that a translation is semantically correct.  We show
  that the complexity of correctness is lower for insertion than deletion.
  Finally, we discuss extensions to the translation language.

BCP: I's still reading, but my first impression is that this is both very
relevant to us and deeply strange in its view of what is pragmatically
reasonable.  

Reference 17 looks like something we should look at.  (Maybe some others
too.)  The deductive databases people *also* seem to have been looking at
view update!
 

_____________________________________________________________________________________
_____________________________________________________________________________________
_____________________________________________________________________________________
**     Abiteboul et al, A logical view of structure files

url = "http://www.math.tau.ac.il/~milo/ftp/vldbj.ps"

@article{abiteboul98logical,
    author = "Serge Abiteboul and Sophie Cluet and Tova Milo",
title = "A logical view of structure files",
journal = "VLDB Journal",
volume = 7,
number = 2,
    pages = "96--114",
year = 1998,
    citeseerurl = "citeseer.nj.nec.com/abiteboul98logical.html",
summary = {Abiteboul {\em et al.}~\cite{abiteboul98logical} define a system
for bi-directional transformations based around the concept of {\em
structuring schemas} (parse grammars annotated with semantic
information). Although they only consider a subset of our problem (namely,
{\em lossless} schemas that present an isomorphism between concrete and
abstract views), they do present interesting update optimization methods
based around locally translating updates. Their \PUT{} direction consists of
``unparsing'' a new abstract view into a new concrete view, and they show
sufficient conditions on the parsing grammar (\GET{}) that will make it
lossless ({\em i.e.}, an isomorphism).}
}

_____________________________________________________________________________________
_____________________________________________________________________________________

_____________________________________________________________________________________
**     Buneman, Khanna, and Tan, On Propagation of Deletions and Annotations Through Views

@inproceedings   {BunemanKhannaTan2002,
title        =   "On Propagation of Deletions and Annotations Through Views",
author       =   "Peter Buneman and Sanjeev Khanna and Wang-Chiew Tan",
booktitle    =   pods02,
pages        =   "150--158",
year         =   "2002",
url          =   "",
summary      =   {Summary of part of Wang-Chiew's thesis.  The basic results
                  are negative results about complexity of view update in
                  the relational setting for query languages that include both
                  join and either select or project.  Also some tractability
                  results for weaker languages.}
}
% booktitle    =   "Principles of Database Systems (PODS)",

*
* --------------------------------------------------

*
* LENS PROGRAMMING BY EXAMPLE

_____________________________________________________________________________________
**    Yan et al, Data-Driven Understanding and Refinement of Schema Mappings

@article{ yan01datadriven,
    author = "Ling Ling Yan and Ren{\'e}e J. Miller and Laura M. Haas and
    Ronald Fagin",
    title = "Data-driven understanding and refinement of schema mappings",
    journal = "ACM SIGMOD Record",
    volume = "30",
    number = "2",
    pages = "485--496",
    year = "2001",
    citeseerurl = "citeseer.nj.nec.com/yan01datadriven.html" 
}

BCP: Looks really interesting, for when we get back around to lens
programming by example.


*
* MORE PAPERS ON VIEWS (TO BE READ FOR A LATER VERSION OF FOCAL PAPER)

_____________________________________________________________________________________
** #   Abiteboul et al, A database interface for file update

The title is unpromising, but from a scan of the intro it looks like the
 content might be very related.  - BCP

@inproceedings{ abiteboul95database,
    author = "Serge Abiteboul and Sophie Cluet and Tova Milo",
    title = "A database interface for file update",
    pages = "386--397",
    year = "1995",
    citeseerurl = "citeseer.nj.nec.com/abiteboul95database.html",
}

_____________________________________________________________________________________
** ?   <Bunch of papers on databases and views>

% from dan suciu - answering queries using views
@article{halevy01answering,
author = "Alon Halevy",
title = "Answering queries using views: a survey",
journal = "VLDB Journal",
year = 2001,
url = "http://www.cs.washington.edu/homes/alon/site/files/view-survey.ps",
schmittacomment = { Only deals with querying views, does not deal with view
  update. }
}

@inproceedings{levy95answering,
author = "Alon Y. Levy and Alberto O. Mendelzon and Yehoshua Sagiv and
  Divesh Srivastava",
title = "Answering Queries Using Views",
booktitle = pods95,
year = 1995,
url = "http://www.cs.washington.edu/homes/alon/site/files/pods95-views.ps",
schmittacomment = { Only deals with querying views, does not deal with view
  update. }
}

@inproceedings{abiteboul98complexity,
author = "Serge Abiteboul and Oliver M. Duschka",
title = "Complexity of Answering Queries Using Materialized Views",
booktitle = pods98,
year = 1998,
pages = "254--263",
url = "http://logic.stanford.edu/people/duschka/papers/PODS98.ps",
schmittacomment = { Only deals with querying views, does not deal with view
  update. They do mention something slightly related in their future work. }
}

% from dan suciu - incremental view updates
@inproceedings{colby96algorithms,
author = "Latha S. Colby and Timothy Griffin and Leonid Libkin and Inderpal
  Singh Mumick and Howard Trickey",
title = "Algorithms for Deferred View Maintenance",
booktitle = sigmod96,
year = 1996,
pages = "469--480",
url = "http://cm.bell-labs.com/cm/cs/who/libkin/papers/sigmod96b.ps.gz",
schmittacomment = { This paper is about view maintenance: how to regenerate
  a view efficiently when the underlying database has changed. }
}

@INPROCEEDINGS{wol97,
author    = "{Susan Davidson and A. Kosky}",
booktitle = "{Proceedings of the International Conference of Data
  Engineering}",
month     = "{Apr}",
pages     = "{55-65}",
url       = "{ftp://ftp.cis.upenn.edu/pub/papers/db-research/icde97.ps.Z}",
title     = "{WOL: A Language for Database Transformations and Constraints}",
year      = "{1997}"
}

@book{date93guide,
author = "C. J. Date and Hugh Darwen",
title = "A Guide to The SQL Standard, Third Edition",
publisher = "Addison-Wesley Publishing Company, Inc.",
year = 1993,
comment = {Dan Suciu says they have a very hairy definition of when a view
is updateable. Might be worth a look.}
}


_____________________________________________________________________________________
**     Abiteboul, Hull and Vianu, Foundations of Databases: The Logical Level

@book{ahv95foundations,
 editor = {Serge Abiteboul and Richard Hull and Victor Vianu},
 title = {Foundations of Databases: The Logical Level},
 year = {1995},
 isbn = {0201537710},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
 }

_____________________________________________________________________________________
**     <Some random PL stuff (probably not very important)>

% PL stuff
@article{burton93pattern,
author = "F. W. Burton and R. D. Cameron",
title = "Pattern matching with abstract data types",
journal = "Journal of Functional Programming",
volume = 3,
number = 2,
year = 1993,
pages = "171--190"
}

@inproceedings{ erwig96active,
author = "Martin Erwig",
title = "Active Patterns",
booktitle = "Implementation of Functional Languages",
pages = "21-40",
year = "1996",
citeseerurl = "citeseer.nj.nec.com/erwig96active.html" 
}

@inproceedings{palao96new,
author = {P. Palao Gostanza and R. Pe\~{n}a and M. N\'{u}\~{n}ez},
title = "A new look at pattern matching in abstract data types",
booktitle = icfp96,
year = 1996,
pages = "110--121",
rwhurl = "http://www.cs.cmu.edu/~rwh/courses/modules/papers/gostanza-etal96/paper.pdf"
}

_____________________________________________________________________________________
**    Industrial DBMS references

@manual{db2implementation8_1,
  title = "IBM DB2 Universal Database Administration Guide: Implementation",
  year = "2004",
  organization = "International Business Machines Corporation",
  url = "ftp://ftp.software.ibm.com/ps/products/db2/info/vr82/pdf/en_US/db2d2e81.pdf"
}

@manual{oracleadminJune05,
  title = "Oracle Database Administrator's Guide",
  month = "June",
  year = "2005",
  organization = "Oracle",
  author = "Steve Fogel and Paul Lane",
  url = "http://www.oracle.com/pls/db102/portal.portal_db?selected=1"
}


@manual{oraclesqlDec05,
  title = "Oracle Database SQL Reference",
  month = "December",
  year = "2005",
  organization = "Oracle",
  author = "Diana Lorentz",
  url = "http://www.oracle.com/pls/db102/portal.portal_db?selected=1"
}

@manual{sqlserverCreateMaintain,
  title = "Creating and Maintaining Databases",
  organization = "Microsoft",
  series = "MSDN Library",
  url = "http://msdn.microsoft.com/library/default.asp?url=/library/en-us/createdb/cm_8_des_01_116b.asp",
  year = "2005",
}

_____________________________________________________________________________________
**     <Some things cited by dong>

@misc{bailey02event,
author = "James Bailey and Alexandra Poulovassilis and Peter Wood",
title = "An Event-Condition-Action Language for XML",
booktitle = "Proceedings of ACM-WWW Int'l Conf.",
year = 2002,
citeseerurl = "citeseer.nj.nec.com/bailey02eventconditionaction.html",
schmittacomment = { This paper describes Event-Condition-Action for XML to
  update some documents when some other document triggers a condition. This
  does not mention view updating at all. }
}

@techreport{lehti01design,
author = "Patrick Lehti",
title = "Design and Implementation of a Data Manipulation Processor for an
  XML Query Language",
institution = {Teschniche Universit\"{a}t Darmstadt},
type = "Diplomarbeit",
number = "Nr. KOM-D-149",
year = 2001,
url = "http://www.ipsi.fhg.de/~lehti/diplomarbeit.pdf"
}

@mastersthesis{chen97update,
author = "Jianjun Chen",
title = "Update Multidatabase through Object Views",
school = "Iowa State University",
year = 1997,
url = "http://www.cs.wisc.edu/~jchen/thesis.ps",
schmittacomment = { Multidatabase system supporting view update by applying
  the techniques developed in barsalou91updating. }
}

@inproceedings{ling92theory,
author    = {Tok Wang Ling and Mong-Li Lee},
editor    = {G{\"u}nther Pernul and A. Min Tjoa},
title     = {A Theory for Entity-Relationship View Updates},
booktitle = {Entity-Relationship Approach - ER'92, 11th International Conference
             on the Entity-Relationship Approach, Karlsruhe, Germany, October
             7-9, 1992, Proceedings},
publisher = {Springer},
series    = {Lecture Notes in Computer Science},
volume    = {645},
year      = {1992},
isbn      = {3-540-56023-8},
pages     = {262--279}
}

@article{davidson83natural,
author = "James Davidson and S. Jerrold Kaplan",
title = "Natural Language Access to Data Bases: Interpreting Update
Requests",
journal = "American Journal of Computational Linguistics",
volume = 9,
number = 2,
pages = "57--68",
year = 1983,
url = "http://acl.ldc.upenn.edu/J/J83/J83-2001.pdf",
schmittacomment = {
  This paper tries to derive updates to a database according to a request that
  can be interpreted as an update to a view (the request is a natural language
  request that is made according to a view of the world, and that is
  formalized as such in the paper). The paper addresses several problems:
  - figuring out what is the view of the user
  - generate several possible updates to the DB reflecting updates to the view
  - use some heuristics to choose an update to apply or request additional
    information from the user.
  Overall the paper is slightly related, in the sense that id does consider
  the view update problem, but the mechanism to generate updates seem to rely
  a lot on the way the request was made in natural language.
  }
}

@inproceedings{hegner84canonical,
author = "Stephen J. Hegner",
title = "Canonical View Update Support through Boolean Algebras of Components",
booktitle = pods84,
pages = "163--172",
year = 1984,
url = "http://www.cs.umu.se/~hegner/Publications/PDF/pods84.pdf"
}

% things that cite gottlob
@article{ torlone94update,
author = "Riccardo Torlone",
title = "Update Operations in Deductive Databases with Functional
  Dependencies",
journal = "Acta Informatica",
volume = "31",
number = "6",
pages = "573-600",
year = "1994",
citeseerurl = "citeseer.nj.nec.com/520495.html",
jonmcomment = { Describes something similar to view update for deductive
databases (e.g. datalog), where they want to do updates on derived
databases, and use functional dependencies in the base relations to resolve
ambiguity. Probably relevant. }
}

@article{ atzeni92updating,
author = "Paolo Atzeni and Riccardo Torlone",
title = "Updating Relational Databases Through Weak Instance Interfaces",
journal = "ACM Transactions on Database Systems",
volume = "17",
number = "4",
pages = "718--745",
year = "1992",
citeseerurl = "citeseer.nj.nec.com/atzeni92updating.html",
jonmcomment = { weak instance interfaces are something similar to views }
}

_____________________________________________________________________________________
**     <Many references on Schema Matching>

@inproceedings{beeri99schemas,
author = "C. Beeri and T. Milo",
title = "Schemas for Integration and Translation of Structured and
  Semi-Structured Data",
booktitle = icdt99,
year = 1999,
url = "http://www.math.tau.ac.il/~milo/ftp/icdt99-2.ps"
}

@inproceedings{milo98using,
author = {Tova Milo and Sagit Zohar},
title = {Using Schema Matching to Simplify Heterogeneous Data
		  Translation},
booktitle = {{I}nternational {C}onference on {V}ery {L}arge {D}ata {B}ases (VLDB), New York, New York},
year = 1998,
url = {http://citeseer.nj.nec.com/milo98using.html},
mbgreencomment = {This paper focuses on the semi-automatic
		  construction of translators from one data-model
		  to another.  The authors observe/assume that the source and
		  destination schemas almost always contain
		  almost the same components with very similar
		  structure.  They propose a rule-based system to
		  heuristically match each component in the
		  source with a component in the target schema,
		  and automatically construct a translator (again based
		  on rules suggesting translation strategies).
		  If they cannot find a matching (or find
		  multiple matches that they can't disambiguate),
		  then they consult the user.  If they can't
		  translate then they consult the user.  But most
		  of the translations should occur automatically.
		  Data models are represented as forests with labeled nodes
		  (children can be ordered).  Schema models are
		  represented as directed graphs (children can
		  also be ordered).
                  They built a system, TransScm, based on these
		  ideas.}}
%booktitle = {Proc. 24th Int. Conf. on Very Large Data Bases
%		  (VLDB)},
%pages = {122--133},

@misc{cliodemo,
author = "M. Hernandez and R. Miller and L. Haas",
title = "Clio: A semi-automatic tool for schema mapping",
howpublished = "Demo at SIGMOD 2001.",
url = "http://www.almaden.ibm.com/software/km/clio/sigmod02demo.pdf" }

@inproceedings{ doan01reconciling,
author = "AnHai Doan and Pedro Domingos and Alon Y. Halevy",
title = "Reconciling Schemas of Disparate Data Sources: A Machine-Learning Approach",
booktitle = sigmod01,
year = "2001",
citeseerurl = "citeseer.nj.nec.com/doan01reconciling.html",
schmittacomment = {
  Uses machine learning to automatically derive one to one schema matching
  from existing schema matching (to do db integration). This might be related
  to some future work on automatic lens generation. }
}

@inproceedings{ madhavan01generic,
author = "Jayant Madhavan and Philip A. Bernstein and Erhard Rahm",
title = "Generic Schema Matching with {Cupid}",
booktitle = {{I}nternational {C}onference on {V}ery {L}arge {D}ata {B}ases (VLDB), Roma, Italy},
pages = "49--58",
year = "2001",
citeseerurl = "citeseer.nj.nec.com/madhavan01generic.html",
mbgreencomment = {Contains a mini-version of rahm01survey as well
		  as a description of the cupid algorithm.  Cupid
		  is a combination of many other approaches and
		  is designed primarily to work on trees (the
		  penultimate section of the paper extends this
		  to more general structures, too).  It also
		  ``supports'' integrity constraints.  The
		  basic idea behind the translation is to rate
		  linguistic similarity of
		  keywords, and structural similarity of the
		  concrete representation and then do the
		  matching on the similarity ratings.  Black
		  magic. } }

@article{ rahm01survey,
author = "Erhard Rahm and Philip A. Bernstein",
title = "A survey of approaches to automatic schema matching",
journal = "VLDB Journal",
volume = "10",
number = "4",
pages = "334--350",
year = "2001",
citeseerurl = "citeseer.nj.nec.com/rahm01survey.html",
mbgreencomment = {A taxonomy of different schema matching
		  schemes.  Useful as an overview, and a place to
		  start if we want to automatically construct
		  lenses based on schema or examples of the
		  application. .}
}
%journal = "VLDB Journal: Very Large Data Bases",

@inproceedings{ pasula01approximate,
author = "Hanna Pasula and Stuart J. Russell",
title = "Approximate inference for first-order probabilistic languages",
booktitle = "{IJCAI}",
pages = "741-748",
year = "2001",
citeseerurl = "citeseer.nj.nec.com/453370.html",
schmittacomment = { Completely unrelated to what we are doing. },
abstract = {
  A new, general approach is described for approximate inference in
  first-order probabilistic languages, using Markov chain Monte Carlo (MCMC)
  techniques in the space of concrete possible worlds underlying any given
  knowledge base. The simplicity of the approach and its lazy construction of
  possible worlds make it possible to consider quite expressive languages. In
  particular, we consider two extensions to the basic relational probability
  models (RPMs) defined by Koller and Pfeffer, both of which have caused
  difficulties for exact algorithms.  The first extension deals with
  uncertainty about relations among objects, where MCMC samples over
  relational structures. The second extension deals with uncertainty about the
  identity of individuals, where MCMC samples over sets of equivalence classes
  of objects. In both cases, we identify types of probability distributions
  that allow local decomposition of inference while encoding possible domains
  in a plausible way. We apply our algorithms to simple examples and show that
  the MCMC approach scales well.
}
}

_____________________________________________________________________________________
**     <Some additional references on view update>

@inproceedings{tucherman83pragmatic,
author = "L. Tucherman and A. L. Furtado and M. A. Casanova",
title = "A pragmatic approach to structure database design",
booktitle = "VLDB'83",
year = 1983,
jonmcomment = "cited by medeiros and tompa as treating views as abstract
data types"
}

@inproceedings{fagin83semantics,
author = "R. Fagin and J. D. Ullman and M. Y. Vardi",
title = "On the semantics of updates in databases",
booktitle = "Proceedings of 2nd ACM SIGACT-SIGMOD Symposium",
year = 1983,
jonmcomment = "cited by gottlob as background"
}

@inproceedings{chamberlin75views,
author = "Donald D. Chamberlin and Jim Gray and Irving L. Traiger",
title = "Views, Authorization and Locking",
booktitle = "AFIPS National Computer Conference Proceedings",
year = 1975,
pages = "425--430",
summary = "cited by cosmodakis. defines a 'rectangle rule' for defining the
  complement of a view"
}

@inproceedings{carlson79updatability,
author = "C. R. Carlson and A. K. Arora",
title = "The updatability of relational views based on functional
  dependencies",
booktitle = "Third International Computer Software and Applications
  Conference",
month = nov,
year = 1979,
summary = "cited by cosmodakis as assigning semantics to view updates."
}

@misc            { braganholo02updating,
author       =   "V. Braganholo",
title        =   "Updating relational databases through xml views",
text         =   "BRAGANHOLO, V. Updating relational databases through
                  xml views.
                  Thesis proposal - in preparation, PPGC-UFRGS, Porto Alegre,
                  2002. Available at
                  www.inf.ufrgs.br/ vanessa/artigos/PropostaTese.pdf.",
year         =   "2002",
url          =   "citeseer.nj.nec.com/article/braganholo02updating.html" ,
note = "Thesis proposal (unpublished)",
bcpcomment   =   "Useful for back-citations because it's recent.  Not that
  important otherwise.",
}

@inproceedings{scholl91updatable,
    author = "Marc H. Scholl and Christian Laasch and Markus Tresch",
    title = "{Updatable Views in Object-Oriented Databases}",
    booktitle = "Proc. 2nd Intl. Conf. on Deductive and Object-Oriented Databases ({DOOD})",
    number = "566",
    publisher = "Springer",
    editor = "C. Delobel and M. Kifer and Y. Yasunga",
    year = "1991",
    citeseerurl = "citeseer.nj.nec.com/scholl91updatable.html",
    schmittacomment = {
      The approach here is imperative (as opposed to functional). Here is
      a quote of the introduction:
      "The key idea that leads to a fully flexible view defenition capability
      of a query language is to make the operations object preserving: The
      objects contained in the result of a query are the input objects (some
      of them, in general). Object preservation is important for it makes
      updates propagate automatically: an update to an object is on update of
      a base object."

      This means that the views that can be built using this approach cannot
      be significantly different (as no new object in the abstract view may be
      created according to the values of some objects of the concrete view.
    },
    bcpcomment = "Title looks relevant!",
 }

@misc{ abiteboul99active,
    author = "S. Abiteboul and B. Amann and S. Cluet and E. Eyal and L. Mignet and T. Milo",
    title = "Active Views for Electronic Commerce",
    url = "http://www-rocq.inria.fr/verso/ACTIVEVIEWS/paper/av.pdf",
    year = "1999",
    citeseerurl = "citeseer.nj.nec.com/article/abiteboul98active.html",
  bcpcomment = " '... we add to O2 views a sophisticated notion of
        access and update facilities...' ",
 }


*
* LESS RELEVANT (PL PAPERS ON VIEWS)

_____________________________________________________________________________________
_____________________________________________________________________________________
**     Leeman, A Formal Approach to Undo Operations in Programming Languages

G. B. Leeman, A Formal Approach to Undo Operations in Programming Languages

ACM TOPLAS, 8(1):50-97, 1986.

Restricted to "undo" operations that return you back to a previous state;
not relevant to "put" direction.

_____________________________________________________________________________________
**     Baker, NREVERSAL of Fortune -- The Thermodynamics of Garbage Collection

The PsiLisp paper
stored as baker-ReverseGC.ps in our papers archive

@inproceedings{BakerPsilisp92,
author  = {Henry G. Baker},
title = {{NREVERSAL} of Fortune -- The Thermodynamics of Garbage
Collection},
booktitle = {Proc. Int'l Workshop on Memory Management},
note = {St. Malo, France. Springer LNCS 637, 1992.  },
month = {September}, 
year = 1992}


How to build reversible Lisp computers, which may
generate less heat. 

MBG looked at it and didn't think there was much there of interest/relevance
for us, other than the argument that reversibility needs to be
built into the language level, and not just the hardware level,
if we really want to have thermodynamically reversible computations.

_____________________________________________________________________________________
**     Stuart Schieber's course notes for ESSLI in Vienna last year

Can't find it [bcp].

_____________________________________________________________________________________
**     Dijkstra, Program Inversion

BCP: Not sure we need to read this, but it's the canonical seminal citation
for program inversion.  The idea is that we can sometimes specify a program
as the inverse of some program that is easy to write down.  Then we work
hard and find general techniques for doing this kind of "inverse
derivation."  The idea led to a big literature.

@inproceedings{DijkstraInversion78,
  editor    = {Friedrich L. Bauer and
               Manfred Broy},
  author    = {Edsger W. Dijkstra},
  title = {Program Inversion},
  booktitle     = {Program Construction, International Summer School, July 26 -
               August 6, 1978, Marktoberdorf, germany},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {69},
  year      = {1979},
  isbn      = {3-540-09251-X},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

**     McCarthy, Inverse Computation

@incollection{McCarthyInversion56,
author = {McCarthy, John},
title = {The Inversion of Functions Defined by Turing Machines},
booktitle = {Automata Studies, Annals of Mathematical Studies},
number =34,
editor = {Claude E. Shannon and J. McCarthy},
publisher = {Princeton University Press},
pages = {177--181},
year = 1956
}

_____________________________________________________________________________________
**     Kaplan and Kay, Regular models of phonological rule systems

@article{204917,
 author = {Ronald M. Kaplan and Martin Kay},
 title = {Regular models of phonological rule systems},
 journal = {Comput. Linguist.},
 volume = {20},
 number = {3},
 year = {1994},
 issn = {0891-2017},
 pages = {331--378},
 publisher = {MIT Press},
 }

Surprise!  This is actually quite relevant to us (in spirit, though quite
distant in technicalities).   They talk about formalisms for phonetic
transformations, and propose a bidirectional (relational) one.  Would be
interesting to read up on the details, especially for Nate, from the point
of view of reversible tree transducers.  

Stored locally as kaplan.pdf

_____________________________________________________________________________________
**     Gluck et al, Transforming interpreters into inverse interpreters by partial evaluation

@inproceedings{777391,
 author = {Robert Gl\"uck and Youhei Kawada and Takuya Hashimoto},
 title = {Transforming interpreters into inverse interpreters by partial evaluation},
 booktitle = {Proceedings of the 2003 ACM SIGPLAN workshop on Partial evaluation and semantics-based program manipulation},
 year = {2003},
 isbn = {1-58113-667-6},
 pages = {10--19},
 location = {San Diego, California, USA},
 doi = {http://doi.acm.org/10.1145/777388.777391},
 publisher = {ACM Press},
 }

BCP: Not very relevant for us -- this is an *appliation* of partial
evaluation to inverse computation.  Other, earlier, papers are more
interesting.

_____________________________________________________________________________________
_____________________________________________________________________________________
**     Cluet et al, Your mediators need data conversion!

@inproceedings{ cluet98your,
author = {Sophie Cluet and Claude Delobel and J{\'e}r{\^o}me
		  Sim{\'e}on and Katarzyna Smaga},
title = {Your mediators need data conversion!},
booktitle = sigmod98,
pages = {177--188},
year = {1998},
url = {citeseer.nj.nec.com/cluet98your.html},
summary = {This paper describes a system, YAT, for translating and
integrating heterogeneous data formats. However, the view update problem is
not considered and is left as future work.
}
}

*
* "PREHISTORIC" PL PAPERS ON VIEWS

_____________________________________________________________________________________
**     Wadler, Views: A Way for Pattern Matching to Cohabit with Data Abstr

@incollection{ wadler87views,
author = "Philip Wadler",
title = "Views: {A} Way for Pattern Matching to Cohabit with Data Abstraction",
booktitle = popl87,
year = "1987",
citeseerurl = "citeseer.nj.nec.com/wadler87views.html",
summary = {Wadler~\cite{wadler87views} describes a programming language
mechanism called a view for translating different representations of data
types into one another for more convenient pattern matching. Indeed, the
``in'' and ``out'' functions he describe seem to generally align with our
``get'' and ``put'' functions, with two main differences: first, the ``out''
direction only takes an abstract view as an argument, whereas our ``put''
takes both an abstract view and an original concrete view; secondly (and
perhaps the first difference is really just a manifestation of this second
one), the concrete representation and the view are required to be
isomorphic, whereas we are considering a more general case where the
abstract view may be ``throwing away'' information.}
}
%booktitle = "Proceedings, 14th Symposium on Principles of Programming
%  Languages",
%publisher = "Association for Computing Machinery",
%editor = "Steve Munchnik",
%pages = "307--312",

_____________________________________________________________________________________
**     Okasaki, Views for Standard ML
@inproceedings{ okasaki98views,
author = "C. Okasaki",
title = "Views for Standard ML",
booktitle = "SIGPLAN Workshop on ML",
pages = "14--23",
year = 1998,
citeseerurl = "citeseer.nj.nec.com/okasaki98view.html",
summary = {Okasaki presents an implementation of Wadler's views for Standard
ML. Again, the abstract view must be isomorphic to the concrete
view. However, some restrictions to the use of views (only usable in pattern
matching, not usable as expressions) only require 1-way transformations, so
there are really only ``get'' functions here.}
}

*
* LESS RELEVANT (PREHISTORIC -- PRE-GOTTLOB -- DB PAPERS ON VIEW UPDATE)
_____________________________________________________________________________________
**     Sevcik & Furtado, Complete and compatible sets of update operations,
@inproceedings{ SevcikFurtado,
    author = "K. C. Sevcik and A. L. Furtado ",
    title = "Complete and compatible sets of update operations",
    booktitle = "International Conference on Management of Data",
    year = "1978",
bcpcomment = {Also cited by Dayal and Bernstein as an example of the 'ADT
  approach' to update translation.  Should check it out.},
}

_____________________________________________________________________________________
**     Furtado, Sevcik and DosSantos, Permitting Updates through Views of Data Bases,
@Article{FurSevDos79,
  author =       "A. L. Furtado and K. C. Sevcik and C. S. DosSantos",
  title =        "Permitting Updates through Views of Data Bases",
  journal =      "Information Systems, Pergamon Press , Pergamon Press,
                 Great Britain",
  volume =       "4",
  number =       "4",
  year =         "1979",
bcpcomment = "This came up when I was searching for SevcikFurtado...",
}

_____________________________________________________________________________________
**     Paolini and Pelagatti, Formal definition of mappings in a database
@inproceedings{paolini77formal,
author = "P. Paolini and G. Pelagatti",
title = "Formal definition of mappings in a database",
booktitle = sigmod77,
year = "1977",
jonmcomment = "cited by gottlob as background"
}

_____________________________________________________________________________________
**     Paolini, Verification of views and applications programs
@inproceedings{paolini79verification,
author = "P. Paolini",
title = "Verification of views and applications programs",
booktitle = "Workshop on Formal Bases for Databases",
year = 1979,
jonmcomment = "cited by gottlob as background"
}

_____________________________________________________________________________________
**     Paolini and R. Zicari, Properties of views and their implementation
@incollection{paolini84properties,
author = "P. Paolini and R. Zicari",
title = "Properties of views and their implementation",
booktitle = "Advances in Database Theory",
volume = 2,
editor = "J. Minker {\em et al.}",
publisher = "Plenum Press",
year = 1984,
jonmcomment = "cited by gottlob as background"
}

_____________________________________________________________________________________
**     Siklossy, Updating views: a constructive approach
@inproceedings{siklossy82updating,
author = "L. Siklossy",
title = "Updating views: a constructive approach",
booktitle = "Proceedings of Workshop on Logical Bases for Databases",
year = "1982",
jonmcomment = "cited by gottlob as background"
}

_____________________________________________________________________________________
_____________________________________________________________________________________

_____________________________________________________________________________________

*
* MISC XML DATABASE PAPERS

_____________________________________________________________________________________
**     Liefke and Davidson, View Maintenance for Hierarchical Semistruct Data

@InProceedings{LiefkeD00,
  title = "View Maintenance for Hierarchical Semistructured Data",
  author = "Hartmut Liefke and Susan B. Davidson",
  booktitle = "Proceedings of Data Warehousing and Knowledge Discovery",
  year = "2000",
  url = "http://www.cis.upenn.edu/~liefke/papers/dawak00.ps.gz",
  summary = {
    The authors consider hierarchical semistructure data; their trees look
  extraordinarily like our views (including abbreviating { s = {}} as { "s" })!
  They punt on order, however (unclear whether cons cells occurred to them
  or not). They define the notion of a "deep union" between two trees which
  looks like it considers the second tree to be an update of the first.

    The authors define database views through the use of a query language
  called WHAX-QL based on XML-QL. WHAX-QL is a generalization of SPJ
  (select-project-join) queries.

    The purpose of WHAX-QL is to efficiently maintain a view, when the
  underlying databases change. Insertion is done efficiently via the use of
  deep-union, as the query can essentially be factored so that you just
  query the update to the underlying database (usu. much smaller than the DB
  itself), and then fold the result into your view. Deletion is handled via
  one of two methods: "view analysis" guarantees that each tuple in the view
  has only one derivation in the underlying database, so in some sense the
  multiple underlying databases are disjoint. Then there is a reference
  counting algorithm to compute the "support" of a tuple in the view so you
  can tell when all its underlying tuples have been deleted.

    Finally, there is a brief discussion about how to handle aggregations
  (i.e. sums) although I didn't fully follow that part.

    In any event, they only handle the "up" direction of our lenses; we
  might build lenses based on their query language in some way, perhaps to
  speed things up if an underlying data set changes during synchronization
  (then you can efficiently recompute the abstract view and try again). They
  note that order is hard, and that you have to basically define a mapping
  between "dynamic" locations and "static" keys to get it right.
  }
}


_____________________________________________________________________________________
**     <Several references on query languages>
@inproceedings   {DBLP:conf/pods/DantsinV00,
author       =   {Evgeny Dantsin and Andrei Voronkov},
title        =   {Expressive Power and Data Complexity of Query Languages
                  for Trees and Lists},
booktitle    =   pods00,
publisher    =   {ACM},
year         =   {2000},
isbn         =   {1-58113-214-X},
pages        =   {157-165},
ee           =   {db/conf/pods/DantsinV00.html},
xxxcrossref     =   {DBLP:conf/pods/00},
bibsource    =   {DBLP, http://dblp.uni-trier.de},
url          =   "http://cs.roosevelt.edu/~dantsin/ps/DV00.ps",
bcpnote      =   {Referenced by Benedikt and Libkin.  Maybe worth checking
                  for intuitions about how to talk about the expressive
                  power of our 'query language'},
}

_____________________________________________________________________________________
**     references on representation mapping, and translation between models/schema
@inproceedings{atzeni97mdm,
author = {Paolo Atzeni and Riccardo Torlone},
title = {{MDM}: a multiple-data model tool for the management of
		  heterogeneous database schemes},
booktitle = {Proceedings of {ACM} {SIGMOD}, Exhibition Section},
pages = {528--531},
year = 1997,
url = {http://citeseer.nj.nec.com/atzeni97mdm.html},
mbgreencomment = {This paper describes an interactive tool that
		  translates from data models from one schema to
		  another, assuming the existence of a
		  ``meta-model'' that is a superset of both
		  schemas.  It is based on the ideas in cite{atzeni96mmm}}}

@inproceedings{atzeni96mmm,
author = {Paolo Atzeni and Riccardo Torlone},
title = {Management of Multiple Models in an Extensible Database
		  Design Tool},
booktitle = {Proceedings of EDBT'96, LNCS 1057},
year = 1996,
mbgreencomment = {This paper represents schemas and models as
		  DAGs.  The Model DAG represents the structure
		  of the data model.  The schema DAG is a pattern
		  that represents many possible structures.  For
		  a class of schemas and models that you want to
		  translate between, a meta-model is defined that
		  is a superset of all the models and schemas in
		  the class.  If you can define a bidirectional
		  translation from each model to/from the
		  metamodel then you can translate between any
		  pairs of models.  A translator from one model
		  to another is correct if the result of
		  applying the translator to an instance of the
		  source always results in something acceptable
		  by the target schema.
                     They define an ordering on correct
		  translations by first preferring translations
		  that result in a new model closer to the
		  target, second by preferring ``simpler''
		  translations.
                  The contribution in this paper is a method for
		  automatically deriving good translations
		  between schemes and models.  Because the
		  meta-model (the abstract view) is always a
		  superset of the concrete views, and because
		  they assume a 1-1 mapping between components of
		  the concrete view and the meta-model, deriving
		  put from get is unambiguous and relatively easy.
}}
% publisher = {Springer Verlag},
% pages = {79--95},


_____________________________________________________________________________________
**     Doan's thesis

% What does Zack know about this one?
@phdthesis{doan01phd,
author = {AnHai Doan},
title = {Learning to map between structured representations of Data},
institution = {University of Washington},
url = {http://citeseer.nj.nec.com/doan02learning.html},
year = 2002}

_____________________________________________________________________________________
_____________________________________________________________________________________

*
* MISC USER INTERFACE PAPERS

______________________________________________________________________________________
**     Kamada and Kawai, A general framework for visualizing abstract objects and relations

A famous, foundational paper, much cited.  But only handles the
unidirectional case.

@article{99903,
 author = {Tomihisa Kamada and Satoru Kawai},
 title = {A general framework for visualizing abstract objects and relations},
 journal = {ACM Trans. Graph.},
 volume = {10},
 number = {1},
 year = {1991},
 issn = {0730-0301},
 pages = {1--39},
 doi = {http://doi.acm.org/10.1145/99902.99903},
 publisher = {ACM Press},
 }

_____________________________________________________________________________________
**     Takahashi, et al, A Framework for Constructing Animations via Declarative Mapping Rules

@inproceedings{ takahashi94trip3,
    author = {Shin Takahashi and Ken Miyashita and Satoshi
              Matsuoka and Akinori Yonezawa}, 
    title = {A Framework for Constructing Animations via
             Declarative Mapping Rules} ,
    booktitle = "Visual Languages",
    pages = "314-322",
    year = "1994",
    citeseerurl = "citeseer.ist.psu.edu/takahashi94framework.html" 
}

Not all that relevant -- although the TRIP3 system is based on TRIP2's
notion of bi-directional transformations, they do not seem to actually use
the PUT direction at all.  The point here is just the extension of the
static visualization to construct dynamic animations.

_____________________________________________________________________________________
**     Matsuoka, et. al. A General Framework for Bi-Directional Translation between Abstract and Pictorial Data

@article{matsuoka-tis92,
author = {Satoshi Matsuoka and Shin Takahashi and Tomihisa Kamada
and Akinori Yonezawa},
title = {A General Framework for Bi-Directional Translation between Abstract and Pictorial Data},
journal = {{ACM} Transactions on Information Systems},
month = {October},
pages = {408--437},
volume = 10,
number = 4,
year = 1992}

Report on TRIP2 system.  Bi-directional mappings for direct
manipulation UI's between an abstract rep and the visual display.

______________________________________________________________________________________

*
* <UNFILED VIEW-RELATED PAPERS (many already cited in our papers!)>

_____________________________________________________________________________________
@inproceedings{halevy03schema,
author = "Alon Y. Halevy and Zachary G. Ives and Dan Suciu and Igor Tatarinov",
title = "Schema Mediation in Peer Data Management Systems",
booktitle = "International Conference on Data Engineering",
year = 2003,
url = "http://www.cis.upenn.edu/~zives/research/p2p-mediation.pdf",
summary = "Describes the Piazza PDBMS (peer data management system), a
framework for scalably adding new views in a peer-to-peer fashion. However,
does not seem to consider the view update problem."
}

_____________________________________________________________________________________
@inproceedings{ abiteboul97correspondence,
author = "Serge Abiteboul and Sophie Cluet and Tova Milo",
title = "Correspondence and Translation for Heterogeneous Data",
booktitle = icdt97,
year = 1997,
citeseerurl = "citeseer.nj.nec.com/abiteboul00correspondence.html",
summary = {Abiteboul {\em et al.}~\cite{abiteboul97correspondence} define a
language for describing {\em correspondences} between sections of trees in a
forest. In turn, these declarative correspondence rules can be used to
translate one tree format into another through non-deterministic
computation. It is unclear whether this process requires an essential
isomorphism between data formats, however. There are also no
well-behavedness results about this system.}
}
% pages = "351--363",
% booktitle = "Proceedings of the 6th International Conference on
%		  Database Theory (also LNCS 1186)",
% publisher = "Springer, Berlin",
% address = "Delphi, Greece",

_____________________________________________________________________________________
@article{clio2001,
author       =   {Ren\'{e}e J. Miller and Mauricio A. Hernandez and Laura
  M. Haas and Lingling Yan and C. T. Howard Ho and Ronald Fagin and Lucian
  Popa},
title        =   "The Clio Project: Managing Heterogeneity",
booktitle    =   "ACM SIGMOD Record",
volume       =   30,
number       =   1,
month        =   "March",
year         =   2001,
pages        =   "78--83",
abstract     =   {Clio is a system for managing and facilitating the complex tasks of heterogeneous data transformation and integration. In Clio, we have collected together a powerful set of data management techniques that have proven invaluable in tackling these difficult problems. In this paper, we present the underlying themes of our approach and present a brief case study.} ,
summary = {Miller {\em et al.}~\cite{clio2001} describe Clio, a system for
managing heterogenous transformation and integration. Clio provides a tool
for visualizing two schemas, specifying correspondences between fields,
defining a mapping between the schemas, and viewing sample query
results. They only consider the \GET{} direction of our lenses, but their
system is somewhat mapping-agnostic, so it might eventually be possible to
use a framework like Clio as a user interface for \lang to allow incremental
lens composition, like that in Figure~\ref{fig:linkexample}.
}
}

_____________________________________________________________________________________
@inproceedings{tomasic94correct,
author = "Anthony Tomasic",
title = "Correct View Update Translations via Containment",
booktitle = "Proceedings of the Workshop on Deductive Database and Logic
  Programming, Second International Conference on Logic Programming (ICLP)",
year = 1994,
url = "http://www.tomasic.net/anthony/doc/1994/TomasicICLPWDD1994.ps",
summary = {This is more deductive database stuff, about how to detect if you
have correctly translated an update on an intensional database into updates
on the underlying extensional databases.
}
}

_____________________________________________________________________________________
@inproceedings   { tatarinov01updating,
author       =   "Igor Tatarinov and Zachary G. Ives and Alon Y. Halevy
                  and Daniel S. Weld",
title        =   "Updating {XML}",
booktitle    =   sigmod01,
year         =   "2001",
url          =   "citeseer.nj.nec.com/tatarinov01updating.html" ,
summary = {Tatarinov {\em et al.}~\cite{tatarinov01updating} describe a
mechanism for translating updates on XML structures that are stored in an
underlying relational database. In this case, there is an isomorphism
between the concrete relational database and the abstract XML view, so
updates are unambiguous. Tatarinov {\em et al.} are mostly concerned with
finding the most efficient translations of various XML updates.
}
}

_____________________________________________________________________________________
@inproceedings{ barsalou91updating,
author = "Thierry Barsalou and Niki Siambela and Arthur M. Keller and Gio
  Wiederhold",
title = "Updating relational databases through object-based views",
booktitle = pods91,
pages = "248--257",
year = "1991",
citeseerurl = "citeseer.nj.nec.com/barsalou91updating.html",
summary = {Barsalou {\em et al.}~\cite{barsalou91updating} describe
  updates on object-based views of relational databases. At view creation
  time, the user enters into an interactive dialog with software that
  defines an update translation policy, thereby removing potential sources
  of ambiguity in update translation. This work builds on the foundation
  laid out by Keller~\cite{keller85translating,keller86choosing}.
}
}

_____________________________________________________________________________________
@inproceedings{masunaga84relational,
author = "Y. Masunaga",
title = "A relational database view update translation mechanism",
booktitle = "VLDB'84",
year = 1984,
url = "http://www.acm.org/sigmod/vldb/conf/1984/P309.PDF",
summary = {Masunaga~\cite{masunaga84relational} describes an automated
algorithm for translating updates on views defined by relational algebra. As
others have noted, ambiguities arise in the translation of some updates, so
Masunaga explicitly annotates where the ``semantic ambiguities'' arise,
indicating they must be resolved either with knowledge of underlying
database semantic constraints or by interactions with the user.}
}
% booktitle = "Proceedings of Tenth VLDB Conference",
% pages = "309--320",

_____________________________________________________________________________________
@phdthesis{medeiros85validation,
author = "C. M. B. Medeiros",
title = "A validation tool for designing database views that permit
  updates",
school = "University of Waterloo",
year = 1985,
note = "Also Technical Report CS-85-44, University of Waterloo"
}

_____________________________________________________________________________________
@inproceedings{medeiros85understanding,
author = "C. M. B. Medeiros and F. W. Tompa",
title = "Understanding the implications of view update policies",
booktitle = "VLDB'85",
year = 1985,
url = "http://www.acm.org/sigmod/vldb/conf/1985/P316.PDF",
summary = {Medeiros and Tompa~\cite{medeiros85understanding} present a
  design tool for exploring the  effects of choosing a view update
  policy. This tool shows the update translation for update requests
  supplied by the user; by considering all possible valid concrete states,
  the tool predicts whether the desired update would in fact be reflected
  back into the view after applying the translated update to the concrete
  database.}
}

_____________________________________________________________________________________
@inproceedings{arenas02normal,
author = "Marcelo Arenas and Leonid Libkin",
title = "A Normal Form for XML Documents",
booktitle = pods02,
year = 2002,
pages = "85--96",
url = "http://www.cs.toronto.edu/~marenas/publications/xnf_pods02.pdf",
jonmcomment = "Arenas and Libkin describe a normal form for XML DTDs that
removes redundancies and thus avoids 'update anomalies.' Perhaps useful in
that if a concrete view is in XNF, it may be easier to choose a put function
by removing update ambiguities."
}

_____________________________________________________________________________________
@unpublished{lehti02towards,
author = "Patrick Lehti and Peter Fankhauser",
title = "Towards type safe updates in XQuery",
note = "http://www.ipsi.fhg.de/~lehti/Typing%20updates%20-%20overview3.txt",
jonmcomment = "Sketch of ensuring that XML updates are well-typed, but does
not consider view translation. Work unfinished anyway."
}

_____________________________________________________________________________________
@article{gottlob88properties,
title = {Properties and Update Semantics of Consistent Views},
author = {G. Gottlob and P. Paolini and R. Zicari},
journal = {ACM Transactions on Database Systems (TODS)},
volume = 13,
number = 4,
pages = {486--524},
year = 1988,
url = "http://delivery.acm.org/10.1145/60000/50068/p486-gottlob.pdf?key1=50068&key2=2962767401&coll=portal&dl=ACM&CFID=8777976&CFTOKEN=94711507",
summary = {define a class of 'consistent' views: if the effect of a view
update on a view state is determined, then the effect of the corresponding
database update is unambiguously determined. thus, in order to know how to
translate a given view-update program into a database-update program, it is
not necessary to know the sequence of the single operations of the
view-update program, but it is sufficient to be aware of a functional
specification of such a program.

defines views as a tuple (A,B,f,\pi) where A is the set of base states, B is
the set of view states, f is get, and \pi maps view updates to base
updates. a view is equivalence preserving iff the functional specification
of a view update is sufficient in order to functionally determine its
translation. in our case, we only have the functional specification of a
view update (namely the new view!), so our lenses only define
equivalence-preseving views.

a consistent lens would be one where
  (l \ c a1 = c1) and (l \ c a2 = c2) and (l / c1 = l / c2) ==> c1 = c2.
conjecture: lenses obeying the lens laws are consistent.
proof. assume l obeys the lens laws. assume l \ c a1 = c1 and l \ c a2 = c2
and l / c1 = l / c2. then l / c1 = l / (l \ c a1) = a1 by PutGet.
l / c2 = l / (l \ c a2) = a2 by PutGet. Then a1 = a2.
Then l \ c a1 = l \ c a2. Then c1 = c2. QED.

incidentally, here's our first hint at a completeness result for Hocus
Focus: can Hocus Focus describe all consistent views for our domain?

this jives with gottlob's theorem that a view is consistent iff it is
equivalence preserving.

gottlob also shows that consistent views preserve serializability and
noninterference for transactions -- which means that our lenses would too
(possibly a useful result for us someday).

gottlob goes on to show that the consistent views are more than just those
that keep a constant complement (although all constant-complement views are
consistent). it turns out that consistent views are ones that hold a
complement constant or allow it to shrink according to some partial order (I
didn't wade through these details yet).

the related work section of this paper is probably exactly what our related
work section should look like!
}
}
%journal = {ACM Transactions on Database Systems},

_____________________________________________________________________________________
**     Keller, Algs for trans. view updates to db updates for views involving selections, projections, and joins

@inproceedings{keller85translating,
author = {Arthur M.~Keller},
title = {Algorithms for translating view updates to database
		  updates for views involving selections,
		  projections, and joins},
booktitle = pods85,
year = 1985,
summary = {
keller's results are for views that contain a key of the database. also, the
key dependency is the only functional dependency on the underlying database.

Keller defines 5 criteria that translated view update requests must satisfy:
1. no database side effects (key of the database must appear in the view)
   -only update tuples that appear in the view
2. only one step changes - each tuple is affect at most once
3. no unnecessary changes - no equivalent translation that performs a proper
subset of the translated actions
4. replacements cannot be simplified - ie. affecting fewer attributes or not
changing the key
5. no delete-insert pairs - for any relation, you have deletions or
insertions but not both.

interesting quote: <quote>we see that a view deletion request is sometimes
translated into a database deletion request best and at other times into a
database replacement request. as we shall see, similar alternatives arise
for insertion and replacement. {\em we suggest that additional semantics be
used to choose among the various alternatives}, but such semantics are
beyond the scope of this paper</quote> (emphasis jonm's)

requirements for joins: the join attributes are the key of one of the
relations, and you can do a topological sort of a "query graph" where one of
the joined relations is a 'root' relation [jonm- I didn't quite get this
part of it]. the views are assumed to be in SPJNF (select-project-join
normal form).

keller outlines all the possible strategies for handling updates to a
select-project-join view, and proves (in his thesis) that these are exactly
the set of translations that satisfy the 5 criteria.}
}
% booktitle = {Proceedings of Fourth Annual ACM Symposium on
%		  Principles of Database Systems ({PODS})},
%month = {march},
%pages = {154--163},
%note = {Portland, Oregon},

_____________________________________________________________________________________
@inproceedings{r2x,
author = "Vanessa de Paula Braganholo and Carlos A. Heuser and Cesar Roberto
   Mariano Vittori",
booktitle = "Proc. 3rd Int. Conf. on Information Integration and
   Web-based Applications and Services (IIWAS)",
title = "Updating Relational Databases through {XML} Views",
year = "2001",
url = "http://metropole.inf.ufrgs.br/grupo_heuser/vanessa/iiwas.pdf",
summary = {Requires that there be a 1:1 mapping between XML view elements
and objects in the database (else view updates are ambiguous). View updates
are performed by handing back a new XML view, and R2X figures out what
changes occurred and reflects them down into the underlying database. R2X
maps relational databases to XML views conforming to a certain DTD, whereas
Hocus Focus maps trees to trees (so we are more general?). It is possible
that the result of an R2X query can produce multiple copies of an underlying
tuple in the output view, in which case they are non-updateable [I guess if
they were all changed in the same way, it would be ok, but they don't
mention this case].
}
}
% booktitle = "Third International Conference on Information Integration and
%    Web-based Applications and Services (IIWAS)",

_____________________________________________________________________________________
@INPROCEEDINGS{updatabilityXML,
abstract  = {http://db.cis.upenn.edu/DL/03/webdb2003abstract.txt},
author    = {Vanessa Braganholo and Susan Davidson and Carlos Heuser},
booktitle = {{WebDB} 2003},
institution= {Department of Computer and Information Science, University of Pennsylvania},
pdf       = {http://www.inf.ufrgs.br/~vanessa/artigos/webdb2003.pdf},
title     = {On the updatability of {XML} views over relational databases},
year      = {2003}
              }

_____________________________________________________________________________________
@article{dayal82translation,
author = {Umeshwar Dayal and Philip~A.~Bernstein},
title = {On the correct translation of update
operations on relational views},
journal = {TODS},
volume = 7,
number = 3,
pages = {381--416},
month = {September},
year = 1982,
summary = {An early paper on formalizing the notion of 'correct update
  translation.'  Unfortunately, I [bcp] find the notation close to
  impenetrable -- they claim to be studying a general, foundational
  problem but then the first thing they do is introduce a {\em very}
  particular and complicated setting [particular query language, etc.],
  which the rest of their investigation is carried out.  Probably it's more
  useful to stick to later papers where the important ideas here have been
  digested and explained in a more general way.},
}
% journal = {{ACM} Transactions on Database Systems},

_____________________________________________________________________________________
@inproceedings{dayal78updatability,
author = "U. Dayal and P. A. Bernstein",
title = "On the updatability of relational views",
booktitle = "Proceedings of 4th VLDB",
year = 1978,
jonmcomment = "cited by gottlob"
}

_____________________________________________________________________________________
@article{dayal82updatability,
author = "U. Dayal and P. A. Bernstein",
title = "On the updatability of network views---extending relational view
  theory to the network model",
journal = "Information Systems",
volume = 7,
number = 1,
year = 1982,
jonmcomment = "cited by gottlob"
}

_____________________________________________________________________________________
@misc{shu97tr,
author = {Hau Shu},
title = {Formulating View Update Translation as Constraint
		  Satisfaction},
year = 1997,
url = {http://citeseer.nj.nec.com/77950.html},
bcpcomments = {
Proposes a formulation of the view update problem which separates the
definituion of a good update (which is expressed as a set of
constraints) from the algorithm for calculating an update (which is
done by general constraint solving).

Notationally heavy going and not so closely related to what we're doing,
but it has a great history and related work section -- well worth reading
just that.

One interesting tidbit: Shu comments that the formal approach of Bancilhon
and Spiratos and of Gottlob et al [4,17] is attractive but that (a) it has
not been applied to concrete languages like SQL and (b) it is
computationally intractable.
}}

_____________________________________________________________________________________
@inproceedings{shu98tr,
author = {Hau Shu},
title = {Using Constraint Satisfaction for View Update
		  Translation},
booktitle = {Proceedings of the 13th Annual European Conference
		  on Artificial Intelligence ({ECAI} '98)},
year = 1998,
pages = {33--37},
url = {http://citeseer.nj.nec.com/shu98using.html}}

_____________________________________________________________________________________
@mastersthesis{ cosmadakis83translating,
author = "Stavros Stylianos Cosmadakis",
title = "Translating Updates of Relational Data Base Views",
school = "Massachusetts Institute of Technology",
note = "MIT-LCS-TR-284",
year = "1983",
url = "http://www.lcs.mit.edu/publications/pubs/pdf/MIT-LCS-TR-284.pdf",
bcpcomment = "Looks worthwhile.  Contains some good early history.
  In particular, it makes Dayal and Bernstein sound VERY relevant
  to our lens laws.",
summary = "with each view, define a view complement (i.e. the rest of the
  underlying database). an update to a view, when translated down, must hold
  the complement constant. this amounts to finding a database state s' such
  that v(s') = uv(s) and v'(s') = v'(s). if such an s' can be found for any
  s, we say that the update u is v'-translatable.

  key results: considers the problem for a single relation, where the view
  is a projection of the underlying relation. it is possible to construct a
  minimal (non-redundant) complement of a projection view in polynomial
  time. it is possible to determine in polynomial time whether insertions,
  deletions, and replacements to a projection view are translatable.

  now, one main difference is that they consider whether a given update to a
  view is translatable or not, whereas we are restricting ourselves further:
  we only want to consider lenses where {\em every} abstract update is
  translatable into a concrete update. further, they deal with relations
  instead of trees, but I suspect the results here may give us insight to
  the whole 'hidden state'/projection problem."
}

_____________________________________________________________________________________
@inproceedings{cluet01views,
author = "Sophie Cluet and Pierangelo Veltri and Dan Vodislav",
title = "Views in a Large Scale {XML} Repository",
booktitle = "Proceedings of the 27th International Conference on Very Large
  Databases (VLDB)",
pages = "271--280",
year = "2001",
url = "http://www-rocq.inria.fr/~veltri/PUBLICATIONS/vldb2001.ps.gz",
jonmcomment = "This paper describes a query language for defining an abstract
  view over heterogeneous concrete XML documents. The basic methodology is
  to describe a transformation as a list of path-pairs (i.e. the leaf at
  path ap in the abstract view comes from the leaf at path cp in the
  concrete view). They describe heuristics for automatically generating
  these mappings via thesaurus associations on the path elements. However,
  they do not deal with updates to the abstract view being pushed back down.

  (Seems very relevant to view programming by example, though! --B)",
mbgreencomment = {If we decide the paper is relevant then a 3rd
		  party should read the paper because my summary
		  clashes with Jon's.  This paper is not about
		  defining an abstract view over heterogeneous
		  XML documents.  Such work is just cited [13].
		  This paper is about translating queries on
		  already-defined abstract views back down to
		  queries on the original, constituent concrete
		  views. (Instead of creating Put lenses, they
		  translate each query).  I think this is
		  irrelevant to our work.}
}

_____________________________________________________________________________________
@inproceedings   {BenediktLibkin2002,
title        =   "Tree Extension Algebras: Logics, Automata,
                  and Query Languages",
author       =   "Michael Benedikt and Leonid Libkin",
booktitle    =   "Logic in Computer Science (LICS)",
year         =   "2002",
url          =   "http://www.cs.toronto.edu/~libkin/papers/lics02.ps.gz",
summary      =   {This is a pretty technical paper, and I did not understand
                  most of the details.  The rough idea, though, is this:
                  They are interested in query languages for trees, and
                  their approach is to introduce a language of
                  first-order constraints over a vocabulary that includes
                  a novel 'tree extension' relation -- T < T' if every
                  branch of T is present (and perhaps extended) in T' --
                  as well as node-label constraints and a predicate that
                  tells whether the domains of two trees are equal.  They
                  study several aspects of this language, including complexity
                  and expressiveness questions, and its relation to more
                  'procedural' presentations in terms of automata.

                  I did not see a direct relationship with Harmony (though
                  one may be buried in the technicalities!), because (a)
                  they are interested in *describing* trees, not transforming
                  them, and (b) they do not consider (AFAICT) the view update
                  problem for their language.  -- BCP
                  }
}

 
*
*
* ###################################################################################
  ###################################################################################
  ##                                                                               ##
* ##                 LARGE-SCALE OPTIMISTIC REPLICATION (N-WAY)                    ##
  ##                                                                               ##
  ###################################################################################
* ###################################################################################

*
* SEMINAL PAPERS

_____________________________________________________________________________________
**     Lamport, Time, Clocks, and the Ordering of Events in a Distributed System

@article{lamport78,
  author = "Leslie Lamport",
  title = "Time, Clocks, and the Ordering of Events in a Distributed System",
  journal = "Communications of the ACM",
  year = 1978,
  volume = 21,
  number = 7,
  month = "July",
  pages = "558--565",
  keywords = "classic paper on logical clocks"
  }

THE classical paper by Lamport on clocks and ordering in distributed systems.

___________________________________________________________________________________
**     Saito and Shapiro "Scaling Optimistic Replication"

Marc Shapiro, Yasushi Saito: Scaling Optimistic Replication.  Future
Directions in Distributed Computing 2003: 164-172.

http://link.springer.de/link/service/series/0558/bibs/2584/25840164.htm

Short, recent survey of scaling issues in optimistic replication systems.
Not much here that is not already found in the longer Saito and Shapiro survey.

_____________________________________________________________________________________
_____________________________________________________________________________________

*
* VECTOR CLOCKS AND SUCH

_____________________________________________________________________________________
**     Baldoni and Raynal, A Practical Tour of Vector Clock Systems

Full title: Fundamentals of Distributed Computing:
            A Practical Tour of Vector Clock Systems
http://dsonline.computer.org/0202/features/bal.htm

@article{ClocksSurvey,
author = {Roberto Baldoni and Michel Raynal},
title = "A Practical Tour of Vector Clock Systems",
journal = {IEEE Distributed Systems Online},
volume = 3,
number = 2,
year = 2002,
note = {http://dsonline.computer.org/0202/features/ bal.htm}}

Online survey of background and applications of vector clocks.  The
mathematical parts of the exposition are a bit clunky.

_____________________________________________________________________________________
**     Morris, lecture on Vector Clocks and File Synchronization

  http://www.pdos.lcs.mit.edu/6.824/lecnotes/l18.txt

An interesting excerpt from a Distributed Systems course by Robert Morris.
Very insightful.  Worthwhile reading for all of us.

At the end, commenting on the use of vector clocks to ensure consistent
pictures of the world at optimistically replicated hosts, he comments that
"TreadMarks uses a similar technique..."  We should track this down.

_____________________________________________________________________________________
**     Fidge, Logical Time in Distributed Computing Systems

@article{ fidge91logical,
  author = "Colin Fidge",
  title = "Logical Time in Distributed Computing Systems",
  journal = "Computer",
  volume = 24,
  number = 8,
  year = "1991",
  month = "Aug",
  pages = "28--33",
  url = "http://theory.lcs.mit.edu/classes/6.895/fall02/papers/Fidge/ieeecomputer.pdf",
  summary = { Simple and short introduction to vector clocks. }
}
_____________________________________________________________________________________
**     Peterson, Preserving Context Information in an IPC Abstraction

@conference{peterson87,
  author = "Larry L. Peterson",
  title = "Preserving Context Information in an {IPC} Abstraction",
  booktitle = "Proceedings of the 6th symposium on Reliability in Distributed
    Software and Database Systems",
  month = "March",
  year = 1987,
  pages = "22--31",
  keywords = "example on the use of vector clocks"
  }
_____________________________________________________________________________________
**     Mattern, Virtual Time and Global States of Distributed Systems

@incollection{ mattern89virtual,
    author = "Friedemann Mattern",
    title = "Virtual Time and Global States of Distributed Systems",
    booktitle = "Parallel and Distributed Algorithms: proceedings of the
      International Workshop on Parallel \& Distributed Algorithms",
    publisher = "Elsevier Science Publishers B. V.",
    editor = "M. Cosnard et. al.",
    pages = "215--226",
    year = "1989",
    url = "http://citeseer.nj.nec.com/mattern89virtual.html",
    summary = { Fairly simple paper describing how vector clocks can be used
      to track logical independancy and potential dependancy. Pretty good
      introduction to the subject, and the distributed snapshot application
      looks interesting.
    }
}

_____________________________________________________________________________________
** ?   Schwarz and Mattern, Detecting Causal Relationships in Distributed Computations

@article{ schwarz94detecting,
    author = "Reinhard Schwarz and Friedemann Mattern",
    title = "Detecting Causal Relationships in Distributed Computations: In Search of the Holy Grail",
    journal = "Distributed Computing",
    volume = "7",
    number = "3",
    pages = "149-174",
    year = "1994",
    citeseerurl = "citeseer.ist.psu.edu/article/schwarz94detecting.html" 
}

These [this and what??] were the two original (and independent) studies of
"vector clocks as a concept."  Earlier papers had used similar ideas in a
pragmatic way (in particular, Parker et al. seems to be cited as the
earliest).  Baldoni and Raynal give a nice historical survey.

_____________________________________________________________________________________
**     Parker et al, Detection of mutual inconsistency in distributed systems

  D. Stott Parker et al. Detection of mutual inconsistency in distributed
  systems. IEEE Transactions on Software Engineering, 9(3):240--247, May
  1983

Cached locally as nway/Parker83.pdf

Introduced the idea of version vectors.  Also the idea of taking the
pointwise max (and incrementing the local version number) when reconciling
conflicting versions.  There is some discussion of automatic reconciliation
of conflicts in certain situations (e.g. directories, mail folders), but it
is rather shallow and pragmatic.

CiteSeer lists at least 75 articles citing this one, including *MANY* that
we should probably look at.

@Article{Parker83,
  author =       "D. S. {Parker, Jr.} and G. J. Popek and G. Rudisin and
                 A. Stoughton and B. J. Walker and E. Walton and J. M.
                 Chow and D. Edwards and S. Kiser and C. Kline",
  title =        "Detection of mutual inconsistency in distributed
                 systems",
  journal =      "IEEE Trans. Software Eng. (USA)",
  volume =       "SE-9",
  number =       "3",
  pages =        "240--247",
  year =         "1983",
  keywords =     "fault tolerant computing operating systems computer
                 networks fault tolerant computing computer networks
                 mutual inconsistency distributed systems communications
                 network network failures redundant copies files version
                 vectors origin points LOCUS local network operating
                 system",
  abstract =     "Many distributed systems are now being developed to
                 provide users with convenient access to data via some
                 kind of communications network. In many cases it is
                 desirable to keep the system functioning even when it
                 is partitioned by network failures. A serious problem
                 in this context is how one can support redundant copies
                 of resources such as files (for the sake of
                 reliability) while simultaneously monitoring their
                 mutual consistency (the equality of multiple copies).
                 This is difficult since network failures can lead to
                 inconsistency, and disrupt attempts at maintaining
                 consistency. In fact, even the detection of
                 inconsistent copies is a nontrivial problem. Naive
                 methods either (1) compare the multiple copies entirely
                 or (2) perform simple tests which will diagnose some
                 consistent copies as inconsistent. Here a new approach,
                 involving version vectors and origin points, is
                 presented and shown to detect single file, multiple
                 copy mutual inconsistency effectively. The approach has
                 been used in the design of LOCUS, a local network
                 operating system at UCLA",
comment =         "18 REFS Treatment PRACTICAL",
}

_____________________________________________________________________________________
** ?   Cox and Josephson, File System Synchronization Using Vector Time Pairs

% references on multi-replica synchronization
@misc{tra03,
author = {Ronny Cox and William Josephson},
title = {File System Synchronization Using Vector Time Pairs},
year = {2003},
url = {http://pdos.lcs.mit.edu/~rsc/tra/osdi.pdf},
abstract = {
  Synchronization of optimistically replicated multiplewriter file systems
  requires keeping perfile metadata in order to make correct
  synchronization decisions. This metadata has traditionally taken the
  form of version vectors. An alternate approach is to use a pair of
  vector times, one noting the time of the last modification and the
  other noting the time of the last synchronization. We present this
  approach and contrast it with version vectors, which can be viewed as
  a conflation of the two vector times we use. We also report on
  experiences using our approach in a userlevel file system synchronizer
  called Tra. Based on the comparisons and our experiences, we conclude
  that using version vectors is never the right approach: using distinct
  synchronization and modification times approach facilitates
  faster synchronizations, requires less space, allows more general
  encoding of conflict resolutions, and avoids the need for complex
  distributed garbage collection algorithms. },
summary = {
  Very relevant to both the systems and the semantic aspects of the
  Harmony project.  And their idea of splitting the usual vector
  clock into two seems worth thinking about.  However, I (bcp) must admit
  that I did not understand the details very well --- their exposition is
  very user-friendly right up to the point where they explain the crucial
  intuition!  Worth another look.

  Their user-level intuition of "correct synchronization" is nicely
  described:

    We describe the behavior of our ideal synchronizer in terms of file
    histories. A file history is a log of the events in a file's life,
    starting with creation, followed by some number of modifications, and
    perhaps ending with a deletion. When confronted with differing
    versions of a file (one of the versions may be a deleted version), we
    declare that it is acceptable to synchronize them if one's history is
    a prefix of the other's. The file with the full history replaces the
    file with the prefix.  The intuition is that synchronization should
    never lose events in a file's life.  }
}

_____________________________________________________________________________________
**     Kang et al, Hash History Approach...

Very useful citations!  Paper is not too well written though -- hard to see
what the algorithm actually does.

@inproceedings{kang03hh,
  author = {Brent ByungHoon Kang and Robert Wilensky and John Kubiatowicz},
  year = 2003,
  title = {The Hash History Approach for Reconciling Mutual Inconsistency},
  booktitle = {23rd IEEE International Conference on Distributed Computing
              Systems {(ICDCS '03)}},
  url = {citeseer.nj.nec.com/kang03hash.html}
}

BCP:

\begin{itemize}
\item rather different approach to ours: they want to maintain the {\em
  whole} causal history rather than compressing it
\item their argument is that you have to maintain this anyway, because you
need to be able to go back and figure out the sequence of deltas between
your current version and any other version that you dominate.  Under this
assumption, the extra storage cost of saving the whole version history for
purposes of determining dominance is almost nil.  (However, the assumption
is not obvious.)
\item Storing dominance relations between replica states means that the size
of their data structures scales with the number of updates, not the total
number of sites.  They claim this is a win.  (Their related work covers a
number of papers with schemes for compressing vector clocks, though.)
\item one important similarity is that they recognize the importance of
``coincidental equalities'', which are a special case of the sorts of
agreement events that we want to capture.  (Indeed, we originally started
out thinking that they were the {\em only} kind of agreement events, as in
Unison.  But we later came to think that this was dangerous, since it
favored one particular use-case over other equally plausible ones.)  
\item Our
equality-agreement events were more permissive: Kang et al include an
``epoch number'' with each version hash, so they can only recognize equality
between two equal replicas in the case where the value being held by the
replicas has been seen the same number of times previously (since the last
``merge event'' between these hosts).
\item They've done some measurements showing that recognizing coincidental
equalities makes an enormous difference in rate of convergence.  However, I
am not sure I buy their assumptions: the explanation is puzzling, but I got
the impression that they are making unrealistically bad assumptions for
vector clocks (so that, once things get out of sync, they essentially never
get back in).  This comes out in a huge cumulative difference between vector
clocks and hash histories, which does not strike me as realistic: in both
systems, in practice, conflicts are going to get reconciled and the whole
system is going to move on from the same state.  Cumulative differences do
not make sense to me.  
\end{itemize}

*** Some citations from the Kang references:
**** Prakash et al, Hierarchical clocks
@article{prakash97wireless,
author = {R. Prakash and M. Singhal},
title = {Dependency Sequences and hierarchical clocks: efficient
alternatives to vector clocks for mobile computing systems},
journal = {Wireless Networks},
volume = 3,
number = 5,
year = 1997,
pages = {349--360}}

**** Ratner et al, Dynamic version vector maintenance,
http://citeseer.nj.nec.com/ratner97dynamic.html
@techreport{ratner97dynamic,
author = {D. Ratner and Peter Reiher and Gerald Popek},
title = {Dynamic version vector maintenance},
institution = {University of California, Los Angeles},
type = {Technical Report},
number = {CSD-970022},
month = {June},
year = {1997}}


_____________________________________________________________________________________
**     Wuu and Bernstein, Efficient Solutions to the Replicated Log and Dictionary Problems

(On of the) inventors of matrix clocks

@inproceedings{WuuBernstein84,
  author = {Gene T. J. Wuu and Arthur J. Bernstein},
  year = 1984,
  title = {Efficient Solutions to the Replicated Log and Dictionary Problems},
  booktitle = {Principles of Distributed Computing},
  pages = "233--242",
  checked = yes,
}

ALAN'S COMMENTS:

- Full matrices give a perfect view of the state of things, in the sense
  that it's not possible to gain more information from what other replica
  know to reduce what needs to be sent.
- There is a tradeoff between the matrix (or row) that is maintained and
  sent in every message and the size of the log that also needs to be
  sent. If we want to compare size, we'd need to think quite a bit about
  this (in our case the matrix is of size O(n^2), and the log size is O(1)
  (we only need to remember the latest value, whereas in their case they
  might have to remember several operations per value).
- The network topology can be used to get a more optimized data
  structure. For instance, if we know that some communications paths cannot
  be taken, and some paths must go through a gateway (a single replica that
  is the only neighbour to two replica), then the size of the matrix can be
  compressed (Strategies 2 and 3 in the paper). We have not yet studied
  these kind of optimizations
- And there is of course the question of agreement. We somehow need to make
  the case that we are also propagating information about them, and that it
  reduces the number of manual conflict resolutions that are needed.


_____________________________________________________________________________________
** ?   Sarin and Lynch, Discarding Obsolete Information in a Replicated Database System

(One of the) inventors of matrix clocks

@article{SarinLynch87,
  author = {Sunil K. Sarin and Nancy A. Lynch},
  year = 1987,
  title = {Discarding Obsolete Information in a Replicated Database System},
  journal = {IEEE Transactions onSoftware Engineering},
  pages = "39--47",
  volume = 13,
  number = 1,
}

_____________________________________________________________________________________
**     Drummond and Barbosa, On reducing the complexity of matrix clocks

@article{DrummondBarbosa03,
 author = {L\'ucia M. A. Drummond and Valmir C. Barbosa},
 title = {On reducing the complexity of matrix clocks},
 journal = {Parallel Computing},
 volume = {29},
 number = {7},
 year = {2003},
 issn = {0167-8191},
 pages = {895--905},
 doi = {http://dx.doi.org/10.1016/S0167-8191(03)00066-8},
 publisher = {Elsevier Science Publishers B. V.},
 }

**     Ruget, Cheaper Matrix Clocks

Frederic Ruget, "Cheaper Matrix Clocks", CS/TR-94-63, Chorus
system.
@misc{ruget94tr,
author = {Frederic Ruget},
title = {Cheaper Matrix Clocks},
note = {CS/TR-94-63, Chorus Systems, Montigny le Bx, France},
month = {July},
year = {1994}}

**  #  Hedaya, et al, Two phase gossip: managing distributed event histories

This looks important, because it is an early paper that reduces
matrix clocks to 2 rows.

@article{Hedaya89,
 author = {A. Heddaya and M. Hsu and W. Weihl},
 title = {Two phase gossip: managing distributed event histories},
 journal = {Information Science},
 volume = {49},
 number = {1-3},
 year = {1989},
 issn = {0020-0255},
 pages = {35--57},
 doi = {http://dx.doi.org/10.1016/0020-0255(89)90023-6},
 publisher = {Elsevier Science Inc.},
 }

**     Holliday, et al, Disconnection modes for mobile databases

@article{545045,
 author = {Joanne Holliday and Divyakant Agrawal and Amr El Abbadi},
 title = {Disconnection modes for mobile databases},
 journal = {Wirel. Netw.},
 volume = {8},
 number = {4},
 year = {2002},
 issn = {1022-0038},
 pages = {391--402},
 doi = {http://dx.doi.org/10.1023/A:1015542723791},
 publisher = {Kluwer Academic Publishers},
 }

Cited by Kshemkalyani and does talk about optimistic replication of
databases (over wireless networks), but this is not the main focus and the
paper as a whole seems quite systemsy and thin.  -BCP

**     Rabinovich, et al, "Scalable Update Propagation in Epidemic Replicated Databases"

@inproceedings{ rabinovich96scalable,
    author = "Michael Rabinovich and Narain H. Gehani and Alex Kononov",
    title = "Scalable Update Propagation in Epidemic Replicated Databases",
    booktitle = "Extending Database Technology",
    pages = "207-222",
    year = "1996",
    citeseerurl = "citeseer.ist.psu.edu/rabinovich95scalable.html" 
}

MBG: Basic idea is to use vector clock for entire database,
rather than per item, to detect in constant time whether a
comparison is needed.  Then some tricks to go through item by
item efficiently.  Questionable assumptions, but even if
reasonable, not directly relevant to us.

_____________________________________________________________________________________
**        Baquero and Moura, Causality in autonomous mobile systems

@misc{ baquero99causality,
  author = "C. Baquero and F. Moura",
  title = "Causality in autonomous mobile systems",
  text = "Carlos Baquero and Francisco Moura. Causality in autonomous mobile systems.
    In Third European Research Seminar on Advances in Distributed Systems. Broadcast,
    EPFL-LSE, April 1999.",
  year = "1999",
  url = "http://gsd.di.uminho.pt/publications/gsd-1999-04",
  oldurl = "citeseer.nj.nec.com/baquero99causality.html" 
}

BCP: I just skimmed it.  It's short and not very well written, but seems
quite interesting.  However, from the authors, date, and some of the
figures, I'm guessing that it is superseded by the next one.

_____________________________________________________________________________________
**     Almeida et al, Version Stamps - Decentralized Version Vectors

@inproceedings{ almeida-version,
  author = "Paulo Sergio Almeida and Carlos Baquero and Victor Fonte",
  title = "Version Stamps -- Decentralized Version Vectors",
  booktitle = {Proceedings of {22nd} {IEEE} International Conference on Distributed Computing Systems {(ICDCS '02)}},
  year = 2002,
  citeseerurl = "citeseer.nj.nec.com/almeida02version.html" 
}

BCP: Addresses the problem of efficiently representing version vectors when
replicas can leave and join.  This seems not terribly relevant for us right
now, though it could get terribly relevant at some point if we get serious
about implementation!  (Alan disagrees: their join events look to him very
similar to our agreement events.)

ALAN'S COMMENTS:

First, it might be interesting to say 
  that this paper is used in a tool (that seems to have died 3 years ago) 
  called panasync (see \verb+http://panasync.sourceforge.net/+), which seems 
  very related to Unison: md5 used to detect file changes, conflicts are 
  solved "manually" (no automatic resolution).

  The approach in this paper is very similar to the version vector approach by 
  taking the max for agreement events.  So it means that they may have to do 
  more agreement events than us. They also only consider synchronous 
  synchronization (both replicas do the synchronization at the same time) 
  instead of local agreement events.

  What is interesting about this paper is twofold:
  \begin{itemize}
    \item they describe how to deal with a variable number of replicas, with 
      "forking" of new replicas and "joining" (which is the same than our 
      agreement event) of existing replica (a synchronization is joining 
      followed by forking);
    \item they have a nice sparsification algorithm that reminds me of our 
      cones: only remember the frontier (intuitively the set of currently 
      conflicting values), and after joining bring parts of it together (this 
      is what they call "simplification").
  \end{itemize}

  So in summary it seems like a good example of a working nway causality 
  detector with agreements, but not as refined as what we're trying to do.

@inproceedings{panasync,
 author = {Paulo S{\'e}rgio Almeida and Carlos Baquero and Victor Fonte},
 title = {Panasync: dependency tracking among file copies},
 booktitle = {EW 9: Proceedings of the 9th workshop on ACM SIGOPS European workshop},
 year = {2000},
 isbn = {1-23456-789-0},
 pages = {7--12},
 location = {Kolding, Denmark},
 doi = {http://doi.acm.org/10.1145/566726.566729},
 publisher = {ACM Press},
 }
_____________________________________________________________________________________
**     Almeida et al, Bounded Version Vectors

BCP: Intro includes an interesting --- but, to me, somewhat confusing ---
discussion of vector clocks vs. version vectors.  The claim is that,
although they work exactly the same, they should be considered as different
because vector clocks are used to place an ordering ordering on events at
some set of replicas while version vectors are used just to detect
incompatibility between values stored at different replicas.  I still am not
clear on the precise difference -- they cite a result of Charron-Bost saying
that no smaller data structure can keep track of the same information, but
emphasize that they are solving a different problem and can do it more
efficiently -- but even so, it seems like the terminological distinction
should focus on the (different) things being computed, not on the
(identical) structures used to do it.

The point of the paper, FWIW, is that -- for the job that version vectors
do -- a bounded amount of information suffices (you don't need arbitrary
size integers).

KK: They first establish the difference between version vectors and vector
clocks(which they admit are often used interchangably by people) :

 For any pair of replicas r_a and r_b, version vectors can establish
if r-a=r_b, r_a > r_b , r_a < r_b or r_a || r_b  (unrelated).
Vector clocks, in addition to that, can also establish the relation
between any pair of update events. Hence the impossibility results
about vector clocks being the minimal representation(and hence not
having a smaller representation) do not apply to version vectors.


They give a mechanism whereby one can replace the integer
counters(which depend on # of updates and are hence unbounded) in
vector clocks with a finite set of labels and yet be able to infer causal
dependencies between pairs of replicas correctly.
The downside is that each integer entry needs to be replaced by a
matrix of size O(n^2) where each entry in the matrix comes from a
finite set of labels,  where the size of the set of labels is of size
O(n^2).

They also assume pairwise symmetrical synchronization. 

@inproceedings{DBLP:conf/wdag/AlmeidaAB04,
  author    = {Jos{\'e} Bacelar Almeida and
               Paulo S{\'e}rgio Almeida and
               Carlos Baquero},
  title     = {Bounded Version Vectors.},
  booktitle = {DISC},
  year      = {2004},
  pages     = {102-116},
  ee        = {http://springerlink.metapress.com/openurl.asp?genre=article{\&}issn=0302-9743{\&}volume=3274{\&}spage=102},
  crossref  = {conf/wdag/2004},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@proceedings{DBLP:conf/wdag/2004,
  editor    = {Rachid Guerraoui},
  title     = {Distributed Computing, 18th International Conference, DISC
               2004, Amsterdam, The Netherlands, October 4-7, 2004, Proceedings},
  booktitle = {DISC},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {3274},
  year      = {2004},
  isbn      = {3-540-23306-7},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

_____________________________________________________________________________________
**     Kshemkalyani, The power of logical clock abstractions

@article{Kshemkalyani2004,
 author = {Ajay D. Kshemkalyani},
 title = {The power of logical clock abstractions},
 journal = {Distrib. Comput.},
 volume = {17},
 number = {2},
 year = {2004},
 issn = {0178-2770},
 pages = {131--150},
 doi = {http://dx.doi.org/10.1007/s00446-003-0105-9},
 publisher = {Springer-Verlag},
 }

Looks interesting, but maybe not so relevant to us (just a nice
generalization of matrix clocks; no notion of agreement).  The introduction
has a wonderfully clear (and up to date) overview of scalar, vector, and
matrix clocks.

Saved locally as nway/Kshemkalyani2004.pdf

ABSTRACT: Vector and matrix clocks are extensively used in asynchronous
distributed systems. This paper asks, "how does the clock abstraction
generalize?" To address this problem, the paper motivates and proposes
logical clocks of arbitrary dimensions. It then identifies and explores the
conceptual link between such clocks and knowledge. It establishes the
necessary and sufficient conditions on the size and dimension of clocks
required to attain any specified level of knowledge about the timestamp of
the most recent system state for which this is possible without using any
messages in the clock protocol. The paper then gives algorithms to determine
the time-stamp of the latest system state about which a specified level of
knowledge is attainable in a given system state, and to compute the
timestamp of the earliest system state in which a specified level of
knowledge about a given system state is attainable. The results are
applicable to applications that deal with a certain class of properties,
identified as monotonic properties. 
_____________________________________________________________________________________
**     Malkhi & Terry, Concise Version Vectors in WinFS
@inproceedings{Malkhi2005,
 author = {Dahlia Malkhi and Douglas B. Terry},
 title = {Concise Version Vectors in {WinFS}},
 booktitle = {Proceedings of the 19th International Conference on
Distributed Computing, {DISC 2005}},
 editor = {Pierre Fraigniaud},
 year = {2005},
 month = {September 26-29},
 location = {Cracow, Poland},
 isbn = {3-540-29163-6},
 pages = {339--353},
 volume = {3724},
 series       = {Lecture Notes in Computer Science},
 publisher = {Springer-Verlag},
 }



*
**   ??? SOME THINGS WE STILL NEED TO LOOK INTO RELATED TO CAUSAL ORDER AND VECTOR CLOCKS:


_____________________________________________________________________________________

***       Morgan, Global and Logical Time in distributed algorithms

@article{morgan85,
  author = "C. Morgan",
  title = "Global and Logical Time in distributed algorithms",
  journal = "Information Processing Letters",
  year = 1985,
  volume = 20,
  pages = "189--194",
  keywords = "good example on the use of logical clocks"
  }

***       Using Timewarp-like ideas instead of vector clocks
****         Strom et al, Optimistic Recovery in Distributed Systems",

@article{sy:OR,
  author = "Robert E. Strom and Shaula A. Yemini",
  title = "Optimistic Recovery in Distributed Systems",
  journal = "{ACM} {T}ransactions on {C}omputer {S}ystems",
  year = "1985",
  volume = "3",
  number = "3",
  pages = "204--226",
  month = "August",
  keywords = "combines the optimistic principle underlying Jefferson's work
                 with the time-as-partial-order ideas of Lamport",
  url = "http://doi.acm.org/10.1145/3959.3962",
  }

BCP: Not closely related to our n-way stuff.  It seems to be basically a way
of replacing conflict resolution (in our sense) by rolling back to a state
before the conflict happened.

ABSTRACT: Optimistic Recovery is a new technique supporting
application-independent transparent recovery from processor failures in
distributed systems. In optimistic recovery communication, computation and
checkpointing proceed asynchronously. Synchronization is replaced by causal
dependency trocking, which enables a posteriori reconstruction of a
consistent distributed system state following a failure using process
rollback and message replay.  Because there is no synchronization among
computation, communication, and checkpointing, optimistic recovery can
tolerate the failure of an arbitrary number of processors and yields better
throughput and response time than other general recovery techniques whenever
failures are infrequent.


****         One of original Timewarp articles by Jefferson

@article{Jefferson85,
  author = "David R. Jefferson",
  title = "Virtual Time",
  journal = toplas,
  year =  1985,
  volume = 7,
  number = 3,
  pages = "404-425",
  month = jul,
  keywords = "virtual time, simulation, time warp",
  url = "http://doi.acm.org/10.1145/3916.3988"
  }

***       Relationship between lamport ordering and synchronized clocks

I am pretty sure that this will turn out to be irrelevant, but I
have not read these papers yet. --- MBG

_____________________________________________________________________________________
****         Neiger et al, Substituting for Real Time and Common Knowledge in Async Dist Systems

@conference{neiger87,
  author = "Gil Neiger and Sam Toueg",
  title = "Substituting for Real Time and Common Knowledge in Asynchronous
             Distributed Systems",
  booktitle = "Proceedings of the Symposium on Principles of Distributed
    Computing",
  year = 1987,
  organization = {ACM SIGPLAN/SIGOPS},
  pages = "281--293",
  keywords = "shows how standard Lamport logical clocks (with simple
                modifications) can be used to simulate synchronized clocks"
  }

_____________________________________________________________________________________
****         Welch (similar to Neiger), Simulating Synchronous Processors

@article{Welch87,
  author = "Jennifer Lundelius Welch",
  title = "Simulating Synchronous Processors",
  journal = "Information and Computation",
  year = 1987,
  month = aug,
  volume = 74,
  number = 2,
  pages = "159--171",
  keywords = "similar results to Neiger and Toueg"
  }
_____________________________________________________________________________________
****         Dolev et al, Reaching approximate agreement in the presence of faults

  @conference{Dolev83,
  author = "D. Dolev and N. Lynch and S. Pinter and E. Stark and W. Weihl",
  title = "Reaching approximate agreement in the presence of faults",
  booktitle = "Proceedings of the Third Symposium on Reliability in
                Distributed Software and Database Systems",
  year = 1983,
  pages = "145-154",
  month = "October",
  }
_____________________________________________________________________________________
****         Schneider, Understanding Protocols for {B}yzantine Clock Synchronization

  @techreport{schneider87,
  author = "Fred B. Schneider",
  title = "Understanding Protocols for {B}yzantine Clock Synchronization",
  institution = "Cornell University",
  address = "Dept. of Computer Science, Upson Hall, Ithaca, NY 14853",
  month = "August",
  number = "TR 87--859",
  year = 1987,
  keywords = "survey on clock synchronization algorithms,
               including lots of references"
  }
_____________________________________________________________________________________

*
* COHERENCY AND CAUSAL HISTORY

_____________________________________________________________________________________
**    Imine et al, Proving correctness of transformation functions in real-time groupware

_____________________________________________________________________________________
**    Alur and Greenwald, group coherency
@TechReport{ GroupCoherencyTR2001,
author = "Rajeev Alur and Michael B. Greenwald",
title = {Coherency of Shared Memory in Ad-hoc Networks},
year = 2001,
type = "Technical Report",
number = "MS-CIS-01-29",
institution = "Department of Computer and Information Science,
University of Pennsylvania"
}

_____________________________________________________________________________________
**    E. Pitoura and B. Barghava, consistent data in desoat
@article{pitoura:kde99,
author = {E.~Pitoura and B.~Barhia},
title = {Data Consistency in Intermittently Connected Distributed Systems},
journal = {{IEEE} Transactions on Knowledge and Data Engineering},
volume = 11,
number = 6,
month = {Nov/Dec},
year = 1999,
pages = {896--915}
}


_____________________________________________________________________________________
_____________________________________________________________________________________

*
* EPIDEMIC ALGORITHMS

_____________________________________________________________________________________
**    Demers et al, Epidemic Algorithms for Replicated Database Maintenance

@InProceedings{DemersGH+87,
  title = "Epidemic Algorithms for Replicated Database Maintenance",
  author = "Alan Demers and Dan Greene and Carl Hauser and Wes Irish and
    John Larson and Scott Shenker and Howard Sturgis and Dan Swinehart
    and Doug Terry",
  booktitle = "Proceedings of PODC'87",
  month = "August",
  year = "1987",
  url = "http://www.cs.cornell.edu/vogels/Epidemics/epidemic-demers.pdf",
  summary = {
Main metrics of concern are:
1. Time required for an update to propagate to all sites.
2. "Residue"--how many nodes never receive a given update?
3. Network traffic generated to propagate a single update.

3 strategies:
1. Direct mail: each new update is immediately mailed from its originating
site to all other sites.
2. Anti-entropy: each site regularly chooses another site at random and
reconciles any differences by exchanging database contents.
3. Rumor mongering: sites are initially "susceptible", and become
"infective" when the receive an update. Infective nodes periodically choose
another node at random and attempt to infect it (where infecting an
already-infected node doesn't work). After some number of failures, a node
can subsequently become "immune", where it knows about the update but is no
longer attempting to spread it.

Use "death certificates" to indicate deletions (else absences might be
accidentally resurrected by some node that doesn't know about the deletion
yet). "Dormant" death certificates act like antibodies; most nodes can
forget about the deletions, but some will retain the dormant DCs and will
re-enable themselves if they encounter an incorrect resurrection.

Instead of choosing nodes to communicate with according to a uniform
distribution, use a distribution that is a function of distance between
nodes and/or topology --> can lead to much lower traffic on
bottleneck/critical links.

Idea that works well: use rumor-mongering to propagate updates initially,
then do periodic anti-entropy to pick up the last few nodes that got
missed. "There is a trade-off between the retention time for death
certificates, the storage space consumed, and the likelihood of old data
undesirably reappearing in the database. By retaining dormant death
certificates at a few sites we can significantly improve the network's
immunity to obsolete data at a reasonable storage cost."}
}

_____________________________________________________________________________________
**    A (garbled) abstract of a NYT article on new epidemic alg. research

"With 6 Degrees of Separation, Computers Stay in Sync"
 New York Times (02/27/03) P. E8; Austen, Ian

A team of scientists have developed a mathematical model demonstrating
 that the "six degrees of separation" theory, which speculates that
 any two people can be connected through no more than six other
 people, also applies to synchronized computing.  Physicist Gyorgy
 Korniss, currently assistant professor at Rensselaer Polytechnic
 Institute, noted that networked computers cannot maintain
 synchronization because parallel networks break down calculative
 problems in stages: Each computer must complete one stage of the
 problem before a new series of calculations can start, which gives
 rise to idle computers that must wait for slower-moving processors to
 catch up.  Centralized synchronization only increases the amount of
 computer inactivity, so Dr. Korniss teamed up with Zoltan Toroczkai
 to research how many processors could be added to a parallel system
 before it collapses.  They theorized that the number of processors
 that could be added to parallel systems was infinite, and started
 investigating ways to address the synchronization problem.  Their
 solution was partly inspired by biological research Korniss was
 conducting, which involved the development of a massively parallel
 computer model designed to simulate how the introduction of new
 species would affect a given region.  The model Korniss, Toroczkai,
 and three other U.S.-based researchers devised supports
 synchronization by having processors make periodical, random checks
 on what another processor in the system is doing; Korniss adds that
 the system can still maintain synchronization even with a few
 inactive processors.  Unlike the small-world theory about six degrees
 of separation, the synchronized system lacks hubs comparable to
 people who can claim an unusual number of links to others.  The
 theory could be applied to a computer at Los Alamos National
 Laboratory that simulates human interaction in order to anticipate
 the path of disease epidemics.
 http://www.nytimes.com/2003/02/27/technology/circuits/27next.html

*
* MISC PAPERS ON SYNCHRONIZATION
_____________________________________________________________________________________
**    Ceri et al, Designing a Global Name Service

@article{ ceri95independent,
    author = "Stefano Ceri and Maurice A. W. Houtsma and Arthur M. Keller and Pierangela Samarati",
    title = "Independent Updates and Incremental Agreement in Replicated Databases",
    journal = "Distributed and Parallel Databases",
    volume = "3",
    number = "3",
    pages = "225-246",
    year = "1995",
    citeseerurl = "citeseer.ist.psu.edu/article/ceri95independent.html" 
}

MBG: Interesting paper on reconiliation.  Operation based, uses
timestamped history of operations to determine how to merge logs.
Supports only eventual consistency.  When dropping assumption of
commutativity, has a naive treatment of undo (not surprising,
because it predates the other "undo" papers cited here).

Keeps two vectors: reception vector and propagation vector to
tell how up to date each site is with respect to each object in
the database.  Info is used to make communication more efficient
and manage garbage collection of log entries.

*
* MISC SYSTEMS PAPERS
_____________________________________________________________________________________
**    Lampson, Designing a Global Name Service

@InProceedings{Lampson86,
  title = "Designing a Global Name Service",
  author = "Butler W. Lampson",
  booktitle = "Proc. 4th ACM Symposium on Principles of Distributed
    Computing",
  year = "1986",
  pages = "1--10",
  url = "http://www.cse.ogi.edu/class/cse515/papers/Lampson-GlobalNames.pdf",
  summary = {
Lampson provides a global name service that provides the abstraction of
directory trees. All updates are time-stamped, and later time-stamps take
precedence; this allows concurrent updates without prior synchronization
(although it assumes some NTP-like clock coordination, depending upon the
frequency of the updates). In this case, it is assumed that updates happen
fairly infrequently. Given directory entries may be replicated as directory
copies on different servers; these are arranged in a ring, and a "sweep"
process proceeds around the ring collecting updates and ensuring that every
eventually gets up-to-date.

Each directory also has an expiration time; arcs or links in the tree may
not be changed until they have expired; this allows for correct caching of
lookup results. All logical nodes have timestamps; updates must specify
paths as lists of (name,timestamp) pairs, and updates fail if their
timestamps are earlier than the current state. Since several updates taken
together will all have the same list of timestamps, this ensures that if
there are two batches of updates, only one will succeed.}
}

_____________________________________________________________________________________
**    Gray et al., The Dangers of Replication and a Solution

@InProceedings{GrayHOS96,
  title = {The Dangers of Replication and a Solution},
  author = {Jim Gray and Pat Helland and Patric O'Neil and Dennis Shasha},
  booktitle = sigmod96,
  year = "1996",
  pages = "173--182",
  url = "http://research.microsoft.com/~gray/replicas.ps",
  summary = {
Update-anywhere-anytime-anyway replication is unstable.
  1. If the number of checkbooks per account increases by a factor of ten,
  the deadlock or reconciliation rates rise by a factor of a thousand.
  2. Disconnected operation and message delays mean lazy replication has
  more frequent reconciliation.

Proposes a two-tier scheme, with base nodes that are always connected (and
propagate updates eagerly (atomically)) and mobile nodes that are allowed to
do optimistic disconnected updating. A mobile node keeps two versions of
each object: its own local view, and the "last known official" view. When a
mobile node syncs up, its transactions are attempted w.r.t. the current
official view, and any failures must be reconciled by the mobile node owner
that initiated the sync. Possibly requires log of updates?

Goals for an ideal replication scheme:
1. Availability and scalability: Provide high availability and scalability
through replication, while avoiding instability.
2. Mobility: Allow mobile nodes to read and update the database while
disconnected from the network.
3. Serializability: Provide single-copy serializable transaction execution.
4. Convergence: Provide convergence (in the absence of additional updates,
things eventually reach the same shared state) to avoid system delusion.

Two axes for replication:
Eager (updates are applied to all replicas of an object as part of the
original transaction) vs. Lazy (one replica is updated by the originating
transaction, updates to other replicas propagate asynchronously, typically
as a separate transaction for each node).
Group (any node with a copy of a data item can update it (update-anywhere))
vs. Master (each object has a master node, only the master can update it,
all other replicas are read-only)

Observations:
"Lazy-group replication just converts waits and deadlocks into
reconciliations. Lazy-master replication has slightly better behavior than
eager-master replication. Both suffer from dramatically increased deadlock
as the replication degree rises. None of the master schemes allow mobile
computers to update the database while disconnected from the system."}
}

*
* BAYOU

_____________________________________________________________________________________
**    Edwards et al., Designing and Impl Async Collaborative Apps with Bayou

@InProceedings{EdwardsMP+97,
  title = "Designing and Implementing Asynchronous Collaborative
    Applications with {Bayou}",
  author = {W. Keith Edwards and Elizabeth D. Mynatt and Karin Petersen
    and Mike J. Spreitzer and Douglas B. Terry and Marvin M. Theimer},
  booktitle = "{ACM} {S}ymposium on {U}ser {I}nterface
               {S}oftware and {T}echnology ({UIST}), Banff, Alberta",
  month = oct,
  year = 1997,
  url = "http://www2.parc.com/csl/members/kedwards/pubs/bayou.pdf",
  pages = "119--128",
  summary = {
[XXX: check out conference Computer-Supported Collaborative Work (CSCW)]

Properties of asynchronous collaboration:
1. Collaboration *needn't necessarily* happen at the same time.
2. Users do not need to coordinate with one another interactively, and do
not need to be notified in "real time" of each other's changes.
3. Users can work largely independently of one another.

Disconnected operation ==> can only provide weak consistency.

Bayou design:
pairwise synchronization ==> handle arbitrary network topology. Conflicts
are handled automatically (without user intervention) according to
application-specific conflict resolution code "mergeprocs".

Example Bayou applications:
1. Collaborative Bibliographic Database (BibDB)
2. Group Calendar --> color-code any tentative data
3. Mobile Electronic Mail
4. Bayou Project Coordinator

Claimed properties of Bayou:
1. Efficient anywhere/anytime access to data: all replicas writable, weak
consistency.
2. Automatic management of conflicts: via application-provided heuristics.
3. "Self consistency" and awareness of data status: session abstraction.
4. Flexible data model: relational DB.
5. Fluid transition between synchronous and asynchronous modes of operation
simply by switching what Bayou server your app is connected to.}
}

_____________________________________________________________________________________
**    Terry et al, Managing Update Conflicts in Bayou

@inproceedings{terry95managing,
    author = "Douglas B. Terry and Marvin M. Theimer and Karin Petersen
            and Alan J. Demers and Mike J. Spreitzer and Carl H. Hauser",
    title = "Managing Update Conflicts in {B}ayou, a Weakly Connected Replicated Storage System",
    booktitle = "Proceedings of the 15th {ACM} Symposium on Operating Systems Principles
            ({SOSP}-15), Copper Mountain Resort, Colorado",
    year = "1995",
    pages = {172--183},
    citeseerurl = "citeseer.ist.psu.edu/terry95managing.html" 
}


_____________________________________________________________________________________
_____________________________________________________________________________________

*
* ICECUBE

_____________________________________________________________________________________
**    Kermarrec et. al. "The IceCube Approach to ... reconciliation ..."
A.-M. Kermarrec, A. Rowstron, M. Shapiro and P. Druschel, The
IceCube approach to the reconciliation of diverging replicas.
In proceedings of the 20th annual ACM
SIGACT-SIGOPS Symposium on Principles of Distributed Computing
(PODC) Aug. 26-29, 2001. Newport, Rhode Island
@inproceedings{icecube:podc01,
	author = {Anne-Marie Kermarrec and Antony Rowstron and Marc Shapiro and
		  Peter Druschel},
	title = {The {IceCube} approach to the reconciliation of
		  diverging replicas},
	booktitle = {{ACM}
			{SIGACT-SIGOPS} Symposium on Principles of
			Distributed Computing (PODC), Newport, Rhode Island},
	month = aug,
	year = {2001},
        pages = "210--218",
}


IceCube is a Bayou-like system that allows for greater
conflict-free reconciliation by relaxing the requirement that
reconciliation preserves the local order of operations.  Instead,
it allows reorderings that avoid "conflicts" and looks for a best
order that preserves intent.  Users provide static and dynamic
constraints that describe intent and identify conflicts. -- MBG

_____________________________________________________________________________________
**    Preguica et. al. "Efficient Semantics-aware reconciliation ..."
@TechReport{ IceCubeTR2002,
  author = "Nuno PreguiÁa and Marc Shapiro and Caroline Matheson",
  title = "Efficient semantics-aware reconciliation for optimistic write sharing",
  year = 2002,
  month = may,
  type = "Technical Report",
  number = "MSR-TR-2002-52",
  institution = "Microsoft Research",
  url = "ftp://ftp.research.microsoft.com/pub/tr/tr-2002-52.pdf",
  schmittacomment = {
    This TR describes an algorithm for centrally synchronizing application
    logs to obtained a reconciled that satisfies some constraints. The
    constraints can either be static (if it does not depend on the shared
    state) or dynamic. Primitive static constraints are "order": a -> b if
    both a and b are scheduled implied a occurs before b, and "implies":
    a => b if a is scheduled implies that b is schedule (not necessarily in
    this order). (I have not understood the difference between "log
    constraints and object constraints).

    The two main differences with our work on Harmony are that this system
    requires application support (to generate the logs of actions), and is
    centralized (there is no notion of causal history as every synchronization
    is global). I have not understood how the system deals with non-avoidable
    conflicts.  }
}
We should give this one highest priority because it is the most recent.  BCP
should definitely read it before traveling to MSR.

_____________________________________________________________________________________
**    Shapiro et. al. "Application-independent reconciliation for nomadic applications"
M. Shapiro, A. Rowstron and
A.-M. Kermarrec. "Application-independent reconciliation for
nomadic applications". Proc. SIGOPS European
Workshop on ``Beyond the PC: New Challenges for the Operating
System'', Kolding (Denmark), Sept. 2000.

_____________________________________________________________________________________
**    IceCube software

Available in pre-alpha (and win32 only!) form.  Turns out to be a minimally
documented set of Java files from summer 2001 with little in the way of
indication how to get anything running.  Most of the files seem to be for a
calendar app.  Not extremely interesting.

_____________________________________________________________________________________
_____________________________________________________________________________________

*
* CODA

_____________________________________________________________________________________
**    Satya et al, Coda: A Highly Available File System for a Distributed Workstation Environment

@article{satyanarayanan90coda,
    author = "M. Satyanarayanan and James J. Kistler and Puneet Kumar and Maria E. Okasaki
              and Ellen H. Siegel and David C. Steere",
    title = "Coda: A Highly Available File System for a Distributed Workstation Environment",
    journal = "IEEE Transactions on Computers",
    volume = "39",
    number = "4",
    pages = "447-459",
    year = "1990",
    citeseerurl = "citeseer.ist.psu.edu/satyanarayanan90coda.html" 
}

Contains quite a bit of technical information, but is tantalizingly brief on
the details of the "repair" operation, which is used "to fix inconsistency
and proceeds in two phases, similar to an update."  CVVs are mentioned, but
again with little detail.

_____________________________________________________________________________________
**    Kumar, Coping with Conflicts in an Optimistically Replicated File System

@inproceedings{ kumar90coping,
  author =       "Puneet Kumar",
  title =        "Coping with Conflicts in an Optimistically
                  Replicated File System",
  booktitle =    "1990 Workshop on the Management of Replicated
                  Data",
  address =      "Houston, TX",
  pages =         "60--64",
  month =        "Nov",
  year =         "1990",
  citeseerurl = "citeseer.ist.psu.edu/kumar90coping.html" 
}

Short workshop paper giving details on some of Coda's procedures for
performing conflict resolution.  Surprisingly global!

The critical mechanism for us is Coda Version Vectors (CVVs) [described
(briefly!) in satyanarayanan90coda].

_____________________________________________________________________________________
**    Kumar and Satya, Flexible and Safe Resolution of File Conflicts

@inproceedings{kumar95flexible,
    author = "Puneet Kumar and M. Satyanarayanan",
    title = "Flexible and Safe Resolution of File Conflicts",
    booktitle = "Proceedings of the annual {USENIX} 1995 Winter
Technical Conference",
    pages = "95-106",
    month = {January},
    year = "1995",
    note = {New Orleans, {LA}},
    citeseerurl = "citeseer.ist.psu.edu/kumar95flexible.html" 
}
_____________________________________________________________________________________
_____________________________________________________________________________________

*
* FARSITE
http://www.research.microsoft.com/sn/farsite/

______________________________________________________________________________________
**    Feasibility of a Serverless Distributed File System Deployed on an Existing Set of Desktop PCs

Conference SIGMETRICS 2000

Authors William J. Bolosky, John R. Douceur, David Ely, and Marvin Theimer

Abstract

We consider an architecture for a serverless distributed file system that does
not assume mutual trust among the client computers. The system provides
security, availability, and reliability by distributing multiple encrypted
replicas of each file among the client machines. To assess the feasibility of
deploying this system on an existing desktop infrastructure, we measure and
analyze a large set of client machines in a commercial environment. In
particular, we measure and report results on disk usage and content; file
activity; and machine uptimes, lifetimes, and loads. We conclude that the
measured desktop infrastructure would passably support our proposed system,
providing availability on the order of one unfilled file request per user per
thousand days.

Citation 	W. J. Bolosky, J. R. Douceur, D. Ely, M. Theimer; Proceedings
of the international conference on Measurement and modeling of computer
systems, 2000, pp. 34-43

http://www.research.microsoft.com/sn/farsite/Sigmetrics2000.pdf

@inproceedings{farsite-osdi,
  author = { Atul Adya and William J. Bolosky and Miguel Castro and Gerald
    Cermak and Ronnie Chaiken and John R. Douceur and Jon Howell and Jacob R.
    Lorch and Marvin Theimer and Roger P.  Wattenhofer },
  title = { FARSITE: Federated, Available, and Reliable Storage for an
    Incompletely Trusted Environment },
  booktitle = { Proceedings of the 5th OSDI },
  year = { 2002 },
  month = { Dec },
  abstract = { Farsite is a secure, scalable file system that logically
    functions as a centralized file server but is physically distributed among
    a set of untrusted computers. Farsite provides file availability and
    reliability through randomized replicated storage; it ensures the secrecy
    of file contents with cryptographic techniques; it maintains the integrity
    of file and directory data with a Byzantine-fault-tolerant protocol; it is
    designed to be scalable by using a distributed hint mechanism and
    delegation certificates for pathname translations; and it achieves good
    performance by locally caching file data, lazily propagating file updates,
    and varying the duration and granularity of content leases. We report on
    the design of Farsite and the lessons we have learned by implementing much
    of that design. },
  url = { http://www.research.microsoft.com/sn/farsite/OSDI2002.pdf },
  schmittacomment = { They do not deal with disconnected operation, as they
    say on page 13: "An important area of distributed-file-systems research,
    but one that is orthogonal to Farsite, is disconnected operation." }
}

_____________________________________________________________________________________
_____________________________________________________________________________________

*
* OTHER SYSTEMS/TOOLS

_____________________________________________________________________________________
**    http://www.osafoundation.org/index.htm
%   (A bit of web searching shows that there is an on-line paper about
%   Chandler at http://www.osafoundation.org/architecture.htm.  I
%   haven't read it yet. -MG)
%   (I've read it, they talk about synchronizations and views, but as a
%   wishlist, they do not specify any technical solution. -AS)
%   But now [May 03] there is a pre-release there -- we should go over it
%   again. -BCP
%
_____________________________________________________________________________________
**    www.groove.net  and  www.distributed.net
%   iCommune ("Napster with access control, over Rendezvous") -- might be
%     an interesting technology for us to work on top of
%   yukon (MS SQL-in-FS thing -- product?)
%   lots of synchronizers listed in Apple OSX Downloads
%  http://www.fifthvision.net/open/bin/view/Arch/WebHome
%    This is a revision control system, and it mentions having distributed
%    repositories and a fairly advanced "merge" step.
%
_____________________________________________________________________________________
**    Saito et al, "Taming aggressive replication in the Pangaea wide-area file system",
      Y. Saito, C. Karamariolis, M. Karlsson, and M. Mahalingam OSDI 2002.

This is interesting because it is very recent.

@inproceedings{ saito02taming,
  author = {Yasushi Saito and Christos Karamonolis and Magnus Karlsson and Mallik Mahalingam},
  title = "Taming aggressive replication in the Pangaea wide-area
file system",
  booktitle = {Proceedings of the 5th Symposium
    on Operating Systems Design and Implementation ({OSDI} '02)},
  pages = {15--30},
  month = {December},
  year = "2002",
  note = {Boston, {MA}},
  citeseerurl = "citeseer.ist.psu.edu/saito02taming.html" 
}

Need to read this carefully.  From skimming intro, it is related
because it allows optimistic updates and resolves conflicts in
the background.  However, very different than us because it
assumes that everyone is always connected if their node is up.
Thus no disconnected nodes make updates.  Weakly consistent,
"guarantee" is to resolve consistency conflicts "within minutes",
in practice resolution occurs "within 5 seconds." --- MBG

_____________________________________________________________________________________
**    PersonalRAID (interesting sync project)
%   http://www.cs.princeton.edu/~rywang/papers/fast02a/pr/

_____________________________________________________________________________________
**    Rasch and Burns, In-Place Rsync: File Sync for Mobile & Wireless Devices

In the 2003 Usenix Technical conference:
  In-Place Rsync: File Synchronization for Mobile and Wireless Devices
  David Rasch and Randal Burns, Johns Hopkins University

_____________________________________________________________________________________
**    Lanham, et. al. FCDP (Format-Independent Change Detection and Propoagation)

In the 2002 Symposium on Databases (Brazil)
  Format-Independent Change Detection and Propoagation in Support of Mobile Computing
  M. Lanham, A. Kang, J. Hammer, A. Helal, and J. Wilson, University of Florida

@inproceedings{lanham:sbbd02,
 author = {M. Lanham and A. Kang and J. Hammer and A. Helal and J. Wilson},
 title = {Format-Independent Change Detection and Propagation in Support of Mobile Computing},
 booktitle = {Brazilian Symposium on Databases (SBBD), Gramado, Brazil},
 pages = "27--41",
 year = 2002,
 month = oct,
}

_____________________________________________________________________________________
**    Ratner, Roam: A Scalable Replication System for Mobility 

@article{Roam04,
 title = {Roam: a scalable replication system for mobility},
 author = "David Ratner, Peter Reiher and Gerald J. Popek",
 journal = {Mob. Netw. Appl.},
 volume = {9},
 number = {5},
 year = {2004},
 issn = {1383-469X},
 pages = {537--544},
 doi = {http://doi.acm.org/10.1145/1027347.1027356},
 publisher = {Kluwer Academic Publishers},
 }

ABSTRACT: Nomadic users require replication to store copies of critical data on their
mobile machines while disconnected or poorly connected. Existing replication
services do not provide all classes of mobile users with the capabilities
they require, which include: the ability for direct synchronization between
any two replicas, support for large numbers of replicas, and detailed
control over what files reside on their local (mobile) replica. Mobile users
must adapt their behavior to match the level of service provided by today's
replication systems, thereby hindering mobility and costing additional time,
money, and systems management. 

Roam is a replication system designed to satisfy the requirements of the
mobile user. Roam is based on the Ward Model, a replication architecture for
mobile environments. Using the Ward Model and new distributed algorithms,
Roam provides a scalable replication solution for the mobile user. We
describe the motivation, design, and implementation of Roam and report its
performance. 


ALSO: 

@phdthesis{926258,
 author = {David Howard Ratner},
 note = {Co-Chair-Gerald J. Popek and Co-Chair-W. W. Chu},
 title = {Roam: a scalable replication system for mobile and distributed computing},
 year = {1998},
 isbn = {0-591-69395-X},
 order_no = {AAI9818027}},
 }



_____________________________________________________________________________________
** #  Richard et al,  Clique: A transparent, Peer-to-Peer collaborative file sharing system

@inproceedings{richard:mdm03,
author = {Bruno Richard and Donal Mac Nioclais and Denis Chalon},
title = {Clique: a transparent, peer-to-peer collaborative file sharing system},
booktitle = {International Conference on Mobile Data Management (MDM), Melbourne, Australia},
month = jan,
year = 2003,
url = "http://www.hpl.hp.com/techreports/2002/HPL-2002-307.pdf"
}

BCP: Extremely relevant to both Unison and Harmony, particularly wrt. n-way
synchronization.

The reconciliation algorithm is based on "version histories," which seem
akin to hash histories.  (They cite Reconcile as the source of the idea.)
Basically, each node maintains a complete (back to some horizon) record of
all the states a given file has gone through.  When one replica talks to
another, it transmits all current states of all files it knows (!).  The
receiving host compares these states to its own current and past states: if
the states are identical, then the files are synchronized and nothing
happens.  If not, then the receiving host searches for the sending host's
current state throughout its own history --- if it finds it, then it decides
that its own version is better and updates the receiver.  (Surely this can't
be right!  Suppose, for example, that the sender's file has been through
states AB and the receiver's has been through states XYZPQRSetcetcetcXYZA.
It does not seem right to update the receiver with B!)

Lots of low-level fanciness using IP multicast for efficient transmission of
updates.

Includes this useful summary of other peer-to-peer filesystems work:

  A recent trend has been the emergence of a second
  generation of fully peer-to-peer platforms. These systems
  such as Freenet [10], Chord [11], Pastry [12], Tapestry
  [13], CAN [14], Hypercast [15] typically construct a
  server-less overlay network at the application level that
  implements a distributed hash table. For each file to be
  stored, a unique key is produced by, for example, hashing
  the file contents. Each node in the overlay stores files
  relating to a particular range of key values. The system
  supports put and get operations, which store and retrieve
  files at the corresponding node. These overlay networks
  exhibit very high levels of fault -tolerance and generally
  scale well, with O(logN).

  A number of file systems, such as CFS [16], PAST
  [17] and Oceanstore [18] have been implemented on top
  of these systems . PAST and CFS are designed for use as
  read-only archival and publishing platforms. Oceanstore
  adds a client-server layer with strong security and scalability
  features in order to provide a global storage repository
  distributed across a vast number of untrusted network
  nodes. However, these systems do not support traditional
  file system semantics, such as delete and rename
  operations.
  
  Other efforts [19], [20], [21], [22], [23] have focused
  on replication policies, such as gossiping, rumoring and
  anti-entropy algorithms. In the Clique case, we took an
  approach relying on a one-to-all communication channel.

_____________________________________________________________________________________
**    Cohen, A Java Framework for mobile data synchronization

@inproceedings{cohen:00,
author = {Norman H. Cohen},
title = {A {J}ava Framework for Mobile Data Synchronization},
url = "http://www.research.ibm.com/sync-msg/CoopIS2000.pdf",
booktitle = "Cooperative Information Systems (CoopIS)",
year = 2000,
pages = "287-298",
publisher = "Springer",
series = {Lecture Notes in Computer Science},
number=  1901,
comment = "Cooperative Information Systems: 7th International
  Conference, CoopIS 2000; Eilat, Israel, September 2000; Proceedings.
  Lecture Notes in Computer Science 1901, Springer-Verlag, Berlin, 2000,
  287-298"
}

BCP: I said before... "This is important stuff -- a recent, ambitious
project involving many companies!  We need to read in detail and grok
deeply."

But now I am not so convinced it is interesting, at least from the
perspective of our n-way stuff.  (If we were building our own system, then
we'd have to be very aware of this work.)  They seem to handle conflicts by
passing them off to application-specific code.  They mention version vectors
as their basic conflict detection mechanism.

_____________________________________________________________________________________

** ?? Coatta et al, A Data Synchronization Service for Ad Hoc Groups

A Data Synchronization Service for Ad Hoc Groups
Terry Coatta?, Norman C. Hutchinson†, Andrew Warfield‡ and Joseph H. T. Wong
2004 (where did it appear?)

_____________________________________________________________________________________

**    Golding and Long, Modeling replica divergence in a weak-consst. prtcl for global-scl dist dbs

@misc{golding93modeling,
author = {Richard A. Golding and Darrell D. Long},
title = {Modeling replica divergence in a weak-consistency protocol for global-scale distributed data bases},
note = {UCSC-CRL-93-09},
year = 1993,
abstract = {Distributed database systems for wide-area networks
must scale to 
very large numbers of replicas in order to provide acceptable
availability and response time. Weak-consistency replication
protocols, such as the timestamped anti-entropy (TSAE) protocol
we have developed, allow a database to scale to hundreds or
thousands of replicas. The TSAE protocol allows updates to be
processed by a single replica, then propagated from one replica
to another in the background, causing replicas to temporarily
diverge. The divergence is resolved in a short time and is
resolved correctly even in the presence of temporary replica
failure and network partition. We present a detailed analysis of
the update propagation latency and the divergence between
replicas caused by this protocol.}}

_____________________________________________________________________________________

**    Brodsky et al, Using File-Grain Connectivity to Implement a Peer-to-Peer File System

Using File-Grain Connectivity to Implement a Peer-to-Peer File System
Dmitry Brodsky, Alex Brodsky, Jody Pomkoski, Shihao Gong Michael J. Feeley, and Norman C. Hutchinson
http://www.cs.ubc.ca/spider/feeley/papers/2002-2.pdf

BCP: Describes the Mammoth file system -- a FS implemented on a P2P platform
but supporting a standard FS API.  Interesting project in several ways.

Conflict resolution is handled in what sounds like a standard way --
conflicts are detected and reported to the user for manual reconciliation.
(See section 3.5.)  Not clear how the reconciled is put back into a "good
state", but I guess this is standard.  

_____________________________________________________________________________________
_____________________________________________________________________________________

*
* FICUS AND RUMOR
**    Resolving File Conflicts in the Ficus File System, Reiher, Heideman ... and Popek
  reiher94usenix, (bcp.bib)
**    Implementation of the Ficus Replicated File System, Guy, Heidemann, Mak, Page Jr, Popek, and Rothmeier
**    Perspectives on Optimistically Replicated, Peer-to-Peer Filing 1997
  In bcp.bib, PageGuy97 FIXME: wrong citation!!
**    Rumor, Richard G. Guy  (a user-space version of Ficus)


@article{PageGuy97correct,
  author    = {Thomas W. Page Jr. and
               Richard G. Guy and
               John S. Heidemann and
               David Ratner and
               Peter L. Reiher and
               Ashish Goel and
               Geoffrey H. Kuenning and
               Gerald J. Popek},
  title     = {Perspectives on Optimistically Replicated, Peer-to-Peer
               Filing.},
  journal   = {Softw., Pract. Exper.},
  volume    = {28},
  number    = {2},
  year      = {1998},
  pages     = {155-180},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

Also, cite{Rumor} from bcp.bib is the Rumor manual.

@inproceedings{guy98rumor,
author = "Richard G. Guy and Peter L. Reiher and David Ratner 
          and Michial Gunter and Wilkie Ma and Gerald J. Popek",
booktitle = "Proceedings of the {ER} Workshop on Mobile Data Access",
title = "Rumor: Mobile Data Access through optimistic peer-to-peer replication",
pages = "254--265",
year = 1998,
citeseerurl = "citeseer.nj.nec.com/guy98rumor.html"
}


_____________________________________________________________________________________
*
* BENGAL
**    Bengal Database Replication System, Ekenstam, Matheny, Reiher and Popek

@article{ekenstam01bengal,
author = {Todd Ekenstam and Charles Matheny and Peter L. Reiher
and Gerald J. Popek},
title = {The {B}engal Database Replication System},
journal = {Distributed and Parallel Databases},
volume = 9,
number = 3,
year = 2001,
pages = {187--210},
citeseerurl = "citeseer.nj.nec.com/ekenstam01bengal.html"
}

Bengal Database Replication System uses the Ficus/Rumor
algorithms, is loosely coupled (but is layered on top of
OLE/COM), non-generic (only works for databases), and doesn't
support heterogeneous databases (implemented for a variety of
commercial databases, but reconciliation occurs between multiple
replicas of the same database). Primitive objects are records.
Operation-based to avoid scanning entire database, but doesn't
use operation-log to avoid conflicts (operation-based is strictly
to improve performance of update detection).  Uses version vector
to resolve conflicts.
in case of
conflict records are copied to new "version", and separate
"conflict resolver" is launched.  Can often be manual resolver.

*
*
* ###################################################################################
  ###################################################################################
  ##                                                                               ##
* ##                OPTIMISTIC REPLICATION AND DATA SYNCHRONIZATION                ##
  ##                                                                               ##
  ###################################################################################
* ###################################################################################

_____________________________________________________________________________________
_____________________________________________________________________________________

*
* SEMINAL PAPERS

_____________________________________________________________________________________
**  #  Munson and Dewan, A Flexible Object Merging Framework
@inproceedings{ munson94flexible,
    author = {Jonathan P. Munson and Prasun Dewan},
    title = "A Flexible Object Merging Framework",
    booktitle = {ACM Conference on Computer Supported Cooperative Work (CSCW), Chapel Hill, North Carolina},
    pages = "231--242",
    year = "1994",
    citeseerurl = "citeseer.nj.nec.com/munson94flexible.html",
    mbgreencomment = {I have not read this as carefully as I
                       should yet; it is extremely useful and
informative about operational
transformation.  It is not clear there is anything here that is
not subsumed by later papers in the area, but the explanation and
overview is much more convincing and clear than the papers we've
read by Molli et. al.
However, although there seems to not be much new here, it is an
important citation because it explicitly relates UNDO in
groupware to merging in optimistic replication.}
	}

I haven't read it all yet, but it seems quite intelligent.  The first few
pages give an excellent discussion of "object merging" issues and some nice
use case examples.  -- BCP

_____________________________________________________________________________________

*
* SURVEYS

_____________________________________________________________________________________
** #   Saito and Shapiro "Replication: Optimistic Approaches"
Y. Saito and M. Shapiro, Replication: Optimistic
Approaches. Technical Report HPL-2002-33, February 2002.

@techreport{saito:hp02,
author = {Yasushi Saito and Marc Shapiro},
title = {Replication: Optimistic Approaches},
institution = {HP Laboratories Palo Alto},
type = {Technical Report},
number = {HPL-2002-33},
month = {Feb. 8},
year = 2002,
url = "http://www.hpl.hp.com/techreports/2002/HPL-2002-33.html"
}

@Article{saito:survey,
  author = 	 {Yasushi Saito and Marc Shapiro},
  title = 	 {Optimistic Replication},
  journal = 	 {Computing Surveys},
  year = 	 2005,
  volume =	 37,
  number =	 1,
  pages =	 {42--81},
  month =	 mar,
}

_____________________________________________________________________________________
**     Shapiro, A Terse Bibliography on Optimistic Replication and Reconciliation

  http://www.cs.unibo.it/ersads/tutorials/shapiro-biblio.html

Useful survey of a large swath of literature circa 2001.

Shapiro uses the word "Reconciliation" to describe what happens when two
optimistically replicated hosts meet and exchange updates.

A good place to start a search for relevant documents.

We should go through this one more time to find (and note here) other papers
that we want to read.

_____________________________________________________________________________________
_____________________________________________________________________________________

_____________________________________________________________________________________
_____________________________________________________________________________________

*
*  SYNCHRONIZERS FOR SPECIALIZED DOMAINS

_____________________________________________________________________________________
**    Horwitz et al, Integrating noninterfering versions of programs

@article{Horwitz89,
 author = {Susan Horwitz and Jan Prins and Thomas Reps},
 title = {Integrating noninterfering versions of programs},
 journal = toplas,
 volume = {11},
 number = {3},
 year = {1989},
 issn = {0164-0925},
 pages = {345--387},
 doi = {http://doi.acm.org/10.1145/65979.65980},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }
 
__
**    Hunt and Tichy, Extensible language-aware merging

Hunt, J.J.   Tichy, W.F.   
Forschungszentrum Informatik, Karlsruhe;

This paper appears in: Software Maintenance, 2002. Proceedings. International Conference on
Publication Date: 2002
On page(s): 511- 520
ISSN: 1063-6773 
ISBN: 0-7695-1819-2
INSPEC Accession Number: 7503829
Digital Object Identifier: 10.1109/ICSM.2002.1167812
Posted online: 2003-01-29 10:12:54.0

Abstract
Parallel development has become standard practice in software development and maintenance. Though almost every revision control and configuration management system provides some form of merging for combining changes made in parallel, these mechanisms often yield unsatisfactory results. The authors present a new merging algorithm, that uses a fast differencing algorithm and renaming analysis to provide better merge results. The system is language aware, but not language dependent and does not require a special editor so it can be easily integrated in current development environments.

__
**    Mens, A State-of-the-Art Survey on Software Merging

@article{DBLP:journals/tse/Mens02,
  author    = {Tom Mens},
  title     = {A State-of-the-Art Survey on Software Merging},
  journal   = {IEEE Trans. Software Eng.},
  volume    = {28},
  number    = {5},
  year      = {2002},
  pages     = {449-462},
  ee        = {http://www.computer.org:80/tse/ts2002/e0449abs.htm},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

_____________________________________________________________________________________
_____________________________________________________________________________________

*
*  3-WAY MERGING

__
**   Shen and Sun, A complete textual merging algorithm for software configuration management systems






BCP: This looks like it might be interesting
Haifeng Shen   Chengzheng Sun   
Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore;

This paper appears in: Computer Software and Applications Conference,
2004. COMPSAC 2004. Proceedings of the 28th Annual International 
Publication Date: 28-30 Sept. 2004
On page(s): 293- 298 vol.1
ISSN: 0730-3157 
ISBN: 0-7695-2209-2
INSPEC Accession Number: 8303550
Digital Object Identifier: 10.1109/CMPSAC.2004.1342846
Posted online: 2004-10-18 08:49:33.0

Abstract:
Software configuration management (SCM) systems are very important for
coordinating group efforts in developing large and complex software
systems. The ability to support concurrent software development is the key
to deliver high quality software with low time-to-market, where merging is
the core enabling technique. Textual merging is the primary and the only
successful merging function available in today's SCM systems. However none
of them supports complete textual merging, which is not only very useful
itself but also the foundation for syntactic and semantic textual
merging. We propose a novel operation-based textual merging algorithm, which
has the capability of supporting complete textual merging while still
preserving the intentions of individual editing operations. 


__
**     La Fontaine and Whitaker, A Generalized Grammar for Three-way XML Synchronization

@inproceedings{LaFontaine05,
title = {A Generalized Grammar for Three-way XML Synchronization},
author = {Robin La Fontaine and Nigel Whitaker},
year = 2005,
booktitle = "XML '05, Atlanta, Georgia",
}

BCP: The (somewhat implausible, IMO) premise of this paper is that,
depending on the application domain, there may be many reasonable ways to
merge multiple documents (e.g., accept deletions from A as long as they are
also deleted from B but not C).  The paper proposes a way of formalizing a
large class of such rulesets.

__
**     La Fontaine, Merging XML files: a new approach providing intelligent merge of XML data sets

"Merging XML files: a new approach providing intelligent merge of XML data sets". This paper describes both 2-way merging of XML files and 3-way merging when two files that are variations of a single base file need to be merged, Presented at XML Europe 2002, Barcelona, May 2002. Paper: PDF.

BCP: Describes the DeltaXML algorithm.  Couldn't make out exactly how he
deals with list-structured data, but it does not seem very sophisticated in
this respect.

_____________________________________________________________________________________
**    Lindholm, Three-way Merge as a Reconciliation Engine for Mobile Data

@InProceedings{lindholm:mobide03,
author = {Tancred Lindholm},
title = {{XML} Three-way Merge as a Reconciliation Engine for Mobile Data},
booktitle = {ACM Workshop on Data Engineering for Wireless and Mobile Access (MobiDE), San Diego, California},
month = sep,
pages = "93--97",
year = 2003,
}

_____________________________________________________________________________________
**    Lindholm, A three-way merge for XML documents

@inproceedings{Lindholm04,
 author = {Tancred Lindholm},
 title = {A three-way merge for XML documents},
 booktitle = {DocEng '04: Proceedings of the 2004 ACM symposium on Document engineering},
 year = {2004},
 isbn = {1-58113-938-1},
 pages = {1--10},
 location = {Milwaukee, Wisconsin, USA},
 doi = {http://doi.acm.org/10.1145/1030397.1030399},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

_____________________________________________________________________________________
**    Stallman et al, diffutils sources and manual

@misc{diffutils,
author = "Richard Stallman et al",
title = "GNU {\tt diffutils}, version 2.8.1",
year = "2002",
note = "Available from gnu.org"
}

@misc{diffutilsman,
author = "Stallman, Richard and others",
title = "Comparing and Merging Files",
year = "2002",
note = "Manual for GNU {\tt diffutils}; available at gnu.org"
}

@misc{diff3,
author = "Randall Smith",
title = "{GNU} {\tt diff3}",
year = "1988",
note = "Version 2.8.1, April 2002; distributed with GNU {\tt diffutils}
package" 
}

@book{MacKenzieEggertStallman03,
title = "Comparing and Merging Files with GNU diff and patch",
author = {David MacKenzie and Paul Eggert and Richard Stallman},
publisher = "Network Theory Ltd.",
year = 2003,
note = "Printed version of GNU {\tt diffutils} manual",
}

__
**   Cederqvist, Version Management with {CVS}

@Manual{cvs-man,
  author =	"Per Cederqvist",
  title =	"Version Management with {CVS}",
  organization = "Signum Support AB",
  year = 	"1993",
  month =	nov,
  address =	"Box 2044, S-580 02 Linkoping, Sweden",
  URL =  	"http://www.loria.fr/~molli/cvs/cvs-0.9/cvs_toc.html#SEC3",
  keywords =	":cvs:scm:",
}

__
**   Collins-Sussman, The {Subversion Project}: Building a Better {CVS}

@Article{Collins-Sussman:2002:SPB,
  author =	"Ben Collins-Sussman",
  title =	"The {Subversion Project}: Building a Better {CVS}",
  journal =	"Linux Journal",
  volume =	"94",
  pages =	"80--81, 83, 85",
  month =	feb,
  year = 	"2002",
  CODEN =	"LIJOFX",
  ISSN = 	"1075-3583",
  bibdate =	"Fri Feb 8 16:59:02 MST 2002",
  bibsource =	"http://noframes.linuxjournal.com/lj-issues/issue94/index.html",
  URL =  	"http://noframes.linuxjournal.com/lj-issues/issue94/article.php?sid=4768",
  abstract =	"A kinder, gentler versioning system.",
}

__
**    Miller and Myers, A File Comparison Program

@article{DBLP:journals/spe/MillerM85,
  author    = {Webb Miller and
               Eugene W. Myers},
  title     = {A File Comparison Program},
  journal   = {Softw., Pract. Exper.},
  volume    = {15},
  number    = {11},
  year      = {1985},
  pages     = {1025-1040},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

__
**    Myers, An O(ND) Difference Algorithm and Its Variations

@article{DBLP:journals/algorithmica/Meyers86,
  author    = {Eugene W. Myers},
  title     = {An O(ND) Difference Algorithm and Its Variations},
  journal   = {Algorithmica},
  volume    = {1},
  number    = {2},
  year      = {1986},
  pages     = {251-266},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

__
**    Ukkonen, Algorithms for Approximate String Matching

@article{DBLP:journals/iandc/Ukkonen85,
  author    = {Esko Ukkonen},
  title     = {Algorithms for Approximate String Matching},
  journal   = {Information and Control},
  volume    = {64},
  number    = {1-3},
  year      = {1985},
  pages     = {100-118},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

_____________________________________________________________________________________
_____________________________________________________________________________________

*
*  OPERATION TRANSFORMATION

_____________________________________________________________________________________
** #  Molli, Oster, Skaf-Molli, Imine, Safe Generic Data Synchronizer

Pascal MOLLI, G¬érald OSTER, Hala SKAF-MOLLI, and Abdessamad
IMINE. Safe Generic Data Synchronizer. Rapport de recherche, May
2003. http://www.loria.fr/~molli/rech/esec03.
@techreport{molli:tr03,
	author={Pascal Molli and Gerald Oster and Hala Skaf-Molli
	        and Abdessamad Imine},
title = {Safe Generic Data Synchronizer},
	url = {http://www.loria.fr/~molli/rech/esec03},
	year = 2003,
	month = may,
	type = {Rapport {de} recherche},
	institution = "LORIA France"}


(BCP has a more up to date version of this one that Imine sent.)

This is a very important point of comparison for us (since it is recent,
since it is at least attempting to be formal, since it claims to be
"generic" in a similar sense to us, and since it explicitly criticizes
Unison).  However, it is rather unsatisfying.  I (BCP) read it carefully and
sent the authors a long list of comments, but they have not responded yet.

_____________________________________________________________________________________
**    Sun et al, Achieving convergence, causality preservation, etc....

Sun, Jia, Zhang, Yang, and Chen, Achieving convergence, causality
preservation, and intention preservation in real-time cooperative editing
systems. ACM Transactions on Computer-Human Interaction (TOCHI). Volume 5,
Issue 1 (March 1998).

(BCP has a copy.)

I (bcp) downloaded this article hoping to find a definition of "intention
preservation," a term that has puzzled me in some other papers.  Indeed,
this paper gives a definition; but I fail to see how it is useful.  To wit:

  Definition 3 (Intention of an Operation). The intention of an operation O is
  the execution effect which can be achieved by applying O on the document
  state from which O was generated.

I.e., the intention of an operation is the effect of that operation _on the
state in which it was originally generated_.  How this could possibly be
"preserved" in the presence of concurrent updates escapes me
completely.

I stopped reading carefully after this point.

(MBG: it is explained more clearly in Sun & Ellis from CSCW98
(with a slightly modified definition that isolates "independent"
(i.e. causally unrelated) operations from each other). I now
understand how it makes sense in the real-time collaboration
context, because a key point is what is exposed to the user
interface (they assume that conflicts among concurrent operations
can be resolved before the user "sees" the conflict).  Therefore,
they make sure that the state of the document is identical on all
sites before applying O.  So to the user who initiated O it
appears as if someone else succeeded in executing O' first, and O
behaves "correctly" and identically on all replicas --- although
it may not do what the user *wanted*, it behaves "as expected" on
the document.  And the user can immediately fix it up.

However, in disconnected operation you cannot hide the
intermediate state, and you can't expect the user to resolve the
conflict immediately, so this notion seems misplaced.)


_____________________________________________________________________________________
**    Palmer and Cormack, Operation transforms for a distributed shared spreadsheet

CSCW, 1998

http://doi.acm.org/10.1145/289444.289474

Very cool paper.  Really shows what operation transformations can be
used for, and how to set them up carefully.  --bcp

@inproceedings{palmer:cscw98,
author = {C. Palmer and G. V. Cormack},
title = {Operation transforms for a distributed shared spreadsheet},
month = nov,
pages = {69--78},
year = 1998,
booktitle = cscw98,
}

_____________________________________________________________________________________
**    Imine, Molli, et al, Proving correctness of transformation functions in real-time groupware

Abdessamad Imine, Pascal Molli, G¬érald Oster, and Micha¬ël
Rusinowitch. Proving correctness of transformation functions in
real-time groupware. In Proceedings of the 8th European Conference on
Computer-Supported Cooperative Work, Helsinki, Finland, September
2003. ACM. http://www.loria.fr/~molli/rech/ecscw03.

@inproceedings{imine:ecscw03,
	author = {Abdessamad Imine and Pascal Molli and Gerald
Oster and Michael Rusinowitch},
title = {Proving correctness of transformation functions in
real-time groupware},
	booktitle = cscw03,
	month = sep,
	year = 2003,
	url = {http://www.loria.fr/~molli/rech/ecscw03}}

_____________________________________________________________________________________
**    Molli et al, Using the transformational approach to build a safe and generic data synchronizer

@inproceedings{molli:group03,
author = {Pascal Molli and Gerald Oster and Hala Skaf-Molli and Abdessamad Imine},
title = {Using the transformational approach to build a safe and generic data synchronizer},
booktitle = {{ACM} {SIGGROUP} {C}onference on {S}upporting {G}roup {W}ork ({GROUP}), Sanibel Island, Florida},
month = nov,
pages = "212--220",
year = 2003,
url = {http://www.loria.fr/~molli/rech/group03/main.pdf}
}

_____________________________________________________________________________________
**    Cormack, "A Calculus for Concurrent Update"
      PODC 1995

Gordon V. Cormack: A Calculus for Concurrent Update
(Abstract). PODC 1995: 269
@inproceedings{cormack:podc95,
author = {Gordon V. Cormack},
title = {Brief Abstract: A Calculus for Concurrent Update},
pages = 269,
month = aug,
year = 1995,
booktitle = {Symposium on Principles of Distributed Computing (PODC), Ottawa, Canada}
}

_____________________________________________________________________________________
**    Chengzheng Sun and Clarence Ellis, Operational transform in real-time group editors

Operational transform in real-time group editors: Issues, algorithms, and
achievements.  CSCW, 1998.
@Inproceedings{sun:cscw98,
author = {Chengzheng Sun and Clarence (Skip) Ellis},
title = {Operational transform in real-time group editors:
Issues, algorithms, and achievements},
year = 1998,
booktitle = cscw98,
pages = {59--68},
mbgreencomment = {Sings the praises of operational transformation in a
collaborative real-time editing setting.  Covers the GROVE,
REDUCE, and Jupiter systems.  Covers dOPT, adOPTed, GO, GOT, and
GOTO algorithms for consistency maintenance and "intention
preservation".

Proceeds by looking at systems that maintain particular
properties.  They start with convergence and causality, then add
intention preservation, and then add (unnamed) transformation
properties which ensure that you can both preserve intention and
converge (although this limits the domain of applicability).

"The term {\em intention} as defined ... and used in this paper
has only captured a small piece of the much richer meaning of
intention from the human user's perspective."

One of the better explanations of Operational Transformation,
although I still don't find it very convincing.}
}

_____________________________________________________________________________________
**  # Clarence A. Ellis and Simon J. Gibbs, "Concurrency Control in groupware
systems", SIGMOD '89, pp. 399-407

A much cited paper.  Another case a'la Molli, where convergence
is valued over "intention".  Each site is guaranteed to see the
same order of operations, no operations are aborted, but some
operations may nullify others.  The merge of two schedules is
priority-based, and the priority is based on the site ID and the
target of the operation.  I need to read this, just skimmed so
far.

@Inproceedings{ellis:sigmod89,
author = {Clarence A. Ellis and Simon J. Gibbs},
title = {Concurrency Control in groupware systems},
pages = {399--407},
booktitle = sigmod89,
year = 1989}

_____________________________________________________________________________________
**  # Davis, Sun, and Lu, Generalizing operational transformation to SGML

Looks very relevant to Harmony.  Also recent, so trolling for citations
should be useful.

@inproceedings{587088,
 author = {Aguido Horatio Davis and Chengzheng Sun and Junwei Lu},
 title = {Generalizing operational transformation to the standard general
 markup language},
 booktitle = {Proceedings of the 2002 ACM conference on Computer supported
 cooperative work},
 year = {2002},
 isbn = {1-58113-560-2},
 pages = {58--67},
 location = {New Orleans, Louisiana, USA},
 doi = {http://doi.acm.org/10.1145/587078.587088},
 publisher = {ACM Press},
 }

The CSCW session where this appeared was called "Group editing alorithms."
Doing some citeseeing and/or googling of this term would probably be useful!

_____________________________________________________________________________________
**  # Ignat and Morrie, Tree-based model alg. for maint. consistency in RT collaborative editing systems

http://dsonline.computer.org/collaborative/events/iwces-4/Ignat.paper.pdf

Relevant for us (trees!).  Also pretty recent and contains a number of
interesting citations.  See, in particular, citation 19, which describes the
"SOCT4 algorithm" -- apparently a popular one in the operation
transformation community.

_____________________________________________________________________________________
**    Knister, M. J. and Prakash A., "Undoing actions in collaborative
 work", CSCW, Nov. 1992
http://citeseer.nj.nec.com/cache/papers/cs/3859/

Conference paper superseded by the journal version in Transaction
on CHI, below.

_____________________________________________________________________________________
**    Atul Prakash and Michael J. Knister, "A framework for Undoing actions in
collaborative systems", CSCW, Nov. 1992

@article{ prakash94framework,
    author = "Atul Prakash and Michael J. Knister",
    title = "A framework for undoing actions in collaborative systems",
    journal = "{ACM} {T}ransactions on {C}omputer-{H}uman {I}nteraction",
    volume = "1",
    number = "4",
    pages = "295--330",
    year = "1994",
    citeseerurl = "citeseer.nj.nec.com/article/prakash94framework.html",
    mbgreencomment = {
In the end, not relevant to us.  Establishes conditions under
which users can undo their own operations in a setting where
multiple users are interleaving edits to the same object.  This
paper answers where it is easy to do, and where it is hard.
Provides "formal properties that the undo framework should
satisfy, in order for undo to work correctly in a group
environment."  Its strength is in identifying when primitive
operations have unique undo functions.  The paper by Abowd and
Dix delves more deeply into the broader question of when
"intention" is unambiguous.  See below:
}
}

_____________________________________________________________________________________
**    Gregory D. Abowd and Alan J. Dix, "Giving Undo Attention"

Interacting with Computers, 4(3):317-342, 1992.

@article{ abowd92giving,
    author = "Gregory D. Abowd and Alan J. Dix",
    title = "Giving Undo Attention",
    journal = "Interacting with Computers",
    volume = "4",
    number = "3",
    pages = "317-342",
    year = "1992",
    citeseerurl = "citeseer.nj.nec.com/abowd91giving.html",
    mbgreencomment = {Also see comments under Knister and
Prakash.  This paper
identifies when "intention" is unambiguous, and undo can work
correctly, and when "intention" is
ambiguous, in which case simple "undo" can't work correctly.
Interestingly, undo may be ambiguous even when there exists
unique undo functions for each primitive operation.  The capper
on this area of when undo is ambiguous or not is the paper by
lechtenborger:pods03, below.}
}

_____________________________________________________________________________________
**    Alain Karsenty and Michel Beaudouin-Lafon, "An Algorithm for Distributed
Groupware Applications", 13th IEEE ICDCS, pg 195-202, 1993.

Another example of using commutativity to resolve schedule
conflicts.  This is just another example that could have gone
into Shapiro & Saito, section 7.2.1. --- MBG

_____________________________________________________________________________________
**    Lomet and Tuttle, A Theory of Redo Recovery

David Lomet, Mark Tuttle
SIGMOD '03

(Just saw the title --b)

_____________________________________________________________________________________
_____________________________________________________________________________________

_____________________________________________________________________________________


_____________________________________________________________________________________
_____________________________________________________________________________________

*
* "PEER DATA MANAGEMENT" (NOT ESPECIALLY RELEVANT TO US)

No idea what this area is really about, but the name (which appears to have
some currency in the SIGMOD community) looks enticing.  We should at least
scan these papers to find out what people have said about the area and a
vision for where it's going.

_____________________________________________________________________________________
**    Bernstein, Giunchiglia, et al., Data management for peer-to-peer computing: A vision.
      WebDB 2002.

http://www.db.ucsd.edu/webdb2002/papers/15.pdf

From a quick scan, it does not appear that they have much to say about
optimistic replication.

_____________________________________________________________________________________
**    Deswani, Garcia-Molina, Yang.  Problems in data-sharing peer-to-peer systems.
      ICDT, 2003.

http://dbpubs.stanford.edu:8090/pub/2003-1

BCP: Not really relevant for us -- focuses on SEARCH and SECURITY issues,
rather than optimistic data sharing.  However, we should check out the
website of the Stanford PEERS project...

__
**  # Gribble, Halevy, Ives, Rodrig, and Suciu.  What can databases do for peer-to-peer?
      WebDB 2001.

_____________________________________________________________________________________
_____________________________________________________________________________________

*
* "DATA INTEGRATION" 
**   <see articles inline>

@article{ florescu98database,
    author = "Daniela Florescu and Alon Y. Levy and Alberto O. Mendelzon",
    title = "Database Techniques for the World-Wide Web: A Survey",
    journal = "ACM SIGMOD Record",
    volume = "27",
    number = "3",
    pages = "59-74",
    year = "1998",
    citeseerurl = "citeseer.nj.nec.com/florescu98database.html" 
}

@article{ halevy00theory,
    author = "Alon Y. Halevy",
    title = "Theory of answering queries using views",
    journal = "ACM SIGMOD Record",
    volume = "29",
    number = "4",
    pages = "40--47",
    year = "2000",
    citeseerurl = "citeseer.nj.nec.com/halevy00theory.html" 
}

@inproceedings{ abiteboul97querying,
    author = "Serge Abiteboul",
    title = "Querying Semi-Structured Data",
    booktitle = icdt97,
    pages = "1--18",
    year = "1997",
    citeseerurl = "citeseer.nj.nec.com/abiteboul97querying.html" 
}

_____________________________________________________________________________________
**    Kementsietsidis et al, Mapping Data in Peer-to-Peer Systems: Semantics and Algorithmic Issue

Anastasios Kementsietsidis, Marcelo Arenas, Renee J Miller
SIGMOD 03

(Not sure this is relevant -- just noticed the title.)

_____________________________________________________________________________________
_____________________________________________________________________________________

*
*
* ###################################################################################
  ###################################################################################
  ##                                                                               ##
* ##                             TREE TRANSDUCERS, ETC                             ##
  ##                                                                               ##
  ###################################################################################
* ###################################################################################

*
**    Milo, Suciu and Vianu. Typechecking for XML Transformers. PODS 2000

@inproceedings{ milo00typechecking,
author = "Tova Milo and Dan Suciu and Victor Vianu",
title = "Typechecking for {XML} Transformers",
booktitle = pods00,
publisher = "ACM",
pages = "11--22",
year = "2000"
}

_____________________________________________________________________________________
**    Alon, Milo, Neven, Suciu, and Viano. XML with Data Values: Typechecking Revisted.
@inproceedings{ alon01xml,
    author = "Noga Alon and Tova Milo and Frank Neven and Dan Suciu and Victor Vianu",
    title = "{XML} with Data Values: Typechecking Revisited",
    booktitle = "Symposium on Principles of Database Systems",
    year = "2001",
    citeseerurl = "citeseer.nj.nec.com/alon01xml.html" 
}

_____________________________________________________________________________________
**    Traditional regular tree transducers (article in Handbook of Formal Languages)

Rozenberg and Salomaa, Springer 1997.

_____________________________________________________________________________________
**    Tree transducer book by F\"ul\"op and Vogler

_____________________________________________________________________________________
**    "Macro Tree Transducers" (Courcelle, etc.)

_____________________________________________________________________________________
**    Maneth and Neven,  Recursive Structured Document Transformations based on XSL

DBPL 1999
http://www.wi.leidenuniv.nl/home/maneth/DBPL99.ps.gz

Frank Neven has written a *bunch* of papers that look like they might be
relevant.  See http://alpha.luc.ac.be/~lucg5503/ for more.

_____________________________________________________________________________________
**    XSL

www.w3.org/TR/WD-xsl

Maybe we can relate Focal to XSL (or one of its descendants) in some way... -B

_____________________________________________________________________________________
**    "Theory of XML Transformations: Tree Transducers", slides by Sebastian Matheth

http://www.liacs.nl/~maneth/slides/Lausanne_21Feb03_gray.pdf

We don't need to keep this in the bib file forever, but it's a useful quick
and overview and source of citations to other places.  --B

_____________________________________________________________________________________
**    Gecseg and Steinby, Tree Languages

Good, compact (but dense) handbook article on various aspects of tree
languages, recognizers, and transducers.

First chapter of the Handbook of Formal Languages, Volume 3, by Rozenberg
and Salomaa, Springer 1997.

_____________________________________________________________________________________
**    Engelfriet and Vogler, Modular Tree Transducers

   J. Engelfriet and H. Vogler, Modular Tree Transducers.  Theoretical
   Computer Science 78 (1991), 267--303.

The reference to this paper in Gecseg and Steinby's Tree Languages chapter
says:

   The {\em modular tree transducers} of [EnV91] can be defined as special
   term rewriting systems in which the rules are partitioned into {\em
   modules}.  Each module is equipped with a natural number and it can call
   modules with lower numbers.  Modular tree transducers compute precisely
   the primitive recursive functions on trees...

_____________________________________________________________________________________
**    Comon et al, Tree Automata Techniques and Applications

The URL here doesn't seem to work.  If anyone succeeds in finding a copy,
please update this.  (Citeseer has separate entries for each chapter, so
they can be downloaded one at a time, if nothing else.)

@unpublished{tata,
author       =   "Hubert Comon and Max Dauchet and R\'emy Gilleron
                  and Florent Jacquemard and Denis Lugiez and
                  Sophie Tison and Marc Tommasi",
title        =   "Tree Automata Techniques and Applications",
year         =   "1999",
note         =   "Draft book; available electronically on
                  \URL{http://www.grappa.univ-lille3.fr/tata}",
}

_____________________________________________________________________________________
**    Zilio et al, A Logic You can Count On

@InProceedings{DalzilioS:POPL04,
   author    = {{Dal Zilio}, Silvano and Lugiez, Denis and Meyssonnier, Charles},
   title     = {{A Logic You Can Count On}},
   booktitle = popl04,
   month     = jan, 
   publisher = {ACM Press},
   pages     = "135--146",
   year      = 2004
}

*
*
* ###################################################################################
  ###################################################################################
  ##                                                                               ##
* ##           LINEARITY, BI-DIRECTIONAL SYNTAX (AKA NATE'S WPEII)                 ##
  ##                                                                               ##
  ###################################################################################
* ###################################################################################

*
**    Arrighi and Dowek. Linear-algebraic lambda Calculus, 2004

@ARTICLE{arrighi-2004-33,
  author = {Pablo Arrighi and Gilles Dowek},
  title = {Linear-algebraic lambda-calculus},
  journal = {TURKU CENTRE FOR COMPUTER SCIENCE GENERAL PUBLICATION},
  volume = {33},
  pages = {2004},
  url = {http://www.citebase.org/cgi-bin/citations?id=oai:arXiv.org:quant-ph/0501150},
  year = {2004}
}

** Selinger and Valiron. A Lambda Calculus for Quantum Computation with Classical Control

@inproceedings{DBLP:conf/tlca/SelingerV05,
  author    = {Peter Selinger and
               Benoit Valiron},
  title     = {A Lambda Calculus for Quantum Computation with Classical
               Control.},
  booktitle = {TLCA},
  year      = {2005},
  pages     = {354-368},
  ee        = {http://springerlink.metapress.com/openurl.asp?genre=article{\&}issn=0302-9743{\&}volume=3461{\&}spage=354},
  crossref  = {DBLP:conf/tlca/2005},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

** Abramsky. A structural appraoch to reversible computation

@article{DBLP:journals/tcs/Abramsky05,
  author    = {Samson Abramsky},
  title     = {A structural approach to reversible computation.},
  journal   = {Theor. Comput. Sci.},
  volume    = {347},
  number    = {3},
  year      = {2005},
  pages     = {441-464},
  ee        = {http://dx.doi.org/10.1016/j.tcs.2005.07.002},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

** van Tonder. A Lambda Calculus for Quantum Computation 

@ARTICLE{vantonder-2004-33,
  author = {Andre {van Tonder}},
  title = {A Lambda Calculus for Quantum Computation},
  journal = {SIAM J.COMPUT.},
  volume = {33},
  pages = {1109},
  url = {doi:10.1137/S0097539703432165},
  year = {2004}
}

** van Tonder Quantum Computation, Categorical Semantics and Linear Logic

@MISC{vantonder-2003-,
  author = {Andre {van Tonder}},
  title = {Quantum Computation, Categorical Semantics and Linear Logic},
  url = {http://www.citebase.org/cgi-bin/citations?id=oai:arXiv.org:quant-ph/0312174},
  year = {2003}
}


*
* ###################################################################################
  ###################################################################################
  ##                                                                               ##
* ##                              UNFILED CITATIONS                                ##
  ##                                                                               ##
  ###################################################################################
* ###################################################################################

@inproceedings{BatuKKM04,
title={Reconstructing Strings from Random Traces},
author={Tugkan Batu and Sampath Kannan and Sanjeev Khanna and Andrew McGregor},
booktitle={SODA},
year={2004}}

@inproceedings{BunemanKTT02,
title={Archiving scientific data},
author={Peter Buneman and Sanjeev Khanna and Keishi Tajima and Wang Chiew Tan},
booktitle = sigmod02,
pages = "1--12",
year = "2002"}

@inproceedings{ChekuriK03,
title={Edge Disjoint Paths Revisited},
author={C.~Chekuri and S.~Khanna},
booktitle = {SODA},
year="2003"}

@inproceedings{ChekuriK02,
title= {Approximation schemes for preemptive weighted flow time},
author={C. Chekuri and  S. Khanna},
booktitle = {STOC},
year="2002"}

@inproceedings{ChekuriKZ01,
title={ Algorithms for Minimizing Weighted Flow Time},
author = {C. Chekuri and S. Khanna and A. Zhu},
booktitle = {{STOC}},
year = "2001"}

@inproceedings{ChekuriGKK04,
title = {Multi-processor Scheduling to Minimize Flowtime with $\epsilon$
Resource Augmentation},
author = {C. Chekuri and A. Goel and S. Khanna and A. Kumar},
booktitle = {{STOC}},
year = {2004}}

@inproceedings{ChekuriKS04,
title = {The All-or-Nothing Multicommodity Flow Problem},
author = {C. Chekuri and S. Khanna and B. Shepherd},
booktitle = {{STOC}},
year = {2004}}

@inproceedings{ChuzhoyGHKKN04,
title={Asymmetric k-center is log*n-hard to Approximate},
author = {Julia Chuzhoy and Sudipto Guha and Eran Halperin and
Sanjeev Khanna and Guy Kortsarz and Joseph Naor},
booktitle = {{STOC}},
year = {2004}}

@inproceedings{GreenwaldK04,
title={Power-Conserving Computation of Order-Statistics over Sensor
Networks},
author={Michael Greenwald and Sanjeev Khanna},
booktitle = pods04,
year = {2004}}

@inproceedings{IslerKK04,
title={ Randomized Pursuit-Evasion with Limited Visibility},
author = {Volkan Isler and Sampath Kannan and Sanjeev Khanna},
booktitle ={{SODA}},
year = {2004}}

@inproceedings{KannanK03,
title = {Selection with monotone comparison cost},
author = {Sampath Kannan and Sanjeev Khanna},
booktitle = {{SODA}},
pages = "10--17",
year = {2003}}

@inproceedings{KhannaNR02,
title={Control Message Aggregation in Group
Communication Protocols},
author = {Sanjeev Khanna and Joseph Naor and Danny Raz},
booktitle = {{ICALP}},
pages = "135--146",
year = "2002"}


@Misc{XQuerySemantics,
  author =	 {Peter Fankhauser and Mary Fern\'{a}ndez and Ashok
                  Malhotra and Michael Rys and J{\'e}r{\^o}me
                  Sim{\'e}on and Philip Wadler},
  title =	 {{XQuery 1.0 Formal Semantics}},
  howpublished = {\URL{http://www.w3.org/TR/query-semantics/}},
  OPTmonth =	 {},
  year =	 {2001},
  OPTnote =	 {},
  OPTannote =	 {}
}

@inproceedings{hofmann94positive,
author =          "Martin Hofmann and Benjamin Pierce",
title =           "Positive Subtyping",
booktitle =       "POPL'95",
year =            "1995",
}

@Article{Chawathe96xdiff,
author =          {Sudarshan S. Chawathe and A. Rajamaran and H. Garcia-Molina and Jennifer Widom},
title =           {Change detection in hierarchically structured information},
  journal =      {ACM SIGMOD Record},
  year =         {1996},
  volume =       {25},
  number =       {2},
  pages =        {493--504},
  month =        jun,
  note =         {},
}

@Misc{RFC2425,
  author =       "T. Howes and M. Smith and F. Dawson",
  title =        "{RFC 2425}: {A MIME} Content-Type for Directory
                 Information",
  month =        sep,
  year =         "1998",
  URL =          "ftp://ftp.internic.net/rfc/rfc2425.txt",
  acknowledgement = ack-nhfb,
  format =       "TXT=64478 bytes",
  online =       "yes",
  status =       "PROPOSED STANDARD",
}

@Misc{RFC2426,
  author =       "F. Dawson and T. Howes",
  title =        "{RFC 2426}: {vCard} {MIME} Directory Profile",
  month =        sep,
  year =         "1998",
  URL =          "ftp://ftp.internic.net/rfc/rfc2426.txt,
                 ftp://ftp.math.utah.edu/pub/rfc/rfc2426.txt",
  acknowledgement = ack-nhfb,
  format =       "TXT=74646 bytes",
  online =       "yes",
  status =       "PROPOSED STANDARD",
}

@article{HuetZipperJFP,
 author = {G. Huet},
 title = {The Zipper},
 journal = jfp,
 volume = {7},
 number = {5},
 year = {1997},
 issn = {0956-7968},
 pages = {549--554},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
 }

@InProceedings{xsugar-old,
  author =       {Claus Brabrand and Anders M\o{}ller and Michael I. Schwartzbach},
  title =        {Dual Syntax for {XML} Languages},
  booktitle =    dbpl05,
  volume =       3774,
  year =         2005,
  month =        aug,
  series =       lncs,
  publisher =    springer,
  pages =        "27--41",
}

@Article{xsugar,
  author =       {Claus Brabrand and Anders M\o{}ller and Michael I. Schwartzbach},
  title =        {Dual Syntax for {XML} Languages},
  journal =      {Information Systems},
  year =         {2007},
  publisher =    {Elsevier},
  note         = "To appear. Extended abstract in {\em Database Programming Languages (DBPL)} 2005",
}

@inproceedings{BunemanKhannaTan01,
  author    = {Peter Buneman and
               Sanjeev Khanna and
               Wang Chiew Tan},
  title     = {Why and Where: A Characterization of Data Provenance},
  booktitle = {International Conference on Database Theory (ICDT), London, UK},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {1973},
  year      = {2001},
  pages     = {316--330},
}

@article{CuiWidom03,
  author    = {Yingwei Cui and
               Jennifer Widom},
  title     = {Lineage tracing for general data warehouse transformations.},
  journal   = {VLDB Journal},
  volume    = {12},
  number    = {1},
  year      = {2003},
  pages     = {41--58},
}

@phdthesis{CuiThesis,
 author = {Yingwei Cui},
 title = {Tracing Lineage in Data Warehouses},
 year = {2001},
 school = {Stanford University},  
 }

@InProceedings{ProvenanceSemiRings07,
  author =       {Todd J. Green and Gregory Karvounarakis and Val Tannen},
  title =        {Provenance Semi-Rings},
  booktitle =    pods07, 
  year =         {2007},
  note =         {To appear.},
}


@inproceedings{WoodruffStonebraker97,
  author    = {Allison Woodruff and
               Michael Stonebraker},
  title     = {Supporting Fine-grained Data Lineage in a Database Visualization
               Environment},
  booktitle = {International Conference on Database Theory (ICDT), Birmingham, UK},
  year      = {1997},
  pages     = {91--102},
}

@inproceedings{EnnalsGay07,
  author = {Robert Ennals and David Gay},
  title = { Multi-Language Synchronization},
  booktitle = {European Symposium on Programming (ESOP), Braga, Portugal},
  year = 2007,
  pages = {475--489},
  publisher = springer,
  series = lncs,
  volume = 4421,
}

@inproceedings{biarrows,
  author = {Alimarine, Artem and Smetsers, Sjaak and van Weelden, Arjen
            and van Eekelen, Marko and Plasmeijer, Rinus},
  title = {There and Back Again: {A}rrows for Invertible Programming},
  booktitle = {{ACM} {SIGPLAN} {W}orkshop on {H}askell},
  pages = {86--97},
  year = {2005}
}

@book{BerstelBook,
  author = { Jean Berstel and Dominique Perrin and Christophe Reutenauer },
  title = { Codes and Automata },
  year = 2005,
  note = { Manuscript available from \URL{http://www-igm.univ-mlv.fr/~berstel/LivreCodes/}}
}

@article{KennedyPickler04,
 author = {Andrew J. Kennedy},
 title = {Functional Pearl: Pickler Combinators},
 journal = jfp, 
 volume = {14},
 number = {6},
 year = {2004},
 pages = {727--739},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
}

@article{BentonEmbedded05,
 author = {Nick Benton},
 title = {Embedded interpreters},
 journal = jfp, 
 volume = {15},
 number = {4},
 year = {2005},
 pages = {503--542},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
}

@inproceedings{RamseyEmbedding03,
 author = {Norman Ramsey},
 title = {Embedding an interpreted language using higher-order functions and types},
 booktitle = {{ACM} {SIGPLAN} {W}orkshop on {I}nterpreters, {V}irtual {M}achines and {E}mulators ({IVME}), {S}an {D}iego, {CA}},
 year = {2003},
 pages = {6--14},
}     

@inproceedings{bixid,
  author = {Shinya Kawanaka and Haruo Hosoya},
  title = {biXid: a bidirectional transformation language for {XML}},
  booktitle = icfp06,  
  year = {2006},
  pages = {201--214},
}

@inproceedings{pads,
  author    = {Kathleen Fisher and
               Robert Gruber},
  title     = {{PADS}: a domain-specific language for processing ad hoc data},
  booktitle = {{ACM} {SIGPLAN} {C}onference on {P}rogramming
               {L}anguage {D}esign and {I}mplementation ({PLDI}), {Chicago, IL}},
  year      = {2005},
  pages     = {295--304},
}

@inproceedings{Tabuchi02,
  author    = {Naoshi Tabuchi and
               Eijiro Sumii and
               Akinori Yonezawa},
  title     = {Regular Expression Types for Strings in a Text Processing
               Language},
  booktitle = {Workshop on Types in Programming (TIP), Dagstuhl, Germany},
  series   = {Electronic Notes in Theoretical Computer Science},
  volume    = {75},
  year      = {2002},
  mon       = jul,
  pages     = {95--113},
}

@article{RabinScott59,
  author = { M. O. Rabin and D. Scott},
  title =  {Finite automata and their decision problems},
  journal = {IBM Journal of Research and Development},
  volume = 3,
  number = 2,
  year = 1959,
  pages = {114--125},
}

@book{RocheSchabes96,
  title =    {Finite-State Language Processing},
  publisher =    {MIT Press},
  year =         1996,
  editor =       {Emmanuel Roche and Yves Schabes},
}

@article{Brzozowski64,
  author = {Janusz A. Brzozowski},
  title = {Derivatives of regular expressions},
  journal = {Journal of the ACM},
  volume = 11,
  number = 4,
  pages = {481--494},
  year = 1964
}

@inproceedings{Boomerang07-dup,
author =       {Aaron Bohannon and J. Nathan Foster and Benjamin C. Pierce and Alexandre Pilkiewicz and Alan Schmitt},
title =        {Boomerang: Resourceful Lenses for String Data},
booktitle    =   popl08,
year =         {2008},
month =        jan,
bcp          =   yes,
keys         =   "harmony",
plclub       =   yes,
short        =   "http://www.cis.upenn.edu/~bcpierce/papers/boomerang.pdf",
tr        =   "http://www.cis.upenn.edu/~bcpierce/papers/boomerang-tr.pdf",
}

@inproceedings{SecViews09,
author =       { J. Nathan Foster and Benjamin C. Pierce and Steve Zdancewic},
title =        {Updatable Security Views},
booktitle    =  {Computer Security Foundations Symposium},
year =         {2009},
bcp          =   yes,
keys         =   "harmony",
plclub       =   yes,
}

@inproceedings{QuotientLenses08-dup,
author =       {J. Nathan Foster and Alexandre Pilkiewicz and Benjamin C. Pierce},
title =        {Quotient Lenses},
booktitle =    icfp08,
year =         2008,
month =        sep,
conf           =   "http://www.cis.upenn.edu/~jnfoster/papers/quotient-lenses.pdf",
}

@misc            {MatchingLenses09,
author       =   {Davi M. J. Barbosa and
                  Julien Cretin and
                  Nate Foster and
                  Michael Greenberg and
                  Benjamin C. Pierce},
title        =   {Matching Lenses: Alignment and View Update},
year         =   2009,
note         =   "Submitted to PODS 2010",
}

@inproceedings{Stevens07-dup,
  author    = {Perdita Stevens},
  title     = {Bidirectional Model Transformations in {QVT}:
               {S}emantic Issues and Open Questions},
  booktitle = {International Conference on Model Driven Engineering
Languages and Systems (MoDELS),
               Nashville, TN},
  year      = {2007},
  pages     = {1--15},
  publisher = springer,
  series    = lncs,
  volume    = {4735},
  isbn      = {978-3-540-75208-0},
}

@article{stevens2008lbm,
  title={{A landscape of bidirectional model transformations}},
  author={Stevens, Perdita},
  journal={Postproceedings of GTTSE},
  volume={7},
  year={2008}
}

@inproceedings{DBLP:conf/models/Diskin08,
  author    = {Zinovy Diskin},
  title     = {Algebraic Models for Bidirectional Model Synchronization},
  booktitle = {MoDELS},
  year      = {2008},
  pages     = {21-36},
  ee        = {http://dx.doi.org/10.1007/978-3-540-87875-9_2},
  crossref  = {DBLP:conf/models/2008},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
@proceedings{DBLP:conf/models/2008,
  editor    = {Krzysztof Czarnecki and
               Ileana Ober and
               Jean-Michel Bruel and
               Axel Uhl and
               Markus V{\"o}lter},
  title     = {Model Driven Engineering Languages and Systems, 11th International
               Conference, MoDELS 2008, Toulouse, France, September 28
               - October 3, 2008. Proceedings},
  booktitle = {MoDELS},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {5301},
  year      = {2008},
  isbn      = {978-3-540-87874-2},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@conference{stevens2008tat,
  title={{Towards an algebraic theory of bidirectional transformations}},
  author={Stevens, Perdita},
  booktitle={Graph Transformations: 4th International Conference, ICGT 2008, Leicester, United Kingdom, September 7-13, 2008, Proceedings},
  pages={1},
  year={2008},
  organization={Springer}
}

@article{HuHOSC07,
  author = {Zhenjiang Hu and Shin-Cheng Mu and Masato Takeichi},
  title = {A Programmable Editor for Developing Structured Documents based on Bidirectional Transformations}, 
  journal = hosc,
  publisher = springer,
  year = 2007,
  note = { To appear. Extended abstract in PEPM'04. },
}

@article{HuJSSST06,
  author = {Shin-Cheng Mu and Zhenjiang Hu and Masato Takeichi}, 
  title = {Bidirectionalizing Tree Transformation Languages: A Case Study}, 
  journal = {JSSST Computer Software}, 
  volume = 23,
  number = 2, 
  pages = {129--141},
  year = 2006,
}


@inproceedings{HuXQuery08,
 author = {Dongxi Liu and Zhenjiang Hu and Masato Takeichi},
 title = {Bidirectional interpretation of XQuery},
 booktitle = {ACM SIGPLAN Symposium on Partial Evaluation and Semantics-based Program Manipulation (PEPM), Nice, France},
 year = {2007},
 mon = jan,
 pages = {21--30},
 address = {New York, NY, USA},
 }

@article{Blattner77,
  author    = {Meera Blattner},
  title     = {Single-Valued a-Transducers},
  journal   = jcss,
  volume    = {15},
  number    = {3},
  year      = {1977},
  pages     = {310--327},
}

@article{UniProt,
  author = {Bairoch, Amos   and Apweiler, Rolf   and Wu, Cathy  H.  and Barker, Winona  C.  and Boeckmann, Brigitte   and Ferro, Serenella   and Gasteiger, Elisabeth   and Huang, Hongzhan   and Lopez, Rodrigo   and Magrane, Michele   and Martin, Maria  J.  and Natale, Darren  A.  and O'Donovan, Claire   and Redaschi, Nicole   and Lai},
  journal = {Nucleic Acids Research},
  month = jan,
  number = {Database issue},
  pages = {D154--9},
  title = {The {U}niversal {P}rotein {R}esource ({U}ni{P}rot).},
  volume = {33},
  year = {2005}
}

@misc{Greenberg2007,
 AUTHOR = {Michael Greenberg and Shriram Krishnamurthi},
 TITLE = {{Declarative Composable Views}},
 YEAR = 2007,
 NOTE = {Undergraduate Honors Thesis. Department of Computer
Science, Brown University}}

@inproceedings{HuModels07,
 author = {Yingfei Xiong and Dongxi Liu and Zhenjiang Hu and Haiyan Zhao and Masato Takeichi and Hong Mei},
 title = {Towards automatic model synchronization from model transformations},
 booktitle = {IEEE/ACM International Conference on Automated Software Engineering (ASE), Atlanta, GA},
 year = {2007},
 pages = {164--173},
 }

@inproceedings{Evers04,
  author    = {Sander Evers and
               Peter Achten and
               Rinus Plasmeijer},
  title     = {Disjoint forms in graphical user interfaces},
  booktitle = {Trends in Functional Programming},
  pages     = {113--128},
  publisher = {Intellect},
  volume    = {5},
  year      = {2006},
  isbn      = {1-84150-144-1},
}

@article{Cunha06,
  title={{Type-safe two-level data transformation}},
  author={Cunha, A. and Oliveira, J.N. and Visser, J.},
  journal={European Symposium on Formal Methods},
  publisher = springer,
  volume={4085},
  pages={284--299},
}

@InProceedings{Berdaguer07,
  author = 	 {Pablo Berdaguer and Alcino Cunha and Hugo Pacheco and Joost Visser},
  title = 	 {Coupled Schema Transformation and Data Conversion For {XML} and {SQL}},
  booktitle =	 {International Symposium on Practical Aspects of Declarative Languages (PADL), Nice France},
  pages =	 {290--304},
  year =	 {2007},
  volume =	 {4354},
  series =       lncs,
  publisher =    springer,
}

@misc{Eger05,
 author = {David T. Eger},
  title = {Bit Level Types},
  mon = mar,
  year = 2005,
  note = {Unpublished manuscript. Available from \url{http://www.yak.net/random/blt/blt-drafts/03/blt.pdf}}
}

@article{Ramsey03,
  title={{Embedding an interpreted language using higher-order functions and types}},
  author={Norman Ramsey},
  journal={Workshop on Interpreters, Virtual Machines and Emulators},
  pages={6--14},
  year={2003},
}

@article{Clio01,
  title={The Clio Project: Managing Heterogeneity},
  author={Miller, R.J. and Hern{\'a}ndez, M.A. and Haas, L.M. and Yan, L. and Ho, C.T.H. and Fagin, R. and Popa, L.},
  journal={ACM SIGMOD Record},
  volume={30},
  number={1},
  pages={78--83},
  year={2001},
}

@misc{TearlineWiki,
  key = {Tearline},
  title = {Tearline Wiki: Information collaboration across security domains},
  year = 2008,
  note = {White paper; available from \URL{http://www.virtualacquisitionshowcase.com/docs/2008/Galois-Brief.pdf}}
}

@article{mohri2004wfs,
 title={Weighted Finite-State Transducer Algorithms: An Overview},
 author={Mehryar Mohri},
 journal={Studies In Fuzziness and Soft Computing},
 volume={148},
 pages={551--564},
 year={2004},
 publisher={Physica-Verlag}
}


@INPROCEEDINGS{Shivers05BUBS,
    author = {Olin Shivers and Mitchell W},
    title = {Bottom-up $\beta$-reduction: Uplinks and $\lambda$-DAGs},
    booktitle = {Proceedings of the 14th European Symposium on Programming (ESOP 2005), number 3444 in LNCS},
    year = {2005},
    pages = {217--232}
}

@article{Stoica02,
 author = {Andrei Stoica and Csilla Farkas},
 title = {Ontology guided XML security engine},
 journal = {J. Intell. Inf. Syst.},
 volume = {23},
 number = {3},
 year = {2004},
 issn = {0925-9902},
 pages = {209--223},
 doi = {http://dx.doi.org/10.1023/B:JIIS.0000047392.50246.77},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 }

@inproceedings{DBLP:conf/sigmod/FanCG04,
  author    = {Wenfei Fan and
               Chee Yong Chan and
               Minos N. Garofalakis},
  title     = {Secure XML Querying with Security Views},
  booktitle = {SIGMOD Conference},
  year      = {2004},
  pages     = {587-598},
  ee        = {http://doi.acm.org/10.1145/1007568.1007634, http://www.sigmod.org/sigmod/sigmod04/eproceedings/pdf/R-637.pdf},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{DBLP:journals/toplas/SimonetP07,
  author    = {Vincent Simonet and
               Fran\c{c}ois Pottier},
  title     = {A constraint-based approach to guarded algebraic data types},
  journal   = {ACM Trans. Program. Lang. Syst.},
  volume    = {29},
  number    = {1},
  year      = {2007},
  ee        = {http://doi.acm.org/10.1145/1180475.1180476},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{DBLP:conf/sp/SwamyCH08,
  author    = {Nikhil Swamy and
               Brian J. Corcoran and
               Michael Hicks},
  title     = {Fable: A Language for Enforcing User-defined Security Policies},
  booktitle = {IEEE Symposium on Security and Privacy},
  year      = {2008},
  pages     = {369-383},
  ee        = {http://doi.ieeecomputersociety.org/10.1109/SP.2008.29},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@INPROCEEDINGS{corcoran07provenance,
  AUTHOR = {Brian J. Corcoran and Nikhil Swamy and Michael Hicks},
  TITLE = {Combining Provenance and Security Policies in a Web-based
    Document Management System},
  BOOKTITLE = {On-line Proceedings of the Workshop on Principles of Provenance (PrOPr)},
  NOTE = {\url{http://homepages.inf.ed.ac.uk/jcheney/propr/}},
  LOCATION = {Edinburgh, Scotland, UK},
  MONTH = NOV,
  YEAR = 2007
}

@article{sabelfeld03,
 author = {Andrei Sabelfeld and Andrew C. Myers},
 title = {Language-{B}ased {I}nformation-{F}low {S}ecurity},
 journal = {{IEEE} {J}ournal on {S}elected {A}reas in {C}ommunications},
 volume = 21,
 number = 1,
 year = 2003
}

@incollection{Pitts05ATTAPL,
  author =	 {A. M. Pitts},
  title =	 {Typed Operational Reasoning},
  booktitle =	 {Advanced Topics in Types and Programming Languages},
  pages =	 {245--289},
  publisher =	 {The MIT Press},
  year =	 2005,
  editor =	 {B. C. Pierce},
  chapter =	 7
}


*
* ###################################################################################
  ###################################################################################
  ##                                                                               ##
* ##                         CONTRACTS AND REFINEMENT TYPES                        ##
  ##                                                                               ##
  ###################################################################################
* ###################################################################################

** Gronski, et al. Sage

@INPROCEEDINGS{Gronski06Sage,
    author = {Jessica Gronski and Kenneth Knowles and Aaron Tomb and Stephen N. Freund and Cormac Flanagan},
    title = {Sage: Hybrid checking for flexible specifications},
    booktitle = {In Workshop on Scheme and Functional Programming},
    year = {2006}
}

** Flanagan. Hybrid Type Checking

@inproceedings{Flanagan06Hybrid,
 author = {Cormac Flanagan},
 title = {Hybrid type checking},
 booktitle = {POPL '06: Conference record of the 33rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
 year = {2006},
 isbn = {1-59593-027-2},
 pages = {245--256},
 location = {Charleston, South Carolina, USA},
 doi = {http://doi.acm.org/10.1145/1111037.1111059},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

** Knowles, et al. Type reconstruction for general refinement types

@INPROCEEDINGS{Knowles07Inference,
    author = {Kenneth Knowles and Cormac Flanagan},
    title = {Type reconstruction for general refinement types},
    booktitle = {In ESOP «07},
    year = {2007},
    publisher = {Springer-Verlag}
}

** Ou, et al. Dynamic typing with dependent types

@TECHREPORT{Ou04DTDT,
    author = {Xinming Ou and Gang Tan and Yitzhak M and David Walker},
    title = {Dynamic typing with dependent types},
    institution = {Princeton University},
    year = {2004}
}

** Xu, et al.  Static Contract Checking for Haskell

@MISC{Xu09Static,
    author = {Dana N. Xu and Simon Peyton Jones and Koen Claessen},
    title = {Static Contract Checking for Haskell},
    institution = {University of Cambridge},
    booktitle = {POPL '09: Conference record of the 36th ACM
                  SIGPLAN-SIGACT symposium on Principles of
                  programming languages \textit{Accepted.}},
    year = {2009}
}

** Wadler, Findler. Well-typed Programs Can't Be Blamed.

@inproceedings{Wadler07Blame,
	author = {Wadler, Philip   and Findler, Robert  B. },
	booktitle = {International Conference of Functional Programming},
	journal = {Scheme Workshop},
	month = {September},
	title = {Well-typed programs can't be blamed},
	url = {http://homepages.inf.ed.ac.uk/wadler/papers/blame/blame.pdf},
	year = {2007}
}

** Ross, et al. Evolving Types.

@misc{Ross08Evolving,
        author = {Ross, K.D.P. and Gottschling, Peter and Lumsdaine, Andrew and Sabry, Amr},
        title = {Evolving Types},
        year = {2008}
}

** Siek. Gradual typing for functional languages.

@INPROCEEDINGS{Siek06Gradual,
    author = {Jeremy G. Siek},
    title = {Gradual typing for functional languages},
    booktitle = {In Scheme and Functional Programming Workshop},
    year = {2006},
    pages = {81--92}
}

** Siek, Vachharajani. Gradual Typing with Unification-based Inference.

@techreport{Siek08Inference,
	author = {Jeremy Siek and Manish Vachharajani},
	institution = {University of Colorado at Boulder},
	month = {January},
	number = {CU-CS-1039-08},
	title = {Gradual Typing with Unification-based Inference},
	year = {2008},
}

** Herman, Tomb, Flanagan.  Space-efficient gradual typing.

@INPROCEEDINGS{Herman07Space,
    author = {David Herman and Aaron Tomb and Cormac Flanagan},
    title = {Space-efficient gradual typing},
    booktitle = {In Trends in Functional Programming (TFP},
    year = {2007}
}

** Tobin-Hochstadt and Felleisen.  The design and implementation of typed scheme.

@inproceedings{DBLP:conf/popl/Tobin-HochstadtF08,
  author    = {Sam Tobin-Hochstadt and
               Matthias Felleisen},
  title     = {The design and implementation of typed scheme},
  booktitle = {POPL},
  year      = {2008},
  pages     = {395-406},
  ee        = {http://doi.acm.org/10.1145/1328438.1328486},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

** Knowles, Flanagan. Hybrid type checking.

@misc{Knowles08HTC,
        author = {Kenneth Knowles and Cormac Flanagan},
        title = {Hybrid Type Checking},
        year = {2008},
        institution = {University of California at Santa Cruz}
}


** Hinze, et al. Typed contracts for functional programming.

@INPROCEEDINGS{Hinze06Typed,
    author = {Ralf Hinze and Johan Jeuring and Andres L\"oh},
    title = {Typed contracts for functional programming},
    booktitle = {In FLOPS '06: Functional and Logic Programming: 8th International Symposium},
    year = {2006},
    pages = {208--225},
    publisher = {Springer-Verlag}
}
_____________________________________________________________________________________
_____________________________________________________________________________________




*
* ###################################################################################
  ###################################################################################
  ##                                                                               ##
* ##                                    NOTES                                      ##
  ##                                                                               ##
  ###################################################################################
* ###################################################################################

*
* CONFERENCES WORTH SCANNING RECENT INSTANCES OF
**    FOR SYNCHRONIZATION IN GENERAL
**      SIGMOD  [BCP has scanned the last ten years]
**      PODS    [BCP has scanned the last ten years]
** ##   Coopis  (Cooperative Information Systems)     [should we submit here??]
** ##   MPC     Mathematics of Program Construction
**      CSCW    [AS has scanned the last ten years]
**      GROUPS
**      Mobile Data Management Conference (MDM)
**      ICDE
**      Usenix special interest conferences/workshops
**    FOR VIEW UPDATE AND BI-DIRECTIONAL PROGRAMMING LANGUAGES
**      MPC    (deadline Jan, conference July -- lots of HuMu type work)
**      PEPM   (deadline spring, conference fall)



Local Variables:
mode: outline
End:

