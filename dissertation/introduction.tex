% TODO with high priority: add a paragraph with real content about the last few chapters
Recent years have seen increased interest in the area of bidirectional
programming. Broadly speaking, the problem domain involves maintaining a
connection between two different representations of otherwise very similar
information. The strong connections between an in-memory representation of a
data structure and its serialized form; a piece of source code and its
parsed abstract syntax tree~\cite{rendel2010invertible}; tool-specific
configuration formats and a common configuration format~\cite{Augeas}; a
database and some particular summary of interest; or two distant but
partially replicated computers~\cite{pierce2004unison} are all examples of
areas where two pieces of data are very similar. We will call each of the
two objects in these pairings \emph{repositories}. In each case, one would
like the two repositories to stay ``in synch'': modifications to one
repository should be propagated and reflected in the other.

At the moment, one common way of tackling this problem is to design by hand
two programs that work together. Calling the two repositories $X$ and $Y$,
the first program translates updates to $X$ into updates to $Y$, and the
second translates in the other direction, turning updates to $Y$ into
updates to $X$. (Taking the example of connecting a piece of source code and
its abstract syntax tree from above, these two programs might be a parser
and a pretty-printer.) Programming in this style, however, quickly grows
unmanageable. Recent developments in bidirectional transformations have
suggested that a language-based approach---that is, the creation of a
language where each program represents two transformations---may be more
practical in many ways. Existing languages have a uniform interface across
terms: different programs are run in the same manner. This means that such
bidirectional programs are easy to extend to accommodate the evolution of
the data structures being connected. Moreover, the language itself can
provide evidence that the transformations are correct, for example, by
guaranteeing that any transformation that can be constructed within the
language will restore synchrony on each run, will not discard too much
information, will not disrupt synchrony unnecessarily, or similar behavioral
guarantees\footnote{We will use ``synchronize'' and related words informally
to mean simply ``maintain a correspondence between two repositories by
propagating edits in both directions''. A full-blown synchronization tool
would also include, at a minimum, some mechanism for dealing with conflicts
between disconnected edits to the two structures, which is outside the scope
of this document. Note, though, that we will go beyond most existing
synchronization tools in allowing the repositories to be structured
differently and to share only a part of their information.}. Designing a
language is also a more modular approach to solving the bidirectional
transformation problem, as the design of bidirectional building blocks can
be separated from the process of gluing the blocks together into particular
useful transformations.

The term ``lens'' is a broad term encompassing a large family of related
language-based approaches to the bidirectional transformation problem.
In \S\ref{sec:asymmetric-lenses}, we will introduce one of the earliest
language-based approaches, asymmetric lenses, as a way to ground our ongoing
discussion of the features that make bidirectional programming attractive
and practical. We will identify four key challenges in lens design:
alignment (the ability to represent data evolution precisely,
\S\ref{sec:intro-alignment}), symmetry (no more restrictions on one piece of
connected data than on the other, \S\ref{sec:intro-symmetry}), performance
(handling data in an incremental way, \S\ref{sec:intro-performance}), and
syntax (the existence of example transformations, \S\ref{sec:intro-syntax}).
Table~\ref{tab:related-work-matrix} shows how other approaches stack up on
these four key features. We will discuss this figure in depth in
Chapter~\ref{chap:related}; for now, it suffices to observe that the edit
lens framework as described in this document is the first framework to
support all four features.

\begin{table}
     % TODO: add \cite commands for each row
    \begin{center}
    \begin{tabular}{l|cccc}
        & Alignment & Symmetry & Performance & Syntax \\
        \hline
        group-based lenses      &\Y&\N&\N&\N\\
        symmetric delta lenses  &\Y&\Y&\N&\N\\
        symmetric lenses        &\N&\Y&\N&\Y\\
%        triple graph grammars   &\N&\Y&\N&\Y\\
        asymmetric delta lenses &\Y&\N&\N&\Y\\
        matching lenses         &\Y&\N&\N&\Y\\
        hole-based delta lenses &\Y&\N&\N&\Y\\
        constraint maintainers  &\Y&\Y&\N&\Y\\
        edit lenses             &\Y&\Y&\Y&\Y\\
    \end{tabular}
    \end{center}
    \caption{Feature coverage for various approaches to bidirectional
    programming}
    \label{tab:related-work-matrix}
\end{table}

\section{Asymmetric Lenses}
\label{sec:asymmetric-lenses}
One well-studied approach to bidirectional programming is the framework of
\emph{asymmetric}, \emph{state-based} lenses. A thorough review of this work
is available elsewhere~\cite{FosterThesis}, so we will give only a brief
introduction to the core concepts. Suppose we have two repositories; one
repository stores a piece of data represented by an element of the set $S$,
and the other stores an element of $V$. Then a lens connecting the two
repositories has three components:
\begin{align*}
    \aget &\in S \to V \\
    \aput &\in V \times S \to S \\
    \acreate &\in V \to S
\end{align*}
In this model, the $V$ repository is a \emph{view} of or \emph{query} on the
$S$ repository (called a \emph{source}): that is, it can be completely
reconstructed from the other without additional outside information. The
type of the \GET component of the lens reflects this assumption. In most
cases, a query will keep only some of the information available in the
source; as a result, the opposite reconstruction property---that the source
can be completely reconstructed from the view---usually does not hold.
Asymmetric, state-based lenses handle this situation by allowing their other
major function component to have access to both a modified value from the
view repository \emph{and} an original value from the source repository to
merge the new data into, as reflected in the type of \PUT. As a technical
detail, it is sometimes convenient to demand (and rarely difficult to
supply) a way to generate a value in the source repository with some sane
defaults. This is the \CREATE component of the lens.

Lenses have one more piece, which was alluded to above. The structure we
have described so far already addresses the need to give two transformations
(namely \GET and \PUT), but does not yet address our desire to prove that
these two transformations work well together. Let us first try to build an
intuition for what ``works well together'' might mean before we formalize
this. Suppose we have a lens $\ell$; to simplify things, we will take
$\ell.\aget$ to be unassailable\footnote{We will use record notation for
lens components, so that $\ell.\aget$ is the \GET component of $\ell$.} and
phrase all our desires in terms of constraints on $\ell.\aput$. It is
natural to expect two things from our lens: first, that $\ell.\aput$ changes
enough---that whatever change we make to the view is faithfully reflected in
the source so that future calls to $\ell.\aget$ give exactly the value we
changed the view to---and second, that $\ell.\aput$ does not change too
much---that only the parts of the source that are used to compute the view
are modified. Three behavioral laws address this intuition:
\begin{align*}
    \aput(\aget(s),s)  &= s & \rn{GetPut} \\
    \aget(\aput(v,s))  &= v & \rn{PutGet} \\
    \aget(\acreate(v)) &= v & \rn{CreateGet}
\end{align*}
The \rn{PutGet} law formalizes the expectation that $\ell.\aput$ changes
enough; the \rn{GetPut} law takes a step toward formalizing the expectation
that $\ell.\aput$ does not change too much. In fact, the \rn{GetPut} law
only guarantees that unmodified views result in unmodified sources, but any
change to the view, no matter how tiny, voids all further guarantees; this
has been viewed as a weakness of some previous approaches. It is very hard
to come up with a better generic guarantee than this within the asymmetric,
state-based lens framework, but Chapter~\ref{chap:delta} takes an unexpected
step in refining this behavioral law. There is a third law,
\rn{CreateGet}, which serves a similar purpose to the \rn{PutGet} law.
Collectively, these behavioral laws are often also called \emph{roundtrip
laws}: another way to read them is that in a given ``round trip'' through
the lens the repository returns to exactly the same state it started at.
% violating GetPut but satisfying PutGet:
%     get(x,y) = x
%     put(x',(x,y)) = (x',3)
% violating PutGet but satisfying GetPut:
%     get(x) = x
%     put(x', x) = x + 2*(x'-x)
In the remainder, we will write $\ell \in S \alens V$ to assert that $\ell$
is an asymmetric, state-based lens---that is, that it is a triple of
functions whose types are as above that satisfy the three behavioral laws
discussed. We will use record notation to refer to the three components;
thus $\ell.\aget$ is the first field of the triple, $\ell.\aput$ the second,
and $\ell.\acreate$ the third.

In the remaining sections, we use asymmetric lenses as a vehicle to explore
the importance of and challenges involved in supporting good alignment
strategies, information symmetry, good performance, and a rich syntax.

\begin{figure}
    \begin{align*}
        \ell\LIST.\aget(t) &= \map(\ell.\aget,t) \\
        \ell\LIST.\acreate(u) &= \map(\ell.\acreate,u) \\
        \ell\LIST.\aput(t,u) &=
            \zip(\ell.\aput,\map(\ell.\acreate),\constU(\NIL),t,u)
    \end{align*}
    \caption{A naive implementation of the bidirectional \map operation}
    \label{fig:naive-asymmetric-map}
\end{figure}

\section{Alignment}
\label{sec:intro-alignment}
% TODO: Diskin et al notes that there's another very subtle flaw with the
% way state-based lenses do alignment. Since each lens is responsible for
% rediscovering the alignment, it's possible for the sublenses to disagree!
% Perhaps we can come up with a really compelling example of lenses k and l
% such that k;l is well-typed but l.put produces some output with one
% alignment in mind, and k.put consumes that output with another alignment
% in mind. We'll need to think about where such an example should fit in the
% flow, too.

One very common operation when doing functional (unidirectional) programming
is the \map operation, which runs a computation on each element of a list.
To give an idea of how common, as of April 3, 2012, there were 3878 packages
on Hackage~\cite{Hackage2012}, the central code repository for Haskell
projects, which made a total of 90,040 calls to \map---an average of more
than twenty calls per project\footnote{In fact, the program used to
calculate these numbers itself makes two calls to \map:

\noindent\texttt{ack -cl '\textbackslash bmap\textbackslash b' | cut -d:\ -f2 |}

\noindent\texttt{ghc -e 'interact \$ unlines . map show . scanl (+) 0 . map read . lines'}
}. Most serious attempts at designing a bidirectional language therefore
provide some variant of a mapping operation. Since it is such a popular
operation, it is important to do a really good job of designing the
bidirectional \map (which we will denote by $-\LIST$ to distinguish it from
the unidirectional version), and that job turns out to be surprisingly
difficult! To see why, let us implement $-\LIST$ in the most obvious way;
then we can discuss the deficiencies of this approach.

Like \map, which is parameterized by a unidirectional function to apply to
list elements, $-\LIST$ will be parameterized by a bidirectional operation.
That is, writing $S\LIST$ for the set of lists with elements drawn from $S$,
when $\ell \in S \alens V$, we will have $\ell\LIST \in S\LIST \alens
V\LIST$. Figure~\ref{fig:naive-asymmetric-map} defines the $-\LIST$ lens,
relying on some auxiliary definitions given in
Figure~\ref{fig:uni-map-zip-const}. The \GET and \CREATE operations are
fairly straightforward---direct analogues of the unidirectional
version---but the \PUT operation is more delicate. Since \PUT takes one
value from each repository, our $\ell\LIST.\aput$ operation takes two lists,
of types $S\LIST$ and $V\LIST$. When these lists are the same length we can
just zip them together, applying $\ell.\aput$ to pairs of elements in the
same positions in the two lists. When they are different lengths, there have
been insertions or deletions. Deletions can be reflected directly by
deleting the last few elements of the $S\LIST$ list until the lengths match.
For insertions, we recover elements of $S$ by treating the last few elements
of the $V\LIST$ list as the insertions and using \CREATE to fabricate $S$
elements to insert.

\begin{figure}
    \begin{align*}
        \tolower.\aget(c) &= \mbox{the lower case version of $c$} \\
        \tolower.\aput(c',c) &= \cond{
            \mbox{the upper case version of $c'$} & \mathtt{A} < c < \mathtt{Z} \\
            c' & \mbox{otherwise}
        } \\
        \tolower.\acreate(c) &= c
    \end{align*}
    \caption{The \tolower lens to convert a possibly-upper-case letter into
    a definitely-lower-case one}
    \label{fig:tolower-lens}
\end{figure}
Figure~\ref{fig:tolower-lens} defines a lens \tolower that converts a
character to lower case so that we can demonstrate the behavior of $-\LIST$.
\begin{align*}
    \tolower\LIST.\aget(\mathtt{UpperCasedQord})
        &= \mathtt{uppercasedqord} \\
    \tolower\LIST.\aput(\mathtt{uppercasedword},\mathtt{UpperCasedQord})
        &= \mathtt{UpperCasedWord} \\
    \tolower\LIST.\aput(\mathtt{uppercased},\mathtt{UpperCasedWord})
        &= \mathtt{UpperCased} \\
    \tolower\LIST.\aput(\mathtt{uppercasedsentence},\mathtt{UpperCasedWord})
        &= \mathtt{UpperCasedSentence}
\end{align*}
All of these examples behave essentially optimally. However, not all is
well; a simple example of the so-called \emph{alignment problem} is
something like this, where we have an insertion in the middle of the word to
correct the spelling of ``upper'':
\[\tolower\LIST.\aput(\mathtt{uppercasedword},\mathtt{UperCasedWord})
    = \mathtt{UppeRcaseDword}\]
Because $\tolower\LIST.\aput$ only looks at a lower-cased element's
position when deciding which mixed-case character to match it up with, we
have incorrectly \emph{aligned} the new view with the old source this way:

\begin{diagram}[alignment diagram]
    \foreach \c in {U,p,e,r,C,a,s,e,d,W,o,r,d}
        {\node[on chain=source]{\c};}
    \node[on chain=view,below=5ex of source-1] {u};
    \foreach \c in {p,p,e,r,c,a,s,e,d,w,o,r,d}
        {\node[on chain=view]{\c};}
    \foreach \n in {1,...,13}
        {\draw (source-\n) -- (view-\n);}
\end{diagram}

\breakifoverfraction{0.95}
\noindent A better alignment would look like this:

\begin{diagram}[alignment diagram]
    \foreach \c in {U,p,e,r,C,a,s,e,d,W,o,r,d}
        {\node[on chain=source]{\c};}
    \node[on chain=view,below=5ex of source-1] {u};
    \foreach \c in {p,p,e,r,c,a,s,e,d,w,o,r,d}
        {\node[on chain=view]{\c};}
    \foreach \n in {1,2}
        {\draw (source-\n) -- (view-\n);}
    \foreach \s in {3,...,13}
        {\pgfmathtruncatemacro\v{\s+1}\draw (source-\s) -- (view-\v);}
\end{diagram}

\begin{figure}
    \begin{align*}
        \map(f,t) &= \cond{
            \NIL & t = \NIL \\
            f(x) \CONS \map(f,t') & t = x \CONS t'
        } \\
        \zip(f,g,h,t,u) &= \cond{
            f(x,y) \CONS \zip(f,g,h,t',u') & t = x:t' \land u = y:u' \\
            g(t) & t = x:t' \land u = \NIL \\
            h(u) & t = \NIL \land u = y:u' \\
            \NIL & t = u = \NIL
        } \\
        \constU(x) &= \lambda y.\;x
    \end{align*}
    \caption{Auxiliary unidirectional functions used in the definition of
    $-\LIST$}
    \label{fig:uni-map-zip-const}
\end{figure}

One natural reaction to this infelicity is to think of the \texttt{diff}
algorithm~\cite{hunt1976algorithm} or something similar. This idea has been
developed quite far~\cite{Matching10}; let us see how. At first blush, it
seems difficult to use the \texttt{diff} algorithm directly. Elements of the
source and view have different types, so it is not clear how to compare
them\footnote{One might be tempted to use \texttt{diff} anyway, or to use a
case-insensitive \texttt{diff}. In the general case, the elements of the
source and view lists are very different kinds of objects, so that kind of
trick does not scale well.}. However, the alignment diagram above may be
broken into two stages:

\begin{diagram}[alignment diagram]
    \foreach \c in {U,p,e,r,C,a,s,e,d,W,o,r,d}
        {\node[on chain=source]{\c};}
    \node[on chain=intermediate,below=5ex of source-1] {u};
    \foreach \c in {p,e,r,c,a,s,e,d,w,o,r,d}
        {\node[on chain=intermediate]{\c};}
    \node[on chain=view,below=5ex of intermediate-1] {u};
    \foreach \c in {p,p,e,r,c,a,s,e,d,w,o,r,d}
        {\node[on chain=view]{\c};}
    \foreach \n in {1,...,13}
        {\draw (source-\n) -- (intermediate-\n);}
    \foreach \n in {1,2}
        {\draw (intermediate-\n) -- (view-\n);}
    \foreach \s in {3,...,13}
        {\pgfmathtruncatemacro\v{\s+1}\draw (intermediate-\s) -- (view-\v);}
    \path
        node[right=3em of view-end,font=\rmfamily]           (view-type)
            {new view (of type $V\LIST$)}
        (intermediate-end -| view-type) node[font=\rmfamily] (intermediate-type)
            {old view (of type $V\LIST$)}
        (source-end       -| view-type) node[font=\rmfamily] (source-type)
            {old source (of type $S\LIST$)}
        ;
\end{diagram}

In this restructured alignment diagram, the upper alignment (which connects
elements of different types) will always be completely flat, and hence
requires no sophisticated tools to generate. In contrast, the lower
alignment contains all the interesting information, and is the one we hope
to compute with \texttt{diff}. Moreover, the connections in the lower
alignment are now between elements of the same type, making the use of
% TODO: expand these wrinkles into paragraphs/pages?
\texttt{diff} much more plausible. One wrinkle is that the data in this
example is unrealistically simple, and more complicated data often needs
more complicated tools for specifying the cost function that \texttt{diff}
uses. Another wrinkle is that in real-world situations, one often wants to
discover alignments with crossings like
\begin{diagram}[alignment diagram]
    \foreach \c in {D,i,r,G,r,a,p,h,R,e,s}
        {\node[on chain=source]{\c};}
    \node[on chain=intermediate,below=5ex of source-1] {d};
    \foreach \c in {i,r,g,r,a,p,h,r,e,s}
        {\node[on chain=intermediate]{\c};}
    \node[on chain=view,below=5ex of intermediate-1] {r};
    \foreach \c in {e,s,d,i,r,g,r,a,p,h}
        {\node[on chain=view]{\c};}
    \foreach \n in {1,...,11}
        {\draw (source-\n) -- (intermediate-\n);}
    \foreach \s in {1,...,8}
        {\pgfmathtruncatemacro\v{\s+3}
         \draw (intermediate-\s) -- (view-\v);}
    \foreach \s/\h in {9,...,11}
        {\pgfmathtruncatemacro\v{\s-8}
         \pgfmathparse{7.5-\s}
         \draw (intermediate-\s.south) to[|-|=\pgfmathresult ex] (view-\v.north);}
\end{diagram}
which require more sophisticated algorithms than the traditional
\texttt{diff}.
% TODO: expand the explanation of what's hard about guessing alignments? not
% sure; it would be pretty easy to fill a lot of space with text about that,
% but it seems sort of orthogonal to the point we're trying to make here.
% how should this whole section be structured?

\begin{figure}
    \begin{minipage}{0.33333333\linewidth}
        \centering
        \begin{tabular}{lr}
            Teacher name & Salary \\
            \hline
            Sam Rickard & 57,000 \\
            Jon Jacobs & 50,000 \\
            Mary Jones & 65,000 \\
        \end{tabular}
        \subcaption{HR's view}
        \label{fig:school-salaries-hr}
    \end{minipage}%
    \begin{minipage}{0.33333333\linewidth}
        \centering
        \begin{tabular}{l}
            Teacher name \\
            \hline
            Sam Rickard \\
            Jon Jacobs \\
            Mary Jones \\
        \end{tabular}
        \subcaption{A secretary's view}
        \label{fig:school-salaries-sec-pre}
    \end{minipage}%
    \begin{minipage}{0.33333333\linewidth}
        \centering
        \begin{tabular}{l}
            Teacher name \\
            \hline
            Sam Rickard \\
            Jon Jacobs \\
            Mary Smith \\
        \end{tabular}
        \subcaption{After an update}
        \label{fig:school-salaries-sec-post}
    \end{minipage}\\[3ex]

    \begin{minipage}{\linewidth}
        \begin{diagram}[alignment diagram, inner xsep=1em, start chain=salary]
            \path
                node[on chain=source]       {Sam Rickard}
                node[on chain=source]       {Jon Jacobs}
                node[on chain=source]       {Mary Jones}
                node[on chain=salary,below=of source-1]
                                            {57,000}
                node[on chain=salary,below=of source-2]
                                            {50,000}
                node[on chain=salary,below=of source-3]
                                            {65,000}
                node[on chain=intermediate, below=6ex of salary-1]
                                            {Sam Rickard}
                node[on chain=intermediate] {Jon Jacobs}
                node[on chain=intermediate] {Mary Jones}
                node[on chain=view, below=6ex of intermediate-1]
                                            {Sam Rickard}
                node[on chain=view]         {Jon Jacobs}
                node[on chain=view]         {Mary Smith}
                ;
            \foreach \n in {1,2,3} \draw (salary-\n) -- (intermediate-\n);
            \foreach \n in {1,2}   \draw (intermediate-\n) -- (view-\n);
            \draw[dashed] (intermediate-3) to node[right,font=\sffamily]{?} (view-3);
        \end{diagram}
        \subcaption{Whether the marked edge should be included or not
            depends on invisible context}
        \label{fig:school-salaries-align}
    \end{minipage}
    \caption{A school's staff list, as seen by HR and by the principal's secretary}
    \label{fig:school-salaries}
\end{figure}

Indeed, it is not even clear that it is always possible to correctly guess
the alignment given just an old and a new copy of the data.
Figure~\ref{fig:school-salaries} gives an example of a particularly tricky
situation involving a school's employee database.
Part~\subref{fig:school-salaries-hr} shows the full database, which includes
a listing of all the teachers and their salaries. It transpires that the
school secretary finds it useful to have access to this database; however,
the secretary should not be privy to the confidential salary information.
Consequently there is a secretarial view, shown in
part~\subref{fig:school-salaries-sec-pre}, with salaries redacted, and we
would like to keep the database and view synchronized using a $-\LIST$ lens.
Now, suppose one of two scenarios happens:
\begin{itemize}
    \item Mary Jones gets married and changes her name to Mary Smith.
    \item Mary Jones retires, and the school hires a replacement who, by
        coincidence, shares her first name: Mary Smith.
\end{itemize}
In both cases, when the secretary updates her document, it will look as it
does in part~\subref{fig:school-salaries-sec-post}. As shown in
part~\subref{fig:school-salaries-align}, there are really two feasible
alignments, corresponding to whether the dotted edge should be present or
not. In the first scenario above, the edge should be present: we should
align Mary with her former self, and reflect the change as an update to her
name (but keep her old salary). In contrast, in the second scenario, the
edge should not be present: we should not align the new Mary with any of the
teachers that used to teach at the school. Since only the old and new copies
of the secretary's document are available to a lens, the lens cannot choose
correctly. The context under which the change was made is invisible to the
lens, and it has no way to distinguish between these two scenarios merely by
observing what has changed.

Clearly, discovering alignment information is a tricky business.
Additionally, most current lens frameworks treat such alignment information
as a second-class citizen: it is not passed, stored, or returned by the
lens. Because of this, it is not possible for an outside tool to provide
hints about the alignment; the implementation of alignment discovery is
intermingled with the implementation of alignment usage and propagation
inside each lens' definition; and alignment information cannot be internally
communicated between lens components. The conclusion we must draw is that
doing a really good job of implementing $-\LIST$ involves rethinking some or
all of the theoretical foundations of lenses to address the representation,
propagation, and use of alignment information.

% TODO: it almost seems like this last paragraph appears out of nowhere. I
% wonder if it is worth trying to explode even that into a page or two.

\section{Symmetry}
\label{sec:intro-symmetry}
Let us turn our attention to a second fundamental challenge in lens design:
symmetry. The asymmetric lenses discussed above assume that one repository
is a view of the other. In the following, we will discuss two bidirectional
scenarios, one that highlights the need to relax this assumption, and one
that identifies a useful feature of asymmetric lenses that has long been
thought incompatible with symmetry.

Continuing the example from \ref{sec:intro-alignment}, suppose our school
secretary decided to begin tracking which room each teacher taught in. The
two lower tables in Figure~\ref{fig:span-lenses} shows how the two
repositories might look after this schema change. As before, the salary
information should be hidden from the secretary for privacy reasons; on the
other hand, in our new scenario the human resources department is not
interested in room assignments. Unfortunately, this slight modification puts
our scenario firmly outside the realm of problems that asymmetric,
state-based lens tools can help with: neither repository can be completely
reconstructed just from the information available in the other.

Since the problem is that neither repository contains all the information,
one thing that can be done is to design a third repository that \emph{does}
contain all the information. One would then design two lenses with that
third repository as a common source, as shown in the remainder of
Figure~\ref{fig:span-lenses}. The new repository sits at the top, and
contains teacher names, salaries, and room assignments all in one location.
The two repositories we are really interested in sit below, and are derived
via two lenses. (We introduce the notation $\pi_{i_1,\ldots,i_n}$ for the
lens which projects out distinct fields $i_1,\ldots,i_n$ of a tuple. To be
really precise, each omitted field would need an additional annotation
giving a value to return from the \CREATE operation, but we elide these
annotations to avoid clutter.)

Suppose the secretary updates the room assignments document. The process to
find a corresponding update for the salary document involves two lens
operations: first, we use $\pi_{1,3}\LIST.\aput$ to update the common
source, then $\pi_{1,2}\LIST.\aget$ to regenerate the salary document from
the common source.

\begin{figure}
    \begin{diagram}
        \node (common source) {
            \begin{tabular}{lll}
                Teacher name & Salary & Room \\
                \hline
                Sam Rickard & 57,000 & 314 \\
                Jon Jacobs  & 50,000 & 108b \\
                Mary Jones  & 65,000 & 109
            \end{tabular}
        };
        \node[below left=15ex] (salary) {
            \begin{tabular}{ll}
                Teacher name & Salary \\
                \hline
                Sam Rickard & 57,000 \\
                Jon Jacobs  & 50,000 \\
                Mary Jones  & 65,000
            \end{tabular}
        };
        \node[below right=15ex] (room) {
            \begin{tabular}{ll}
                Teacher name & Room \\
                \hline
                Sam Rickard & 314 \\
                Jon Jacobs  & 108b \\
                Mary Jones  & 109
            \end{tabular}
        };
        \draw[<->] (common source) -- node[left=1em]  {$\pi_{1,2}\LIST$} (salary);
        \draw[<->] (common source) -- node[right=1em] {$\pi_{1,3}\LIST$} (room);
    \end{diagram}
    \caption{A slightly more complicated synchronization scenario}
    \label{fig:span-lenses}
\end{figure}

This approach is workable, and is fairly comprehensive. However, it is a
little bit awkward in a few ways, the most notable of which is that we are
now constructing two lenses. Even in this simple example, we can see that
the structure of the lenses are very similar. All of the arguments which led
people to prefer bidirectional languages over pairs of unidirectional
programs in the first place---uniformity, guaranteed correctness,
maintainability, modularity, etc.---arise here against writing pairs of
bidirectional programs, too. It would be
better to develop some theory which models the two operations together, so
that we can write a single program and derive the two synchronization
operations of interest. One could continue by designing a
``bi-bidirectional'' language---where each term could be interpreted as two
lenses which are intended to be run back-to-back as in this example---but we
choose instead to reconsider the foundations of lens theory and design a
framework of symmetric bidirectional transformations that natively handles
symmetric scenarios.

\begin{figure}
    \centering
    \subcaptionbox{Asymmetric, state-based lenses\label{fig:asymmetric-architecture}}
        {
        \begin{tikzpicture}[>=latex]
            \prettylensarchitectureoverview
            \draw
                (A.east) +(0,-0.1)
                    .. controls (B.west) and (B'.west) ..
                (near A');
            \draw[->,dashed] (B)  to node[right] {user modification} (B');
            \draw[->,dashed] (A') to node[left]  {user modification} (A);
        \end{tikzpicture}
        }

    \begin{center}
    \subcaptionbox{(Partial) isomorphisms\label{fig:isomorphism-architecture}}
        {
        \begin{tikzpicture}[>=latex]
            \prettylensarchitectureoverview
            \draw[->,dashed] (B)  to (B');
            \draw[->,dashed] (A') to (A);
            % spacer so that captions are not broken on two lines
            \path
                ($(B)!.5!(A')$)
                    node {\phantom{(b) (Partial) isomorphisms}}
                    node {\phantom{(c) Constraint maintainers}}
                ;
        \end{tikzpicture}
        }
    \hfil
    \subcaptionbox{Constraint maintainers\label{fig:constraint-maintainer-architecture}}
        {
        \begin{tikzpicture}[>=latex]
            \prettylensarchitectureoverview
            \draw
                (A.east) +(0,-0.1)
                    .. controls (B.west) and (B'.west) ..
                (near A');
            \draw
                (B'.west) +(0,0.1)
                    .. controls (A'.east) and (A.east) ..
                (near B);
            \draw[->,dashed] (B)  to (B');
            \draw[->,dashed] (A') to (A);
            % spacer so that captions are not broken on two lines
            \path
                ($(B)!.5!(A')$)
                    node {\phantom{(b) (Partial) isomorphisms}}
                    node {\phantom{(c) Constraint maintainers}}
                ;
        \end{tikzpicture}
        }
    \end{center}

    \caption{Asymmetric lens life cycle, and some proposed symmetric
    variants}
    \label{fig:asymmetry-vs-symmetry}
\end{figure}

Let us address ourselves to what makes asymmetric lenses asymmetric in the
first place. Figure~\ref{fig:asymmetric-architecture} shows the typical
life-cycle of an asymmetric lens $\ell \in S \alens T$, ignoring \CREATE for
the moment. Drawing the types of the \GET and \PUT operations this way
highlights their asymmetry, and quickly suggests two ways of symmetrizing
the theory. Parts \subref{fig:isomorphism-architecture} and
\subref{fig:constraint-maintainer-architecture} illustrate these two ways,
namely, removing the extra arc in the type of \PUT, or adding an extra arc
to the type of \GET. Together with some appropriate roundtrip laws, the
% TODO: Perhaps ask Benjamin for the Braun citation mentioned in the
% delta/presentation.tex, and ask for other likely citations to put here
former are known as isomorphisms, and several languages whose terms
represent invertible functions in this way have been
designed~\cite{xsugar,rendel2010invertible}. They are especially useful as a
formalism when the extra information available in the repositories is
unimportant. For example, when parsing text, the exact whitespace used may
not be available in the abstract syntax tree, but often a few simple rules
will produce very similar replacement whitespace; and moreover the
whitespace has aesthetic but not semantic significance. In the example given
above, however, the extra information \emph{is} important, and cannot be
replaced with default data: resetting room assignments and salaries on each
roundtrip would be very undesirable behavior.

The latter (again with some appropriate roundtrip laws) are known as
constraint maintainers~\cite{Meertens98}, and do handle extra information
quite explicitly. Constraint maintainers would be a good formalism to use
when designing a bidirectional transformation for the school scenario above.
They can express the connection between salaries and room numbers---that is,
no connection at all---well, and support a \map-like combinator to turn this
single-record maintainer into one which handles lists of records like the
ones stored in the repositories. However, constraint maintainers do not
support \emph{sequential composition}, the ability to run one maintainer
after the other, and experience with asymmetric lenses shows that this is a
very common tool when designing bidirectional programs. To see why, we will
introduce a bidirectional transformation which is most naturally modeled
using composition.

% TODO: possible idea: merge these two examples. e.g. perhaps the school
% example could have an org chart on the HR side; this lets you keep the
% whole ``I wish I could have a tree-flattening lens and a list mapping lens
% that I compose'' thing
\begin{figure}
    \begin{diagram}
        \draw[short picture tree]
            node (root) {} child {
                node (Jan) {Jan}
                    \lolcatchildren{pumpkin,skateboard}
            } child {
                node (May) {May}
                    \lolcatchildren{pineapple}
            }
            ;
        \lolcattagsdef{pineapple-fs-pic}
            {pumpkin/{costume,food},skateboard/{anthro},pineapple/{food}}
    \end{diagram}
    \caption{A whimsical symmetric synchronization scenario}
    \label{fig:cat-server}
\end{figure}

The whimsical situation shown in Figure~\ref{fig:cat-server} involves a web
server, which must keep a file system storing pictures of cats synchronized
with a user-modifiable web page (modeled here as a list of cat pictures with
descriptive tags)\footnote{Pictures used with
permission~\cite{pumpkin-cat,skateboard-cat,pineapple-cat}.}. One natural
approach to implementing this transformation is pictured in
Figure~\ref{fig:cats-composition}. First, we separately implement two
constraint maintainers: a $\mathit{flatten}$ maintainer that flattens trees
to lists by extracting the leaves, and a $\mathit{relabel}$ maintainer that
describes the connection between a single leaf in our original tree and a
single list entry in our final list. We would then like to run these
maintainers back-to-back; that is, we would like a sequential composition
operator $-;-$ with a typing rule like:
\infrule{k \in A \cmaint B \qquad \ell \in B \cmaint C}{k;\ell \in A \cmaint C}
Unfortunately, implementing this combinator is not possible: we must design
the $(k;\ell).\aget \in A \times C \to C$ component using the
components $k.\aget$, $k.\aput$, $\ell.\aget$, and $\ell.\aput$, all of
which require a $B$ as input. It is certainly possible to build a constraint
maintainer which has the desired behavior wholesale, but this involves
writing both constraint maintenance functions and proving that they are
consistent with each other---the exact task we set out to avoid by
designing a language. Alternately, one can step a little bit outside the
constraint maintainer framework by keeping a copy of the ``intermediate''
repository around somewhere and running the constraint maintainers in
sequence on each update. Making this choice, however, leads one to
immediately ask how to model such maintainer chains and what behavioral
guarantees one can expect!

\begin{figure}
    \begin{diagram}
        \draw[short picture tree]
            node (root) {} child {
                node (Jan) {Jan}
                    \lolcatchildren{pumpkin,skateboard}
            } child {
                node (May) {May}
                    \lolcatchildren{pineapple}
            }
            ;
        \begin{scope}[start chain=going below,node distance=0]
            \foreach \name in {pumpkin,skateboard,pineapple} { \draw
                (root.north -| pineapple-fs-pic) +(3,0)
                node[on chain,anchor=north]    (\name-inter-pic)  {\lolcat{\name}}
                node[right=of \name-inter-pic] (\name-inter-name) {\tiny \name.jpg}
                ;
            }
        \end{scope}
        \lolcattags{(pumpkin-inter-pic.north -| pumpkin-inter-name.east) +(2,0)}
            {pumpkin/{costume,food},skateboard/{anthro},pineapple/{food}}
        \node[draw,rounded corners,fit=(root)
                (pumpkin-fs-name)    (pumpkin-fs-pic)
             (skateboard-fs-name) (skateboard-fs-pic)
              (pineapple-fs-name)  (pineapple-fs-pic)
             ] (fs) {};
        \node[draw,rounded corners,fit=
                (pumpkin-inter-pic)    (pumpkin-inter-name)
             (skateboard-inter-pic) (skateboard-inter-name)
              (pineapple-inter-pic)  (pineapple-inter-name)
             ] (inter) {};
        \node[draw,rounded corners,fit=
                (pumpkin-web-pic)    (pumpkin-web-tag)
             (skateboard-web-pic) (skateboard-web-tag)
              (pineapple-web-pic)  (pineapple-web-tag)
             ] (web) {};
        \draw[<->] ($(fs.south)+(0,-0.1)$)
            to[bend right] node[below] {$\mathit{flatten}$}
            ($(inter.south)+(-0.5,-0.1)$);
        \draw[<->] ($(inter.south)+(0.5,-0.1)$)
            to[bend right] node[below] {$\mathit{relabel}\LIST$}
            ($(web.south)+(0,-0.1)$);
    \end{diagram}
    \caption{Adding an intermediate structure can improve modularity}
    \label{fig:cats-composition}
\end{figure}

So an ideal model would capture the behavior of ``sequencing'', retain a
symmetric presentation, and allow each repository to retain information not
available in the other.

\section{Performance}
\label{sec:intro-performance}

% TODO: REW comments: it's important to have a very carefully worded
% sentence saying what performance is all about: e.g. you do everything with
% edits -- transfer, transform, etc. -- and the edits are smaller than the
% repositories
Real-world synchronization tools inevitably address a third concern:
performance. Typical repositories are large objects; consequently, there can
be significant time or memory costs associated with processing the data in a
repository or transmitting a repository across a network. For existing file
system synchronization tools like rsync, DropBox, and Unison and revision
control systems like CVS, SVN, darcs, mercurial, and git~%
\cite{Tridgell96rsync,dropbox,pierce2004unison,berliner1990cvs,subversion,darcs,mercurial,git},
network speed is a significant bottleneck. For these tools, where little
computation on the repositories themselves is required, the relatively
simple \emph{delta compression} technique, which involves noting what has
changed since a previous run of the tool, provides a serious network
transmission performance boost. For bidirectional transformations, where
repositories must be not just copied but transformed, computation time or
memory usage may also be concerns. Extending the use of delta compression to
address processing speed and memory requirements involves, in part, showing
that the computations of interest can be performed solely by inspecting the
deltas---that is, without decompressing and traversing the original
repositories. Since it seems likely that a practical tool will need to avoid
incurring high resource usage, a theory that faithfully models a successful
tool should therefore model not just repository states but also repository
edits, edit transformations, and the connection between edits and repository
states.

\section{Syntax}
\label{sec:intro-syntax}

One of the outstanding features of the body of asymmetric, state-based lens
work and its closest variants is the devotion to retaining a rich
syntax---that is, a large collection of particular lenses and lens
combinators that have the appropriate shape and behavior for the given lens
framework. This is a feature well worth emulating, for several reasons. The
simplest stems from the variety of examples given in previous sections. Even
in seemingly simple scenarios, there is often endless variation. Instead of
designing a synchronization tool that addresses one of these scenarios, we
set our sights higher: we wish to design a synchronization-tool-making tool
that makes it easy to address any of the scenarios. Thus we want to find a
collection of basic building blocks and ways of combining those blocks that
can be used together to customize the bidirectional transformation for many
different use cases.

Additionally, designing a syntax in parallel with the language semantics is
a valuable cross-validation technique. On several occasions during the
development of the framework described in this document, we found a
desirable transformation which could not be implemented within the type or
behavioral guarantees of our framework. Each time this happens, one then has
a valuable opportunity to reevaluate both the lens framework and the
transformation. A particularly good example of this, which we will discuss
in greater depth in Chapter~\ref{chap:complement}, is the transformation
which duplicates information\footnote{For an example where such a
transformation would be useful, imagine the process of turning wiki markup
into an HTML page that includes both a table of contents and a content body.
One might structure this as duplicating the markup, then extracting the
section titles from one duplicate and rendering the other.}. Many lens
frameworks rule this transformation illegal (including ours), because
supporting it involves relaxing the restriction that a single run of the
synchronization tool produces a synchronized state. Whether one prioritizes
behavioral guarantees like single-pass synchronization or richer syntax like
duplication lenses may be a matter of taste; but the choice would not be
readily apparent without attempting to design the syntax in parallel with
the semantics.

Finally, syntax is a proving ground for the practicality of other features.
The ultimate goal of a lens theory is to be an integral part of a
widely-used tool, and designing a collection of instantiations is a critical
first step on that path. A good lens framework can have the potential to
solve alignment, symmetry, or performance problems, and attempting to
design a syntax can quickly realize or dispel that potential.

Experience from the asymmetric, state-based lens work shows that supporting
the majority of synchronization scenarios requires only a handful of lenses.
The most basic lenses simply copy, insert, or delete data. Modular
developments make heavy use of sequential composition for running two lenses
one after the other (as discussed in \S\ref{sec:intro-symmetry}). One also
often wants operations on sums and products such as parallel composition,
projection, injection, and conditionals. Some support for lists (especially
a mapping operation) and other structured data (typically inductive types
with fold and unfold operations) rounds out a fairly complete set of
operations for a practical framework to support.

\section{Contributions}
\label{sec:intro-contributions}
This document espouses a foundational effort to rebuild the lens formalism
with the above challenges in mind from the beginning. Many previous efforts
to address these challenges have begun with asymmetric, state-based lenses
as a base and built additional capabilities on top. Adding to the existing
theory in this way is quite useful, but a system which attempts to combine
these additional features quickly grows baroque. By starting from first
principles, we have a unique opportunity to address these concerns in the
base theory in a new way. We focus on semantics first (modeling the core
behaviors that lenses must allow primitively) and let the syntax (that is,
what transformations are possible with the core building blocks) fall
subordinate. As we hoped, our commitment to this approach has resulted in an
elegant core lens theory which nevertheless has the ability to address each
of the four challenges discussed above.

Chapter~\ref{chap:complement} develops the machinery needed for a symmetric
lens theory in isolation from the issues of alignment and performance. The
key observation is that we can think of the two transformations in a lens as
sharing some state that is independent of the two repositories. We will show
that all the usual lens combinators can be construed as pairs of stateful
transformations. However, there is a price to pay for symmetry: though the
usual transformations are available, they do not have all the same nice
properties one expects from the asymmetric world; for example, lens
composition is not directly associative. As a result, the machinery
developed includes a notion of \emph{lens equivalence}; most properties
(including associativity of composition) then hold, but only up to lens
equivalence.

In Chapter~\ref{chap:delta}, these observations about how to achieve
symmetry will be used as the basis for a system that tackles the alignment
and performance problems (while retaining symmetry). Because the exact
nature of alignment information is so different between data
structures---and even between different transformations on the same
structure---the framework proposed in this chapter will treat such
information as almost completely abstract. It then becomes the
responsibility of each lens definition to specify what information it
expects to receive. We then go on to again implement many of the usual lens
combinators, and show that many of them are capable of disambiguating
between edits that are traditionally the source of serious alignment
headaches. Additionally, we observe that the natural way of implementing
these lenses results in a lens which operates on relatively small
descriptions of what has changed rather than on large repositories, which
addresses some of the performance issues raised above.

\ifimpl
We discuss a prototype implementation of the edit lens theory in
Chapter~\ref{chap:impl}, which includes a Haskell library together with a
small demo program that uses the library to synchronize two databases in a
simple, text-based file format. This gives us a vehicle to validate the
completeness of the edit lens theory. We will find that instantiating our
theory to a particular data model---in our case, we will follow tradition
and use strings as that model---has challenges of its own involving parsing
user actions. We will give some preliminary thoughts on this challenge, and
show that an elegant core library can be developed independent of parsing.
\fi%impl

We will explore related bidirectional frameworks in
Chapter~\ref{chap:related}, with a special focus on work which addresses
alignment issues. We will observe that edit lenses occupy a unique niche in
the design space: most other approaches are either asymmetric or do not
address the machinery needed to provide key symmetric combinators, and even
among the asymmetric approaches it is uncommon to have an elegant theory
that is nevertheless capable of addressing performance concerns.
% TODO: add a paragraph with real content about chapter 5, once it's written
Finally, we will give some short concluding remarks and discuss several
avenues for future research in Chapter~\ref{chap:conclusion}.

\section{Notation and Conventions}
\label{sec:notation}
% TODO: search the other chapters for other notation/conventions to include
% TODO: enforce these conventions
% TODO: pieces we should write about here:
%   * record syntax
%   * R-similarity, ~_R
%   * equivalence? observational equivalence?
%   * equivalence class notation
%   * <-> vs. <=>
%   * \alpha, \lambda, \rho, \gamma for symmetric monoidal categories
%   * notation for infinite lists
%   * \Defined
%   * \restrictedto
%   * \gen and monoid homomorphism specification
This section is intended to be a reference for the most common notation used
in this dissertation. All non-standard notation will also be introduced and
explained inline before its first use, so this section can safely be skimmed
or even completely skipped; nevertheless it might be useful for the reader
who has forgotten what some particular piece of notation means and would not
like to pore through the entire document to find its first use.

\paragraph*{Naming}
When naming a set, we will make the choices that follow (perhaps appending a
subscript or prime) unless there is a compelling local reason to choose
another name:
\begin{itemize}
    \item $S$ and $V$ for the source and view of asymmetric lenses,
    \item $V$, $W$, $X$, $Y$, $Z$ for the kinds of values synchronized by
        symmetric lenses,
    \item and $C$ for complement sets.
\end{itemize}
If we need a set of edits for a named set, its default name is formed by
prepending $\D$; for example, $\DX$ is the set of edits to values of type
$X$. Set members will be named with lower case letters that match the set
name; for example, $x \in X$ or $s \in S$. The lower case version of $\D$ is
$\d$; for example, $\dx \in \DX$. Lenses are named $k$, $\ell$, $m$, and
$n$.

\paragraph*{Lists}
We use $X\LIST$ to denote the set of lists with elements drawn from $X$. A
length $n$ list with $x_i$ in the $i$th position is written $\blist x_1
\clist x_n \elist$. A notable special case of this is $\NIL$, the empty
list. We will also use $x \CONS t$ to denote the list whose first element
is $x$ and whose remaining elements are in $t$. When there is only one list
involved in the nearby discussion, we will use $n$ to denote the length of
that list; otherwise, the notation $|x|$ gives the length of list $x$. To
avoid clutter, we will write singleton lists $\blist x \elist$ simply as $x$
when it is clear from context both that $x$ is a list element and that we
expect a list, not an element. If there is a list $\blist x_1 \clist x_n
\elist$ (with exactly the subscripts $1$ through $n$), we will also denote
this list simply by $x$ with no subscript. We will write $x[i \mapsto v]$
for the list $x$ with index $i$ replaced by element $v$, that is,
\[x[i \mapsto v] = \blist x_1 \clist x_{i-1} \mlist v \mlist x_{i+1} \clist
x_n \elist.\]

We will also need to deal with the set of infinite lists, which we denote
$X\INFTY$ when the elements are drawn from $X$. The infinite list with $x_i$
in the $i$th position is written $\blist x_1 \ilist$, and the infinite list
where there is a single element $x$ in every position is written $x\INFTY$.
As with finite lists, $x \CONS t$ denotes the infinite list whose first
element is $x$ and whose remaining elements are in $t$.

\paragraph*{Miscellaneous notation}
We will use \rn{CamelCasedSmallCaps} for the names of behavioral laws; a
\texttt{monospaced font} for data; and a $\ml{sans\ serif\ font}$ for code
and globally-scoped defined values. We name the canonical single-element set
and its single element by the definition $\Unit=\{\unit\}$. When defining
and using lenses and similar structures, we will use record notation; for
example, $\ell.\aget$ is the \GET component of lens $\ell$. We deal with
many variations on functions in this document; Table~\ref{tab:arrows}
summarizes them.

\begin{table}
    \centering
    % If we just use \begin{tabular}{c|l} in the obvious way, the notation
    % column comes out looking a bit ragged. So we work a bit harder to make
    % sure the arrows line up with each other by giving them their own
    % column.
    \begin{tabular}{r@{}c@{}l|l}
        \multicolumn{3}{l|}{Notation} & Meaning \\
        \hline
        $A$ & ${}\to       {}$ & $B$ & normal functions from $A$ to $B$ \\
        $A$ & ${}\partialto{}$ & $B$ & partial functions from $A$ to $B$ \\
        $S$ & ${}\alens    {}$ & $V$ & asymmetric, state-based lenses connecting $S$ and $V$ \\
        $X$ & ${}\cmaint   {}$ & $Y$ & constraint maintainers connecting $X$ and $Y$ \\
        $X$ & ${}\lens     {}$ & $Y$ & (Chapter~\ref{chap:symm}) symmetric, state-based lenses connecting $X$ and $Y$ \\
            &                  &     & (Chapter~\ref{chap:edits}) symmetric, edit-based lenses connecting $X$ and $Y$
        % TODO: is this really all the kinds of arrows we have everywhere?
    \end{tabular}
    \caption{Function and lens types}
    \label{tab:arrows}
\end{table}
